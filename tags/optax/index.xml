<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>optax on wity&#39;ai</title>
    <link>https://varun-ml.github.io/tags/optax/</link>
    <description>Recent content in optax on wity&#39;ai</description>
    <image>
      <url>https://varun-ml.github.io/images/varun.png</url>
      <link>https://varun-ml.github.io/images/varun.png</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 09 Dec 2022 17:38:58 +0530</lastBuildDate><atom:link href="https://varun-ml.github.io/tags/optax/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Denoising Diffusion Models Part 3: Generating Characters and numbers with Diffusion Models</title>
      <link>https://varun-ml.github.io/posts/diffusion-models/denoising-diffusion-models-3/</link>
      <pubDate>Fri, 09 Dec 2022 17:38:58 +0530</pubDate>
      
      <guid>https://varun-ml.github.io/posts/diffusion-models/denoising-diffusion-models-3/</guid>
      <description>Notebook Github Link Colab EMINST Denoising and Conditional generation Colab EMNIST Introduction We have introduced most of the concepts in the previous two blogs. In this blog post, we will see how the concepts translate to code. If you want to check out the earlier posts, you can find them here, diffusion model intro 1, and diffusion model intro 2.
EMNIST dataset Extended-MNIST dataset, as the name suggests, is an extension of the popular MNIST dataset.</description>
      <content:encoded><![CDATA[<table>
<thead>
<tr>
<th style="text-align:left">Notebook</th>
<th style="text-align:left">Github Link</th>
<th style="text-align:left">Colab</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">EMINST Denoising and Conditional generation</td>
<td style="text-align:left"><a href="https://github.com/varun-ml/diffusion-models-tutorial/blob/master/emnist-colab-notebooks/colab_EMNIST_conditional.diffusion_model.large.with_batch_norm.ipynb" target="_blank" >Colab EMNIST</a></td>
<td style="text-align:left"><a href="https://colab.research.google.com/github/varun-ml/diffusion-models-tutorial/blob/master/emnist-colab-notebooks/colab_EMNIST_conditional.diffusion_model.large.with_batch_norm.ipynb" target="_blank" >
  <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colab (Large)">
</a><a href="https://colab.research.google.com/github/varun-ml/diffusion-models-tutorial/blob/master/emnist-colab-notebooks/colab_EMNIST_conditional.diffusion_model.ipynb" target="_blank" >
  <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colab (Small)">
</a></td>
</tr>
</tbody>
</table>
<h2 id="introduction">Introduction</h2>
<p>We have introduced most of the concepts in the previous two blogs. In this blog post, we will see how the concepts translate to code. If you want to check out the earlier posts, you can find them here, <a href="/posts/diffusion-models/denoising-diffusion-models-1" >diffusion model intro 1</a>, and <a href="/posts/diffusion-models/denoising-diffusion-models-2" >diffusion model intro 2</a>.</p>
<h2 id="emnist-dataset">EMNIST dataset</h2>
<p><a href="https://www.tensorflow.org/datasets/catalog/emnist" target="_blank" >Extended-MNIST dataset</a>, as the name suggests, is an extension of the popular MNIST dataset. It contains labelled 28*28*1 images of handwritten English characters (upper and lower case) and numbers.</p>
<figure class="align-center ">
    <img loading="lazy" src="/images/emnist-sample.png#center"
         alt="Figure 1: Samples from the EMNIST dataset" width="50%"/> <figcaption>
            <p>Figure 1: Samples from the EMNIST dataset</p>
        </figcaption>
</figure>

<h3 id="loading-data">Loading data</h3>
<p>We will use the Tensorflow datasets library to load the EMNIST dataset. The data will be loaded in batches of size 4*128, we will also normalize the data in the range of 0-1.</p>
<p>A part of this code is adapted from the <a href="https://colab.research.google.com/github/google-research/vdm/blob/main/colab/SimpleDiffusionColab.ipynb" target="_blank" >vdm - simple diffusion example colab notebook</a>.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt" id="hl-0-1"><a class="lnlinks" href="#hl-0-1"> 1</a>
</span><span class="lnt" id="hl-0-2"><a class="lnlinks" href="#hl-0-2"> 2</a>
</span><span class="lnt" id="hl-0-3"><a class="lnlinks" href="#hl-0-3"> 3</a>
</span><span class="lnt" id="hl-0-4"><a class="lnlinks" href="#hl-0-4"> 4</a>
</span><span class="lnt" id="hl-0-5"><a class="lnlinks" href="#hl-0-5"> 5</a>
</span><span class="lnt" id="hl-0-6"><a class="lnlinks" href="#hl-0-6"> 6</a>
</span><span class="lnt" id="hl-0-7"><a class="lnlinks" href="#hl-0-7"> 7</a>
</span><span class="lnt" id="hl-0-8"><a class="lnlinks" href="#hl-0-8"> 8</a>
</span><span class="lnt" id="hl-0-9"><a class="lnlinks" href="#hl-0-9"> 9</a>
</span><span class="lnt" id="hl-0-10"><a class="lnlinks" href="#hl-0-10">10</a>
</span><span class="lnt" id="hl-0-11"><a class="lnlinks" href="#hl-0-11">11</a>
</span><span class="lnt" id="hl-0-12"><a class="lnlinks" href="#hl-0-12">12</a>
</span><span class="lnt" id="hl-0-13"><a class="lnlinks" href="#hl-0-13">13</a>
</span><span class="lnt" id="hl-0-14"><a class="lnlinks" href="#hl-0-14">14</a>
</span><span class="lnt" id="hl-0-15"><a class="lnlinks" href="#hl-0-15">15</a>
</span><span class="lnt" id="hl-0-16"><a class="lnlinks" href="#hl-0-16">16</a>
</span><span class="lnt" id="hl-0-17"><a class="lnlinks" href="#hl-0-17">17</a>
</span><span class="lnt" id="hl-0-18"><a class="lnlinks" href="#hl-0-18">18</a>
</span><span class="lnt" id="hl-0-19"><a class="lnlinks" href="#hl-0-19">19</a>
</span><span class="lnt" id="hl-0-20"><a class="lnlinks" href="#hl-0-20">20</a>
</span><span class="lnt" id="hl-0-21"><a class="lnlinks" href="#hl-0-21">21</a>
</span><span class="lnt" id="hl-0-22"><a class="lnlinks" href="#hl-0-22">22</a>
</span><span class="lnt" id="hl-0-23"><a class="lnlinks" href="#hl-0-23">23</a>
</span><span class="lnt" id="hl-0-24"><a class="lnlinks" href="#hl-0-24">24</a>
</span><span class="lnt" id="hl-0-25"><a class="lnlinks" href="#hl-0-25">25</a>
</span><span class="lnt" id="hl-0-26"><a class="lnlinks" href="#hl-0-26">26</a>
</span><span class="lnt" id="hl-0-27"><a class="lnlinks" href="#hl-0-27">27</a>
</span><span class="lnt" id="hl-0-28"><a class="lnlinks" href="#hl-0-28">28</a>
</span><span class="lnt" id="hl-0-29"><a class="lnlinks" href="#hl-0-29">29</a>
</span><span class="lnt" id="hl-0-30"><a class="lnlinks" href="#hl-0-30">30</a>
</span><span class="lnt" id="hl-0-31"><a class="lnlinks" href="#hl-0-31">31</a>
</span><span class="lnt" id="hl-0-32"><a class="lnlinks" href="#hl-0-32">32</a>
</span><span class="lnt" id="hl-0-33"><a class="lnlinks" href="#hl-0-33">33</a>
</span><span class="lnt" id="hl-0-34"><a class="lnlinks" href="#hl-0-34">34</a>
</span><span class="lnt" id="hl-0-35"><a class="lnlinks" href="#hl-0-35">35</a>
</span><span class="lnt" id="hl-0-36"><a class="lnlinks" href="#hl-0-36">36</a>
</span><span class="lnt" id="hl-0-37"><a class="lnlinks" href="#hl-0-37">37</a>
</span><span class="lnt" id="hl-0-38"><a class="lnlinks" href="#hl-0-38">38</a>
</span><span class="lnt" id="hl-0-39"><a class="lnlinks" href="#hl-0-39">39</a>
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">jax</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">jax.numpy</span> <span class="k">as</span> <span class="nn">jnp</span>
</span></span><span class="line"><span class="cl"><span class="c1"># using tensorflow libs to help load the dataset</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">tensorflow_datasets</span> <span class="k">as</span> <span class="nn">tfds</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
</span></span><span class="line"><span class="cl"><span class="n">from</span><span class="err"> </span><span class="n">clu</span><span class="err"> </span><span class="n">import</span><span class="err"> </span><span class="n">deterministic_data</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">dataset_builder</span> <span class="o">=</span> <span class="n">tfds</span><span class="o">.</span><span class="n">builder</span><span class="p">(</span><span class="s1">&#39;emnist&#39;</span><span class="p">,</span> <span class="n">data_dir</span><span class="o">=</span><span class="n">dataset_path</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">dataset_builder</span><span class="o">.</span><span class="n">download_and_prepare</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">train_split</span> <span class="o">=</span> <span class="n">tfds</span><span class="o">.</span><span class="n">split_for_jax_process</span><span class="p">(</span><span class="s1">&#39;train+train&#39;</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">preprocess_fn</span><span class="p">(</span><span class="n">example</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="n">image</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">example</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">],</span> <span class="s1">&#39;float32&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">image</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,))</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># normalizing values to 0-1 range</span>
</span></span><span class="line"><span class="cl">  <span class="n">image</span> <span class="o">=</span> <span class="n">image</span> <span class="o">/</span> <span class="mf">255.0</span>
</span></span><span class="line"><span class="cl">  <span class="k">return</span> <span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">example</span><span class="p">[</span><span class="s2">&#34;label&#34;</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">4</span> <span class="o">*</span> <span class="mi">128</span> <span class="k">if</span> <span class="n">colab</span> <span class="k">else</span> <span class="mi">64</span>
</span></span><span class="line"><span class="cl"><span class="n">train_ds</span> <span class="o">=</span> <span class="n">deterministic_data</span><span class="o">.</span><span class="n">create_dataset</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">dataset_builder</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">split</span><span class="o">=</span><span class="n">train_split</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">rng</span><span class="o">=</span><span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="n">shuffle_buffer_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">batch_dims</span><span class="o">=</span><span class="p">[</span><span class="n">jax</span><span class="o">.</span><span class="n">local_device_count</span><span class="p">(),</span> <span class="n">batch_size</span> <span class="o">//</span> <span class="n">jax</span><span class="o">.</span><span class="n">device_count</span><span class="p">()],</span>
</span></span><span class="line"><span class="cl">    <span class="n">num_epochs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">preprocess_fn</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">preprocess_fn</span><span class="p">(</span><span class="n">x</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">create_input_iter</span><span class="p">(</span><span class="n">ds</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="k">def</span> <span class="nf">_prepare</span><span class="p">(</span><span class="n">xs</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">_f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">      <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">_numpy</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">      <span class="k">return</span> <span class="n">x</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">jax</span><span class="o">.</span><span class="n">tree_util</span><span class="o">.</span><span class="n">tree_map</span><span class="p">(</span><span class="n">_f</span><span class="p">,</span> <span class="n">xs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">it</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="n">_prepare</span><span class="p">,</span> <span class="n">ds</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">it</span> <span class="o">=</span> <span class="n">jax_utils</span><span class="o">.</span><span class="n">prefetch_to_device</span><span class="p">(</span><span class="n">it</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="k">return</span> <span class="n">it</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="utilities-for-visualizing-emnist-data">Utilities for visualizing EMNIST data</h3>
<details>
<summary> Open section on utilities. </summary>
<p>We will be using these utilities to print the images generated from the diffusion models.</p>
<p>A part of this code is adapted from the <a href="https://colab.research.google.com/github/google-research/vdm/blob/main/colab/SimpleDiffusionColab.ipynb" target="_blank" >vdm - simple diffusion example colab notebook</a>.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt" id="hl-1-1"><a class="lnlinks" href="#hl-1-1"> 1</a>
</span><span class="lnt" id="hl-1-2"><a class="lnlinks" href="#hl-1-2"> 2</a>
</span><span class="lnt" id="hl-1-3"><a class="lnlinks" href="#hl-1-3"> 3</a>
</span><span class="lnt" id="hl-1-4"><a class="lnlinks" href="#hl-1-4"> 4</a>
</span><span class="lnt" id="hl-1-5"><a class="lnlinks" href="#hl-1-5"> 5</a>
</span><span class="lnt" id="hl-1-6"><a class="lnlinks" href="#hl-1-6"> 6</a>
</span><span class="lnt" id="hl-1-7"><a class="lnlinks" href="#hl-1-7"> 7</a>
</span><span class="lnt" id="hl-1-8"><a class="lnlinks" href="#hl-1-8"> 8</a>
</span><span class="lnt" id="hl-1-9"><a class="lnlinks" href="#hl-1-9"> 9</a>
</span><span class="lnt" id="hl-1-10"><a class="lnlinks" href="#hl-1-10">10</a>
</span><span class="lnt" id="hl-1-11"><a class="lnlinks" href="#hl-1-11">11</a>
</span><span class="lnt" id="hl-1-12"><a class="lnlinks" href="#hl-1-12">12</a>
</span><span class="lnt" id="hl-1-13"><a class="lnlinks" href="#hl-1-13">13</a>
</span><span class="lnt" id="hl-1-14"><a class="lnlinks" href="#hl-1-14">14</a>
</span><span class="lnt" id="hl-1-15"><a class="lnlinks" href="#hl-1-15">15</a>
</span><span class="lnt" id="hl-1-16"><a class="lnlinks" href="#hl-1-16">16</a>
</span><span class="lnt" id="hl-1-17"><a class="lnlinks" href="#hl-1-17">17</a>
</span><span class="lnt" id="hl-1-18"><a class="lnlinks" href="#hl-1-18">18</a>
</span><span class="lnt" id="hl-1-19"><a class="lnlinks" href="#hl-1-19">19</a>
</span><span class="lnt" id="hl-1-20"><a class="lnlinks" href="#hl-1-20">20</a>
</span><span class="lnt" id="hl-1-21"><a class="lnlinks" href="#hl-1-21">21</a>
</span><span class="lnt" id="hl-1-22"><a class="lnlinks" href="#hl-1-22">22</a>
</span><span class="lnt" id="hl-1-23"><a class="lnlinks" href="#hl-1-23">23</a>
</span><span class="lnt" id="hl-1-24"><a class="lnlinks" href="#hl-1-24">24</a>
</span><span class="lnt" id="hl-1-25"><a class="lnlinks" href="#hl-1-25">25</a>
</span><span class="lnt" id="hl-1-26"><a class="lnlinks" href="#hl-1-26">26</a>
</span><span class="lnt" id="hl-1-27"><a class="lnlinks" href="#hl-1-27">27</a>
</span><span class="lnt" id="hl-1-28"><a class="lnlinks" href="#hl-1-28">28</a>
</span><span class="lnt" id="hl-1-29"><a class="lnlinks" href="#hl-1-29">29</a>
</span><span class="lnt" id="hl-1-30"><a class="lnlinks" href="#hl-1-30">30</a>
</span><span class="lnt" id="hl-1-31"><a class="lnlinks" href="#hl-1-31">31</a>
</span><span class="lnt" id="hl-1-32"><a class="lnlinks" href="#hl-1-32">32</a>
</span><span class="lnt" id="hl-1-33"><a class="lnlinks" href="#hl-1-33">33</a>
</span><span class="lnt" id="hl-1-34"><a class="lnlinks" href="#hl-1-34">34</a>
</span><span class="lnt" id="hl-1-35"><a class="lnlinks" href="#hl-1-35">35</a>
</span><span class="lnt" id="hl-1-36"><a class="lnlinks" href="#hl-1-36">36</a>
</span><span class="lnt" id="hl-1-37"><a class="lnlinks" href="#hl-1-37">37</a>
</span><span class="lnt" id="hl-1-38"><a class="lnlinks" href="#hl-1-38">38</a>
</span><span class="lnt" id="hl-1-39"><a class="lnlinks" href="#hl-1-39">39</a>
</span><span class="lnt" id="hl-1-40"><a class="lnlinks" href="#hl-1-40">40</a>
</span><span class="lnt" id="hl-1-41"><a class="lnlinks" href="#hl-1-41">41</a>
</span><span class="lnt" id="hl-1-42"><a class="lnlinks" href="#hl-1-42">42</a>
</span><span class="lnt" id="hl-1-43"><a class="lnlinks" href="#hl-1-43">43</a>
</span><span class="lnt" id="hl-1-44"><a class="lnlinks" href="#hl-1-44">44</a>
</span><span class="lnt" id="hl-1-45"><a class="lnlinks" href="#hl-1-45">45</a>
</span><span class="lnt" id="hl-1-46"><a class="lnlinks" href="#hl-1-46">46</a>
</span><span class="lnt" id="hl-1-47"><a class="lnlinks" href="#hl-1-47">47</a>
</span><span class="lnt" id="hl-1-48"><a class="lnlinks" href="#hl-1-48">48</a>
</span><span class="lnt" id="hl-1-49"><a class="lnlinks" href="#hl-1-49">49</a>
</span><span class="lnt" id="hl-1-50"><a class="lnlinks" href="#hl-1-50">50</a>
</span><span class="lnt" id="hl-1-51"><a class="lnlinks" href="#hl-1-51">51</a>
</span><span class="lnt" id="hl-1-52"><a class="lnlinks" href="#hl-1-52">52</a>
</span><span class="lnt" id="hl-1-53"><a class="lnlinks" href="#hl-1-53">53</a>
</span><span class="lnt" id="hl-1-54"><a class="lnlinks" href="#hl-1-54">54</a>
</span><span class="lnt" id="hl-1-55"><a class="lnlinks" href="#hl-1-55">55</a>
</span><span class="lnt" id="hl-1-56"><a class="lnlinks" href="#hl-1-56">56</a>
</span><span class="lnt" id="hl-1-57"><a class="lnlinks" href="#hl-1-57">57</a>
</span><span class="lnt" id="hl-1-58"><a class="lnlinks" href="#hl-1-58">58</a>
</span><span class="lnt" id="hl-1-59"><a class="lnlinks" href="#hl-1-59">59</a>
</span><span class="lnt" id="hl-1-60"><a class="lnlinks" href="#hl-1-60">60</a>
</span><span class="lnt" id="hl-1-61"><a class="lnlinks" href="#hl-1-61">61</a>
</span><span class="lnt" id="hl-1-62"><a class="lnlinks" href="#hl-1-62">62</a>
</span><span class="lnt" id="hl-1-63"><a class="lnlinks" href="#hl-1-63">63</a>
</span><span class="lnt" id="hl-1-64"><a class="lnlinks" href="#hl-1-64">64</a>
</span><span class="lnt" id="hl-1-65"><a class="lnlinks" href="#hl-1-65">65</a>
</span><span class="lnt" id="hl-1-66"><a class="lnlinks" href="#hl-1-66">66</a>
</span><span class="lnt" id="hl-1-67"><a class="lnlinks" href="#hl-1-67">67</a>
</span><span class="lnt" id="hl-1-68"><a class="lnlinks" href="#hl-1-68">68</a>
</span><span class="lnt" id="hl-1-69"><a class="lnlinks" href="#hl-1-69">69</a>
</span><span class="lnt" id="hl-1-70"><a class="lnlinks" href="#hl-1-70">70</a>
</span><span class="lnt" id="hl-1-71"><a class="lnlinks" href="#hl-1-71">71</a>
</span><span class="lnt" id="hl-1-72"><a class="lnlinks" href="#hl-1-72">72</a>
</span><span class="lnt" id="hl-1-73"><a class="lnlinks" href="#hl-1-73">73</a>
</span><span class="lnt" id="hl-1-74"><a class="lnlinks" href="#hl-1-74">74</a>
</span><span class="lnt" id="hl-1-75"><a class="lnlinks" href="#hl-1-75">75</a>
</span><span class="lnt" id="hl-1-76"><a class="lnlinks" href="#hl-1-76">76</a>
</span><span class="lnt" id="hl-1-77"><a class="lnlinks" href="#hl-1-77">77</a>
</span><span class="lnt" id="hl-1-78"><a class="lnlinks" href="#hl-1-78">78</a>
</span><span class="lnt" id="hl-1-79"><a class="lnlinks" href="#hl-1-79">79</a>
</span><span class="lnt" id="hl-1-80"><a class="lnlinks" href="#hl-1-80">80</a>
</span><span class="lnt" id="hl-1-81"><a class="lnlinks" href="#hl-1-81">81</a>
</span><span class="lnt" id="hl-1-82"><a class="lnlinks" href="#hl-1-82">82</a>
</span><span class="lnt" id="hl-1-83"><a class="lnlinks" href="#hl-1-83">83</a>
</span><span class="lnt" id="hl-1-84"><a class="lnlinks" href="#hl-1-84">84</a>
</span><span class="lnt" id="hl-1-85"><a class="lnlinks" href="#hl-1-85">85</a>
</span><span class="lnt" id="hl-1-86"><a class="lnlinks" href="#hl-1-86">86</a>
</span><span class="lnt" id="hl-1-87"><a class="lnlinks" href="#hl-1-87">87</a>
</span><span class="lnt" id="hl-1-88"><a class="lnlinks" href="#hl-1-88">88</a>
</span><span class="lnt" id="hl-1-89"><a class="lnlinks" href="#hl-1-89">89</a>
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">io</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">math</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">display_png</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">matplotlib.cm</span> <span class="k">as</span> <span class="nn">cm</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">imify</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">origin</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="s2">&#34;&#34;&#34;Convert an array to an image.
</span></span></span><span class="line"><span class="cl"><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">  Arguments:
</span></span></span><span class="line"><span class="cl"><span class="s2">    arr : array-like The image data. The shape can be one of MxN (luminance),
</span></span></span><span class="line"><span class="cl"><span class="s2">      MxNx3 (RGB) or MxNx4 (RGBA).
</span></span></span><span class="line"><span class="cl"><span class="s2">    vmin : scalar, optional lower value.
</span></span></span><span class="line"><span class="cl"><span class="s2">    vmax : scalar, optional *vmin* and *vmax* set the color scaling for the
</span></span></span><span class="line"><span class="cl"><span class="s2">      image by fixing the values that map to the colormap color limits. If
</span></span></span><span class="line"><span class="cl"><span class="s2">      either *vmin* or *vmax* is None, that limit is determined from the *arr*
</span></span></span><span class="line"><span class="cl"><span class="s2">      min/max value.
</span></span></span><span class="line"><span class="cl"><span class="s2">    cmap : str or `~matplotlib.colors.Colormap`, optional A Colormap instance or
</span></span></span><span class="line"><span class="cl"><span class="s2">      registered colormap name. The colormap maps scalar data to colors. It is
</span></span></span><span class="line"><span class="cl"><span class="s2">      ignored for RGB(A) data.
</span></span></span><span class="line"><span class="cl"><span class="s2">        Defaults to :rc:`image.cmap` (&#39;viridis&#39;).
</span></span></span><span class="line"><span class="cl"><span class="s2">    origin : {&#39;upper&#39;, &#39;lower&#39;}, optional Indicates whether the ``(0, 0)`` index
</span></span></span><span class="line"><span class="cl"><span class="s2">      of the array is in the upper
</span></span></span><span class="line"><span class="cl"><span class="s2">        left or lower left corner of the axes.  Defaults to :rc:`image.origin`
</span></span></span><span class="line"><span class="cl"><span class="s2">          (&#39;upper&#39;).
</span></span></span><span class="line"><span class="cl"><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">  Returns:
</span></span></span><span class="line"><span class="cl"><span class="s2">    A uint8 image array.
</span></span></span><span class="line"><span class="cl"><span class="s2">  &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">  <span class="n">sm</span> <span class="o">=</span> <span class="n">cm</span><span class="o">.</span><span class="n">ScalarMappable</span><span class="p">(</span><span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">sm</span><span class="o">.</span><span class="n">set_clim</span><span class="p">(</span><span class="n">vmin</span><span class="p">,</span> <span class="n">vmax</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="k">if</span> <span class="n">origin</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">origin</span> <span class="o">=</span> <span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s2">&#34;image.origin&#34;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">  <span class="k">if</span> <span class="n">origin</span> <span class="o">==</span> <span class="s2">&#34;lower&#34;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">arr</span> <span class="o">=</span> <span class="n">arr</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">  <span class="n">rgba</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">to_rgba</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="nb">bytes</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="k">return</span> <span class="n">rgba</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">rawarrview</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="s2">&#34;&#34;&#34;Visualize an array as if it was an image in colab notebooks.
</span></span></span><span class="line"><span class="cl"><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">  Arguments:
</span></span></span><span class="line"><span class="cl"><span class="s2">    array: an array which will be turned into an image.
</span></span></span><span class="line"><span class="cl"><span class="s2">    **kwargs: Additional keyword arguments passed to imify.
</span></span></span><span class="line"><span class="cl"><span class="s2">  &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">  <span class="n">f</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">  <span class="n">imarray</span> <span class="o">=</span> <span class="n">imify</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">plt</span><span class="o">.</span><span class="n">imsave</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">imarray</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s2">&#34;png&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">f</span><span class="o">.</span><span class="n">seek</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">dat</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">  <span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">  <span class="n">display_png</span><span class="p">(</span><span class="n">dat</span><span class="p">,</span> <span class="n">raw</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">reshape_image_batch</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">cut</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">rows</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="s2">&#34;&#34;&#34;Given an array of shape [n, x, y, ...] reshape it to create an image field.
</span></span></span><span class="line"><span class="cl"><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">  Arguments:
</span></span></span><span class="line"><span class="cl"><span class="s2">    array: The array to reshape.
</span></span></span><span class="line"><span class="cl"><span class="s2">    cut: Optional cut on the number of images to view. Will default to whole
</span></span></span><span class="line"><span class="cl"><span class="s2">      array.
</span></span></span><span class="line"><span class="cl"><span class="s2">    rows: Number of rows to use.  Will default to the integer less than the
</span></span></span><span class="line"><span class="cl"><span class="s2">      sqrt.
</span></span></span><span class="line"><span class="cl"><span class="s2">    axis: Axis to interpretate at the batch dimension.  By default the image
</span></span></span><span class="line"><span class="cl"><span class="s2">      dimensions immediately follow.
</span></span></span><span class="line"><span class="cl"><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">  Returns:
</span></span></span><span class="line"><span class="cl"><span class="s2">    reshaped_array: An array of shape [rows * x, cut / rows * y, ...]
</span></span></span><span class="line"><span class="cl"><span class="s2">  &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">  <span class="n">original_shape</span> <span class="o">=</span> <span class="n">array</span><span class="o">.</span><span class="n">shape</span>
</span></span><span class="line"><span class="cl">  <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">original_shape</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&#34;array must be at least 3 Dimensional.&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="k">if</span> <span class="n">cut</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">cut</span> <span class="o">=</span> <span class="n">original_shape</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">  <span class="k">if</span> <span class="n">rows</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">rows</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">cut</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="n">cols</span> <span class="o">=</span> <span class="n">cut</span> <span class="o">//</span> <span class="n">rows</span>
</span></span><span class="line"><span class="cl">  <span class="n">cut</span> <span class="o">=</span> <span class="n">cols</span> <span class="o">*</span> <span class="n">rows</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="n">leading</span> <span class="o">=</span> <span class="n">original_shape</span><span class="p">[:</span><span class="n">axis</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">  <span class="n">x_width</span> <span class="o">=</span> <span class="n">original_shape</span><span class="p">[</span><span class="n">axis</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">  <span class="n">y_width</span> <span class="o">=</span> <span class="n">original_shape</span><span class="p">[</span><span class="n">axis</span> <span class="o">+</span> <span class="mi">2</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">  <span class="n">remaining</span> <span class="o">=</span> <span class="n">original_shape</span><span class="p">[</span><span class="n">axis</span> <span class="o">+</span> <span class="mi">3</span><span class="p">:]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="n">array</span> <span class="o">=</span> <span class="n">array</span><span class="p">[:</span><span class="n">cut</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">  <span class="n">array</span> <span class="o">=</span> <span class="n">array</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">leading</span> <span class="o">+</span> <span class="p">(</span><span class="n">rows</span><span class="p">,</span> <span class="n">cols</span><span class="p">,</span> <span class="n">x_width</span><span class="p">,</span> <span class="n">y_width</span><span class="p">)</span> <span class="o">+</span> <span class="n">remaining</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">moveaxis</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">axis</span> <span class="o">+</span> <span class="mi">2</span><span class="p">,</span> <span class="n">axis</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">array</span> <span class="o">=</span> <span class="n">array</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">leading</span> <span class="o">+</span> <span class="p">(</span><span class="n">rows</span> <span class="o">*</span> <span class="n">x_width</span><span class="p">,</span> <span class="n">cols</span> <span class="o">*</span> <span class="n">y_width</span><span class="p">)</span> <span class="o">+</span> <span class="n">remaining</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="k">return</span> <span class="n">array</span>
</span></span></code></pre></td></tr></table>
</div>
</div></details>
<h2 id="setting-up-diffusion-step">Setting up Diffusion Step</h2>
<p>Setting up a diffusion step involves:</p>
<ol>
<li>Defining a schedule for diffusion:  $\alpha$</li>
<li>Defining variables that we will be using during denoising and diffusion steps.</li>
<li>Defining utilities to add noise to an image.</li>
</ol>
<p>You can find more details about diffusion in the <a href="/posts/diffusion-models/denoising-diffusion-models-1/#1-diffusion-step" >earlier post.</a></p>
<p>We are going to use the cosine schedule for diffusion in this example.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt" id="hl-2-1"><a class="lnlinks" href="#hl-2-1"> 1</a>
</span><span class="lnt" id="hl-2-2"><a class="lnlinks" href="#hl-2-2"> 2</a>
</span><span class="lnt" id="hl-2-3"><a class="lnlinks" href="#hl-2-3"> 3</a>
</span><span class="lnt" id="hl-2-4"><a class="lnlinks" href="#hl-2-4"> 4</a>
</span><span class="lnt" id="hl-2-5"><a class="lnlinks" href="#hl-2-5"> 5</a>
</span><span class="lnt" id="hl-2-6"><a class="lnlinks" href="#hl-2-6"> 6</a>
</span><span class="lnt" id="hl-2-7"><a class="lnlinks" href="#hl-2-7"> 7</a>
</span><span class="lnt" id="hl-2-8"><a class="lnlinks" href="#hl-2-8"> 8</a>
</span><span class="lnt" id="hl-2-9"><a class="lnlinks" href="#hl-2-9"> 9</a>
</span><span class="lnt" id="hl-2-10"><a class="lnlinks" href="#hl-2-10">10</a>
</span><span class="lnt" id="hl-2-11"><a class="lnlinks" href="#hl-2-11">11</a>
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">cosine_beta_schedule</span><span class="p">(</span><span class="n">timesteps</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mf">0.008</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">    cosine schedule as proposed in https://arxiv.org/abs/2102.09672
</span></span></span><span class="line"><span class="cl"><span class="s2">    &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">steps</span> <span class="o">=</span> <span class="n">timesteps</span> <span class="o">+</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">,</span> <span class="n">steps</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">alphas_cumprod</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">cos</span><span class="p">(((</span><span class="n">x</span> <span class="o">/</span> <span class="n">timesteps</span><span class="p">)</span> <span class="o">+</span> <span class="n">s</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">s</span><span class="p">)</span> <span class="o">*</span> <span class="n">jnp</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
</span></span><span class="line"><span class="cl">    <span class="n">alphas_cumprod</span> <span class="o">=</span> <span class="n">alphas_cumprod</span> <span class="o">/</span> <span class="n">alphas_cumprod</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="n">betas</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">alphas_cumprod</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">/</span> <span class="n">alphas_cumprod</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">	<span class="c1"># clipping this at 0.1 as I have found it difficult to work with higher values of beta.</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">betas</span><span class="p">,</span> <span class="mf">0.0001</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>Setting up the variables:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt" id="hl-3-1"><a class="lnlinks" href="#hl-3-1"> 1</a>
</span><span class="lnt" id="hl-3-2"><a class="lnlinks" href="#hl-3-2"> 2</a>
</span><span class="lnt" id="hl-3-3"><a class="lnlinks" href="#hl-3-3"> 3</a>
</span><span class="lnt" id="hl-3-4"><a class="lnlinks" href="#hl-3-4"> 4</a>
</span><span class="lnt" id="hl-3-5"><a class="lnlinks" href="#hl-3-5"> 5</a>
</span><span class="lnt" id="hl-3-6"><a class="lnlinks" href="#hl-3-6"> 6</a>
</span><span class="lnt" id="hl-3-7"><a class="lnlinks" href="#hl-3-7"> 7</a>
</span><span class="lnt" id="hl-3-8"><a class="lnlinks" href="#hl-3-8"> 8</a>
</span><span class="lnt" id="hl-3-9"><a class="lnlinks" href="#hl-3-9"> 9</a>
</span><span class="lnt" id="hl-3-10"><a class="lnlinks" href="#hl-3-10">10</a>
</span><span class="lnt" id="hl-3-11"><a class="lnlinks" href="#hl-3-11">11</a>
</span><span class="lnt" id="hl-3-12"><a class="lnlinks" href="#hl-3-12">12</a>
</span><span class="lnt" id="hl-3-13"><a class="lnlinks" href="#hl-3-13">13</a>
</span><span class="lnt" id="hl-3-14"><a class="lnlinks" href="#hl-3-14">14</a>
</span><span class="lnt" id="hl-3-15"><a class="lnlinks" href="#hl-3-15">15</a>
</span><span class="lnt" id="hl-3-16"><a class="lnlinks" href="#hl-3-16">16</a>
</span><span class="lnt" id="hl-3-17"><a class="lnlinks" href="#hl-3-17">17</a>
</span><span class="lnt" id="hl-3-18"><a class="lnlinks" href="#hl-3-18">18</a>
</span><span class="lnt" id="hl-3-19"><a class="lnlinks" href="#hl-3-19">19</a>
</span><span class="lnt" id="hl-3-20"><a class="lnlinks" href="#hl-3-20">20</a>
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">timesteps</span> <span class="o">=</span> <span class="mi">250</span>
</span></span><span class="line"><span class="cl"><span class="n">betas</span> <span class="o">=</span> <span class="n">cosine_beta_schedule</span><span class="p">(</span><span class="n">timesteps</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">alphas</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">betas</span>
</span></span><span class="line"><span class="cl"><span class="n">alphas_</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">cumprod</span><span class="p">(</span><span class="n">alphas</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">variance</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">alphas_</span>
</span></span><span class="line"><span class="cl"><span class="n">sd</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">variance</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># these variables are used during diffusion and denoising step</span>
</span></span><span class="line"><span class="cl"><span class="n">alphas_prev_</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">alphas_</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="s2">&#34;constant&#34;</span><span class="p">,</span> <span class="n">constant_values</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">sigma_squared_q_t</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alphas</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alphas_</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alphas_prev_</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">log_sigma_squared_q_t</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">alphas</span><span class="p">)</span> <span class="o">+</span> <span class="n">jnp</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">alphas_</span><span class="p">)</span> <span class="o">-</span> <span class="n">jnp</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">alphas_prev_</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">sigma_squared_q_t_corrected</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_sigma_squared_q_t</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## following code here -- we are computing the posterior variance</span>
</span></span><span class="line"><span class="cl"><span class="c1">## https://github.com/hojonathanho/diffusion/blob/1e0dceb3b3495bbe19116a5e1b3596cd0706c543/diffusion_tf/diffusion_utils_2.py#L196</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">## https://github.com/hojonathanho/diffusion/blob/1e0dceb3b3495bbe19116a5e1b3596cd0706c543/diffusion_tf/diffusion_utils_2.py#L78 </span>
</span></span><span class="line"><span class="cl"><span class="n">log_posterior_variance</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">posterior_variance</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">posterior_variance</span><span class="p">[</span><span class="mi">1</span><span class="p">:]]))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">posterior_variance_corrected</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_posterior_variance</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>Let&rsquo;s define the utilities as well, adding noise using the re-parameterization trick. The diffusion step takes in data, time step value and adds noise to the data according to the equation below. It uses the schedule $\alpha$ defined above.</p>

$$
\begin{align}
q_t(x_t|x_0) &= \sqrt{\bar\alpha_t}x_0 + \sqrt{(1 - \bar\alpha_t )}\ast\epsilon_0^\ast ; \space where \space \epsilon_0^\ast \in N(0, I) \cr  
&= N(\sqrt{\bar\alpha_t}x_0, (1 - \bar\alpha_t)I) \cr 
\end{align}
$$    

<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt" id="hl-4-1"><a class="lnlinks" href="#hl-4-1"> 1</a>
</span><span class="lnt" id="hl-4-2"><a class="lnlinks" href="#hl-4-2"> 2</a>
</span><span class="lnt" id="hl-4-3"><a class="lnlinks" href="#hl-4-3"> 3</a>
</span><span class="lnt" id="hl-4-4"><a class="lnlinks" href="#hl-4-4"> 4</a>
</span><span class="lnt" id="hl-4-5"><a class="lnlinks" href="#hl-4-5"> 5</a>
</span><span class="lnt" id="hl-4-6"><a class="lnlinks" href="#hl-4-6"> 6</a>
</span><span class="lnt" id="hl-4-7"><a class="lnlinks" href="#hl-4-7"> 7</a>
</span><span class="lnt" id="hl-4-8"><a class="lnlinks" href="#hl-4-8"> 8</a>
</span><span class="lnt" id="hl-4-9"><a class="lnlinks" href="#hl-4-9"> 9</a>
</span><span class="lnt" id="hl-4-10"><a class="lnlinks" href="#hl-4-10">10</a>
</span><span class="lnt" id="hl-4-11"><a class="lnlinks" href="#hl-4-11">11</a>
</span><span class="lnt" id="hl-4-12"><a class="lnlinks" href="#hl-4-12">12</a>
</span><span class="lnt" id="hl-4-13"><a class="lnlinks" href="#hl-4-13">13</a>
</span><span class="lnt" id="hl-4-14"><a class="lnlinks" href="#hl-4-14">14</a>
</span><span class="lnt" id="hl-4-15"><a class="lnlinks" href="#hl-4-15">15</a>
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># how to add noise to the data</span>
</span></span><span class="line"><span class="cl"><span class="nd">@jax.jit</span> <span class="p">:</span> <span class="n">jit</span> <span class="n">compilazation</span> <span class="n">to</span> <span class="n">significantly</span> <span class="n">speed</span> <span class="n">up</span> <span class="n">code</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">get_noisy</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">timestep</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">timestep</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">timestep</span><span class="p">,</span> <span class="s1">&#39;b -&gt; b 28 28 1&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># we will use the reparameterization trick</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># need to generate new keys everytime</span>
</span></span><span class="line"><span class="cl">    <span class="n">_</span><span class="p">,</span> <span class="n">noise_key</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">rng</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">noise_at_t</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">noise_key</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">batch</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">added_noise_at_t</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">batch</span> <span class="o">*</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">alphas_</span><span class="p">[</span><span class="n">timestep</span><span class="p">]),</span> <span class="n">noise_at_t</span> <span class="o">*</span> <span class="n">sd</span><span class="p">[</span><span class="n">timestep</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">added_noise_at_t</span><span class="p">,</span> <span class="n">noise_at_t</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># recovering original data by removing noise</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">recover_original</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">timestep</span><span class="p">,</span> <span class="n">noise</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">true_data</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">noise</span><span class="o">*</span><span class="n">sd</span><span class="p">[</span><span class="n">timestep</span><span class="p">])</span><span class="o">/</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">alphas_</span><span class="p">[</span><span class="n">timestep</span><span class="p">]))</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">true_data</span>
</span></span></code></pre></td></tr></table>
</div>
</div><details>
<summary>Take a random data point and add noise over multiple steps. Click to see the code.</summary>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt" id="hl-5-1"><a class="lnlinks" href="#hl-5-1"> 1</a>
</span><span class="lnt" id="hl-5-2"><a class="lnlinks" href="#hl-5-2"> 2</a>
</span><span class="lnt" id="hl-5-3"><a class="lnlinks" href="#hl-5-3"> 3</a>
</span><span class="lnt" id="hl-5-4"><a class="lnlinks" href="#hl-5-4"> 4</a>
</span><span class="lnt" id="hl-5-5"><a class="lnlinks" href="#hl-5-5"> 5</a>
</span><span class="lnt" id="hl-5-6"><a class="lnlinks" href="#hl-5-6"> 6</a>
</span><span class="lnt" id="hl-5-7"><a class="lnlinks" href="#hl-5-7"> 7</a>
</span><span class="lnt" id="hl-5-8"><a class="lnlinks" href="#hl-5-8"> 8</a>
</span><span class="lnt" id="hl-5-9"><a class="lnlinks" href="#hl-5-9"> 9</a>
</span><span class="lnt" id="hl-5-10"><a class="lnlinks" href="#hl-5-10">10</a>
</span><span class="lnt" id="hl-5-11"><a class="lnlinks" href="#hl-5-11">11</a>
</span><span class="lnt" id="hl-5-12"><a class="lnlinks" href="#hl-5-12">12</a>
</span><span class="lnt" id="hl-5-13"><a class="lnlinks" href="#hl-5-13">13</a>
</span><span class="lnt" id="hl-5-14"><a class="lnlinks" href="#hl-5-14">14</a>
</span><span class="lnt" id="hl-5-15"><a class="lnlinks" href="#hl-5-15">15</a>
</span><span class="lnt" id="hl-5-16"><a class="lnlinks" href="#hl-5-16">16</a>
</span><span class="lnt" id="hl-5-17"><a class="lnlinks" href="#hl-5-17">17</a>
</span><span class="lnt" id="hl-5-18"><a class="lnlinks" href="#hl-5-18">18</a>
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">random_index</span> <span class="o">=</span> <span class="mi">22</span>
</span></span><span class="line"><span class="cl"><span class="n">image</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">create_input_iter</span><span class="p">(</span><span class="n">train_ds</span><span class="p">))[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="n">random_index</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">ims</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl"><span class="n">noisy_images</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">get_noisy</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">einops</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="s1">&#39;h w c -&gt; b h w c&#39;</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="n">timesteps</span><span class="o">//</span><span class="mi">5</span><span class="p">),</span> <span class="n">jnp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="n">colab</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">  <span class="n">noisy_images</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">rearrange</span><span class="p">(</span><span class="n">noisy_images</span><span class="p">,</span> <span class="s1">&#39;b h w c -&gt; b h (w c)&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">noisy_images</span> <span class="o">=</span> <span class="n">unnormalize</span><span class="p">(</span><span class="n">noisy_images</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">timesteps</span><span class="o">//</span><span class="mi">10</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">im</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">noisy_images</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&#34;gray&#34;</span><span class="p">,</span> <span class="n">animated</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">ims</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">im</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">animate</span> <span class="o">=</span> <span class="n">animation</span><span class="o">.</span><span class="n">ArtistAnimation</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">ims</span><span class="p">,</span> <span class="n">interval</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">blit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">repeat_delay</span><span class="o">=</span><span class="mi">3000</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">animate</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">gifs_dir</span><span class="o">+</span><span class="s1">&#39;diffusion.gif&#39;</span><span class="p">,</span> <span class="n">writer</span><span class="o">=</span><span class="s1">&#39;pillow&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">with</span><span class="err"> </span><span class="nb">open</span><span class="p">(</span><span class="n">gifs_dir</span><span class="err"> </span><span class="o">+</span><span class="err"> </span><span class="s1">&#39;diffusion.gif&#39;</span><span class="p">,</span><span class="s1">&#39;rb&#39;</span><span class="p">)</span><span class="err"> </span><span class="k">as</span><span class="err"> </span><span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl"><span class="err">  </span><span class="n">display</span><span class="p">(</span><span class="n">Image</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">(),</span><span class="err"> </span><span class="nb">format</span><span class="o">=</span><span class="s1">&#39;png&#39;</span><span class="p">))</span>
</span></span></code></pre></td></tr></table>
</div>
</div></details>
<figure class="align-center ">
    <img loading="lazy" src="/images/diffusion-z.gif#center"
         alt="Figure 2: Using the utilities defined above to add Gaussian Noise in multiple steps to a handwritten character &amp;lsquo;z&amp;rsquo;" width="50%"/> <figcaption>
            <p>Figure 2: Using the utilities defined above to add Gaussian Noise in multiple steps to a handwritten character &lsquo;z&rsquo;</p>
        </figcaption>
</figure>

<h2 id="the-denoising-model-u-net">The Denoising Model: U-Net</h2>
<p>In the earlier blog posts, we were working on 2-d samples. The <a href="/posts/diffusion-models/denoising-diffusion-models-1/#neural-network" >denoising model</a> was a multi layer perceptron with GeLU activations. In the case of EMNIST we will have to denoise images. <a href="https://en.wikipedia.org/wiki/U-Net" target="_blank" >U-Nets</a> are the recommended models to do this.</p>
<figure class="align-center ">
    <img loading="lazy" src="/images/u-net.png#center"
         alt="Figure 3: U-Net architecture. It&amp;rsquo;s similar to the one we will build." width="100%"/> <figcaption>
            <p>Figure 3: U-Net architecture. It&rsquo;s similar to the one we will build.</p>
        </figcaption>
</figure>

<p>The U-Net architecture has the following characteristics:</p>
<ul>
<li>It&rsquo;s typically represented as a U block.</li>
<li>The first part of the U block downsamples the image. We go from a 28*28 image to a 7*7 image. This is done using Downsampling convolution blocks.</li>
<li>With downsampling, we increase the number of channels (features). We go from 1 channel in the input to 192 channels at the end of the first part of the U-net.</li>
<li>The 2<sup>nd</sup> part of the U block does the opposite of the 1st part. We go from a 7*7 image to a 28*28 image, and also go from 192 channels to 1 channel. Upsampling is done using Upsampling convolutional blocks.</li>
<li>At the same time, the U-Net has residual connections, connecting layers in the downsampling part to the layers in the upsampling part, this makes training the network efficient.</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt" id="hl-6-1"><a class="lnlinks" href="#hl-6-1"> 1</a>
</span><span class="lnt" id="hl-6-2"><a class="lnlinks" href="#hl-6-2"> 2</a>
</span><span class="lnt" id="hl-6-3"><a class="lnlinks" href="#hl-6-3"> 3</a>
</span><span class="lnt" id="hl-6-4"><a class="lnlinks" href="#hl-6-4"> 4</a>
</span><span class="lnt" id="hl-6-5"><a class="lnlinks" href="#hl-6-5"> 5</a>
</span><span class="lnt" id="hl-6-6"><a class="lnlinks" href="#hl-6-6"> 6</a>
</span><span class="lnt" id="hl-6-7"><a class="lnlinks" href="#hl-6-7"> 7</a>
</span><span class="lnt" id="hl-6-8"><a class="lnlinks" href="#hl-6-8"> 8</a>
</span><span class="lnt" id="hl-6-9"><a class="lnlinks" href="#hl-6-9"> 9</a>
</span><span class="lnt" id="hl-6-10"><a class="lnlinks" href="#hl-6-10">10</a>
</span><span class="lnt" id="hl-6-11"><a class="lnlinks" href="#hl-6-11">11</a>
</span><span class="lnt" id="hl-6-12"><a class="lnlinks" href="#hl-6-12">12</a>
</span><span class="lnt" id="hl-6-13"><a class="lnlinks" href="#hl-6-13">13</a>
</span><span class="lnt" id="hl-6-14"><a class="lnlinks" href="#hl-6-14">14</a>
</span><span class="lnt" id="hl-6-15"><a class="lnlinks" href="#hl-6-15">15</a>
</span><span class="lnt" id="hl-6-16"><a class="lnlinks" href="#hl-6-16">16</a>
</span><span class="lnt" id="hl-6-17"><a class="lnlinks" href="#hl-6-17">17</a>
</span><span class="lnt" id="hl-6-18"><a class="lnlinks" href="#hl-6-18">18</a>
</span><span class="lnt" id="hl-6-19"><a class="lnlinks" href="#hl-6-19">19</a>
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># upsample operation in the UNET</span>
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Downsample</span><span class="p">(</span><span class="n">hk</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_channels</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">conv</span> <span class="o">=</span> <span class="n">hk</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">output_channels</span><span class="o">=</span><span class="n">output_channels</span><span class="p">,</span> <span class="n">kernel_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl">  <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl"><span class="c1"># Downsample operation in the UNET</span>
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Upsample</span><span class="p">(</span><span class="n">hk</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_channels</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">conv</span> <span class="o">=</span> <span class="n">hk</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">output_channels</span><span class="o">=</span><span class="n">output_channels</span><span class="p">,</span> <span class="n">kernel_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;SAME&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl">  <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># scaling image to twice size</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s1">&#39;b h w c -&gt; b (a h) (aa w) c&#39;</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">aa</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><strong>Time Step Embeddings:</strong>
We will be using sinusoidal embeddings for time steps. This is following the <a href="/posts/diffusion-models/denoising-diffusion-models-2/#time-step-embedding" >discussion in the previous post.</a></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt" id="hl-7-1"><a class="lnlinks" href="#hl-7-1"> 1</a>
</span><span class="lnt" id="hl-7-2"><a class="lnlinks" href="#hl-7-2"> 2</a>
</span><span class="lnt" id="hl-7-3"><a class="lnlinks" href="#hl-7-3"> 3</a>
</span><span class="lnt" id="hl-7-4"><a class="lnlinks" href="#hl-7-4"> 4</a>
</span><span class="lnt" id="hl-7-5"><a class="lnlinks" href="#hl-7-5"> 5</a>
</span><span class="lnt" id="hl-7-6"><a class="lnlinks" href="#hl-7-6"> 6</a>
</span><span class="lnt" id="hl-7-7"><a class="lnlinks" href="#hl-7-7"> 7</a>
</span><span class="lnt" id="hl-7-8"><a class="lnlinks" href="#hl-7-8"> 8</a>
</span><span class="lnt" id="hl-7-9"><a class="lnlinks" href="#hl-7-9"> 9</a>
</span><span class="lnt" id="hl-7-10"><a class="lnlinks" href="#hl-7-10">10</a>
</span><span class="lnt" id="hl-7-11"><a class="lnlinks" href="#hl-7-11">11</a>
</span><span class="lnt" id="hl-7-12"><a class="lnlinks" href="#hl-7-12">12</a>
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">TimeEmbeddings</span><span class="p">(</span><span class="n">hk</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">half_dim</span> <span class="o">=</span> <span class="n">dim</span> <span class="o">//</span> <span class="mi">2</span>
</span></span><span class="line"><span class="cl">    <span class="n">embeddings</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">half_dim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">half_dim</span><span class="p">)</span> <span class="o">*</span> <span class="o">-</span><span class="n">embeddings</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">      <span class="n">embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span>
</span></span><span class="line"><span class="cl">      <span class="n">embeddings</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">timesteps</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">embeddings</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="n">embeddings</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">jnp</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">embeddings</span><span class="p">),</span> <span class="n">jnp</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">embeddings</span><span class="p">)])</span>
</span></span><span class="line"><span class="cl">      <span class="k">return</span> <span class="n">embeddings</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><strong>Conditional Labels:</strong>
EMNIST dataset has 62 labels, 26 characters in lowercase, 26 characters in uppercase, 10 numbers. We add another label to represent the masked label.
We use the Haiku Embed class to generate embedding vectors for these labels.
Labels are fused with the input as explained in the <a href="/posts/diffusion-models/denoising-diffusion-models-2/#guidance--classifier-free-guidance" >previous post</a>.
Instead of fusing label and time step information only at the start, we are fusing it with the input at every Block.</p>
<p><strong>Network Definition:</strong>
After convolution layers, I am using a <cite>BatchNorm<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></cite> layer, using the Haiku BatchNorm module to normalize the values across the batch. This is shown to improve the convergence of deep models.
Using BatchNorm complicates the implementation a bit since, BatchNorm layers need to maintain a buffer states for mean and variance of the activations.
<a href="https://youtu.be/l_3zj6HeWUE" target="_blank" >This video</a> from Yannic is an excellent introduction to the different kind of Normalizations that one can apply to speed up training.</p>
<p>The code below follows the U-net implementation in <a href="https://github.com/lucidrains/denoising-diffusion-pytorch/blob/main/denoising_diffusion_pytorch/denoising_diffusion_pytorch.py#L267" target="_blank" >LucidRains Diffusion model implementation</a>.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt" id="hl-8-1"><a class="lnlinks" href="#hl-8-1"> 1</a>
</span><span class="lnt" id="hl-8-2"><a class="lnlinks" href="#hl-8-2"> 2</a>
</span><span class="lnt" id="hl-8-3"><a class="lnlinks" href="#hl-8-3"> 3</a>
</span><span class="lnt" id="hl-8-4"><a class="lnlinks" href="#hl-8-4"> 4</a>
</span><span class="lnt" id="hl-8-5"><a class="lnlinks" href="#hl-8-5"> 5</a>
</span><span class="lnt" id="hl-8-6"><a class="lnlinks" href="#hl-8-6"> 6</a>
</span><span class="lnt" id="hl-8-7"><a class="lnlinks" href="#hl-8-7"> 7</a>
</span><span class="lnt" id="hl-8-8"><a class="lnlinks" href="#hl-8-8"> 8</a>
</span><span class="lnt" id="hl-8-9"><a class="lnlinks" href="#hl-8-9"> 9</a>
</span><span class="lnt" id="hl-8-10"><a class="lnlinks" href="#hl-8-10">10</a>
</span><span class="lnt" id="hl-8-11"><a class="lnlinks" href="#hl-8-11">11</a>
</span><span class="lnt" id="hl-8-12"><a class="lnlinks" href="#hl-8-12">12</a>
</span><span class="lnt" id="hl-8-13"><a class="lnlinks" href="#hl-8-13">13</a>
</span><span class="lnt" id="hl-8-14"><a class="lnlinks" href="#hl-8-14">14</a>
</span><span class="lnt" id="hl-8-15"><a class="lnlinks" href="#hl-8-15">15</a>
</span><span class="lnt" id="hl-8-16"><a class="lnlinks" href="#hl-8-16">16</a>
</span><span class="lnt" id="hl-8-17"><a class="lnlinks" href="#hl-8-17">17</a>
</span><span class="lnt" id="hl-8-18"><a class="lnlinks" href="#hl-8-18">18</a>
</span><span class="lnt" id="hl-8-19"><a class="lnlinks" href="#hl-8-19">19</a>
</span><span class="lnt" id="hl-8-20"><a class="lnlinks" href="#hl-8-20">20</a>
</span><span class="lnt" id="hl-8-21"><a class="lnlinks" href="#hl-8-21">21</a>
</span><span class="lnt" id="hl-8-22"><a class="lnlinks" href="#hl-8-22">22</a>
</span><span class="lnt" id="hl-8-23"><a class="lnlinks" href="#hl-8-23">23</a>
</span><span class="lnt" id="hl-8-24"><a class="lnlinks" href="#hl-8-24">24</a>
</span><span class="lnt" id="hl-8-25"><a class="lnlinks" href="#hl-8-25">25</a>
</span><span class="lnt" id="hl-8-26"><a class="lnlinks" href="#hl-8-26">26</a>
</span><span class="lnt" id="hl-8-27"><a class="lnlinks" href="#hl-8-27">27</a>
</span><span class="lnt" id="hl-8-28"><a class="lnlinks" href="#hl-8-28">28</a>
</span><span class="lnt" id="hl-8-29"><a class="lnlinks" href="#hl-8-29">29</a>
</span><span class="lnt" id="hl-8-30"><a class="lnlinks" href="#hl-8-30">30</a>
</span><span class="lnt" id="hl-8-31"><a class="lnlinks" href="#hl-8-31">31</a>
</span><span class="lnt" id="hl-8-32"><a class="lnlinks" href="#hl-8-32">32</a>
</span><span class="lnt" id="hl-8-33"><a class="lnlinks" href="#hl-8-33">33</a>
</span><span class="lnt" id="hl-8-34"><a class="lnlinks" href="#hl-8-34">34</a>
</span><span class="lnt" id="hl-8-35"><a class="lnlinks" href="#hl-8-35">35</a>
</span><span class="lnt" id="hl-8-36"><a class="lnlinks" href="#hl-8-36">36</a>
</span><span class="lnt" id="hl-8-37"><a class="lnlinks" href="#hl-8-37">37</a>
</span><span class="lnt" id="hl-8-38"><a class="lnlinks" href="#hl-8-38">38</a>
</span><span class="lnt" id="hl-8-39"><a class="lnlinks" href="#hl-8-39">39</a>
</span><span class="lnt" id="hl-8-40"><a class="lnlinks" href="#hl-8-40">40</a>
</span><span class="lnt" id="hl-8-41"><a class="lnlinks" href="#hl-8-41">41</a>
</span><span class="lnt" id="hl-8-42"><a class="lnlinks" href="#hl-8-42">42</a>
</span><span class="lnt" id="hl-8-43"><a class="lnlinks" href="#hl-8-43">43</a>
</span><span class="lnt" id="hl-8-44"><a class="lnlinks" href="#hl-8-44">44</a>
</span><span class="lnt" id="hl-8-45"><a class="lnlinks" href="#hl-8-45">45</a>
</span><span class="lnt" id="hl-8-46"><a class="lnlinks" href="#hl-8-46">46</a>
</span><span class="lnt" id="hl-8-47"><a class="lnlinks" href="#hl-8-47">47</a>
</span><span class="lnt" id="hl-8-48"><a class="lnlinks" href="#hl-8-48">48</a>
</span><span class="lnt" id="hl-8-49"><a class="lnlinks" href="#hl-8-49">49</a>
</span><span class="lnt" id="hl-8-50"><a class="lnlinks" href="#hl-8-50">50</a>
</span><span class="lnt" id="hl-8-51"><a class="lnlinks" href="#hl-8-51">51</a>
</span><span class="lnt" id="hl-8-52"><a class="lnlinks" href="#hl-8-52">52</a>
</span><span class="lnt" id="hl-8-53"><a class="lnlinks" href="#hl-8-53">53</a>
</span><span class="lnt" id="hl-8-54"><a class="lnlinks" href="#hl-8-54">54</a>
</span><span class="lnt" id="hl-8-55"><a class="lnlinks" href="#hl-8-55">55</a>
</span><span class="lnt" id="hl-8-56"><a class="lnlinks" href="#hl-8-56">56</a>
</span><span class="lnt" id="hl-8-57"><a class="lnlinks" href="#hl-8-57">57</a>
</span><span class="lnt" id="hl-8-58"><a class="lnlinks" href="#hl-8-58">58</a>
</span><span class="lnt" id="hl-8-59"><a class="lnlinks" href="#hl-8-59">59</a>
</span><span class="lnt" id="hl-8-60"><a class="lnlinks" href="#hl-8-60">60</a>
</span><span class="lnt" id="hl-8-61"><a class="lnlinks" href="#hl-8-61">61</a>
</span><span class="lnt" id="hl-8-62"><a class="lnlinks" href="#hl-8-62">62</a>
</span><span class="lnt" id="hl-8-63"><a class="lnlinks" href="#hl-8-63">63</a>
</span><span class="lnt" id="hl-8-64"><a class="lnlinks" href="#hl-8-64">64</a>
</span><span class="lnt" id="hl-8-65"><a class="lnlinks" href="#hl-8-65">65</a>
</span><span class="lnt" id="hl-8-66"><a class="lnlinks" href="#hl-8-66">66</a>
</span><span class="lnt" id="hl-8-67"><a class="lnlinks" href="#hl-8-67">67</a>
</span><span class="lnt" id="hl-8-68"><a class="lnlinks" href="#hl-8-68">68</a>
</span><span class="lnt" id="hl-8-69"><a class="lnlinks" href="#hl-8-69">69</a>
</span><span class="lnt" id="hl-8-70"><a class="lnlinks" href="#hl-8-70">70</a>
</span><span class="lnt" id="hl-8-71"><a class="lnlinks" href="#hl-8-71">71</a>
</span><span class="lnt" id="hl-8-72"><a class="lnlinks" href="#hl-8-72">72</a>
</span><span class="lnt" id="hl-8-73"><a class="lnlinks" href="#hl-8-73">73</a>
</span><span class="lnt" id="hl-8-74"><a class="lnlinks" href="#hl-8-74">74</a>
</span><span class="lnt" id="hl-8-75"><a class="lnlinks" href="#hl-8-75">75</a>
</span><span class="lnt" id="hl-8-76"><a class="lnlinks" href="#hl-8-76">76</a>
</span><span class="lnt" id="hl-8-77"><a class="lnlinks" href="#hl-8-77">77</a>
</span><span class="lnt" id="hl-8-78"><a class="lnlinks" href="#hl-8-78">78</a>
</span><span class="lnt" id="hl-8-79"><a class="lnlinks" href="#hl-8-79">79</a>
</span><span class="lnt" id="hl-8-80"><a class="lnlinks" href="#hl-8-80">80</a>
</span><span class="lnt" id="hl-8-81"><a class="lnlinks" href="#hl-8-81">81</a>
</span><span class="lnt" id="hl-8-82"><a class="lnlinks" href="#hl-8-82">82</a>
</span><span class="lnt" id="hl-8-83"><a class="lnlinks" href="#hl-8-83">83</a>
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># Unet class to predict noise from a given image</span>
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">UNet</span><span class="p">(</span><span class="n">hk</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">init_conv</span> <span class="o">=</span> <span class="n">hk</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">output_channels</span><span class="o">=</span><span class="mi">48</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;SAME&#39;</span><span class="p">,</span> <span class="n">with_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">hk</span><span class="o">.</span><span class="n">BatchNorm</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="n">decay_rate</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">silu</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">silu</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">block1</span> <span class="o">=</span> <span class="n">Block</span><span class="p">(</span><span class="n">output_channels</span><span class="o">=</span><span class="mi">48</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">downsample1</span> <span class="o">=</span> <span class="n">Downsample</span><span class="p">(</span><span class="mi">96</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">block2</span> <span class="o">=</span> <span class="n">Block</span><span class="p">(</span><span class="n">output_channels</span><span class="o">=</span><span class="mi">96</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">downsample2</span> <span class="o">=</span> <span class="n">Downsample</span><span class="p">(</span><span class="mi">192</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">middle_block</span> <span class="o">=</span> <span class="n">Block</span><span class="p">(</span><span class="n">output_channels</span><span class="o">=</span><span class="mi">192</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">upsample1</span> <span class="o">=</span> <span class="n">Upsample</span><span class="p">(</span><span class="mi">96</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">block3</span> <span class="o">=</span> <span class="n">Block</span><span class="p">(</span><span class="n">output_channels</span><span class="o">=</span><span class="mi">96</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">upsample2</span> <span class="o">=</span> <span class="n">Upsample</span><span class="p">(</span><span class="mi">48</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">block4</span> <span class="o">=</span> <span class="n">Block</span><span class="p">(</span><span class="n">output_channels</span><span class="o">=</span><span class="mi">48</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">hk</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">output_channels</span><span class="o">=</span><span class="mi">48</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;SAME&#39;</span><span class="p">,</span> <span class="n">with_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span> <span class="o">=</span> <span class="n">hk</span><span class="o">.</span><span class="n">BatchNorm</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="n">decay_rate</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">hk</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">output_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">kernel_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;SAME&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">time_mlp</span> <span class="o">=</span> <span class="n">hk</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
</span></span><span class="line"><span class="cl">      <span class="n">hk</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">      <span class="n">jax</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">gelu</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">      <span class="n">hk</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># conditional vectors encoding</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">embedding_vectors</span> <span class="o">=</span> <span class="n">hk</span><span class="o">.</span><span class="n">Embed</span><span class="p">(</span><span class="mi">10</span><span class="o">+</span><span class="mi">26</span><span class="o">+</span><span class="mi">26</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">63</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">timestep_embeddings</span> <span class="o">=</span> <span class="n">TimeEmbeddings</span><span class="p">(</span><span class="mi">96</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      
</span></span><span class="line"><span class="cl">  <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">,</span> <span class="n">cond</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">is_training</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">cond_embedding</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">    <span class="n">conditioning</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">timesteps</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">      <span class="n">timestep_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">timestep_embeddings</span><span class="p">(</span><span class="n">timesteps</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="n">conditioning</span> <span class="o">=</span> <span class="n">timestep_embeddings</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">cond</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">      <span class="n">label_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding_vectors</span><span class="p">(</span><span class="n">cond</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="n">conditioning</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">label_embeddings</span><span class="p">,</span> <span class="n">conditioning</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">conditioning</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>  
</span></span><span class="line"><span class="cl">      <span class="n">cond_embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">time_mlp</span><span class="p">(</span><span class="n">conditioning</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">silu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">init_conv</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">is_training</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="n">xx</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">b1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">block1</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">cond_embedding</span><span class="p">,</span> <span class="n">is_training</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">downsample1</span><span class="p">(</span><span class="n">b1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">b2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">block2</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">cond_embedding</span><span class="p">,</span> <span class="n">is_training</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">downsample2</span><span class="p">(</span><span class="n">b2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">upsample1</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">middle_block</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">cond_embedding</span><span class="p">,</span> <span class="n">is_training</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="n">b3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">block3</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">h</span><span class="p">,</span> <span class="n">b2</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span> <span class="n">cond_embedding</span><span class="p">,</span> <span class="n">is_training</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">upsample2</span><span class="p">(</span><span class="n">b3</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">b4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">block4</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">h</span><span class="p">,</span> <span class="n">b1</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span> <span class="n">cond_embedding</span><span class="p">,</span> <span class="n">is_training</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">silu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">norm1</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">xx</span><span class="p">,</span> <span class="n">b4</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">3</span><span class="p">)),</span> <span class="n">is_training</span><span class="p">)))</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">h</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Block</span><span class="p">(</span><span class="n">hk</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># a basic resnet style convolutional block</span>
</span></span><span class="line"><span class="cl">  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">padding</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">proj</span> <span class="o">=</span> <span class="n">hk</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">output_channels</span><span class="o">=</span><span class="n">output_channels</span><span class="p">,</span> <span class="n">kernel_shape</span><span class="o">=</span><span class="p">(</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;SAME&#39;</span><span class="p">,</span> <span class="n">with_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># using batch norm instead of layernorm as the batch sizes are large</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># orig: self.norm = hk.LayerNorm(axis=(-3, -2, -1), create_scale=True, create_offset=True)</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">hk</span><span class="o">.</span><span class="n">BatchNorm</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="n">decay_rate</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">silu</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">silu</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">hk</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">output_channels</span><span class="o">=</span><span class="n">output_channels</span><span class="p">,</span> <span class="n">kernel_shape</span><span class="o">=</span><span class="p">(</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;SAME&#39;</span><span class="p">,</span> <span class="n">with_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span> <span class="o">=</span> <span class="n">hk</span><span class="o">.</span><span class="n">BatchNorm</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="n">decay_rate</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">out_conv</span> <span class="o">=</span> <span class="n">hk</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">output_channels</span><span class="o">=</span><span class="n">output_channels</span><span class="p">,</span> <span class="n">kernel_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;SAME&#39;</span><span class="p">)</span> 
</span></span><span class="line"><span class="cl">    <span class="c1"># self.time_mlp = None</span>
</span></span><span class="line"><span class="cl">    <span class="n">dims</span> <span class="o">=</span> <span class="n">output_channels</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">time_mlp</span> <span class="o">=</span> <span class="n">hk</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
</span></span><span class="line"><span class="cl">      <span class="n">jax</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">silu</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">      <span class="n">hk</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dims</span><span class="o">*</span><span class="mi">2</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="p">])</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">  <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">timestep_embeddings</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">is_training</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">proj</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">is_training</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">timestep_embeddings</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">time_mlp</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">      <span class="n">time_embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">time_mlp</span><span class="p">(</span><span class="n">timestep_embeddings</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="n">time_embedding</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">rearrange</span><span class="p">(</span><span class="n">time_embedding</span><span class="p">,</span> <span class="s1">&#39;b c -&gt; b 1 1 c&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="n">shift</span><span class="p">,</span> <span class="n">scale</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">time_embedding</span><span class="p">,</span> <span class="n">indices_or_sections</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="n">h</span> <span class="o">=</span> <span class="n">shift</span> <span class="o">+</span> <span class="p">(</span><span class="n">scale</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">h</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">silu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">norm1</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">silu</span><span class="p">(</span><span class="n">h</span><span class="p">)),</span> <span class="n">is_training</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">h</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="training-code">Training Code:</h2>
<p>Loss function: I am using the Huber loss instead of using the L2 or the L1 loss. I would assume changing the loss function wouldn&rsquo;t impact the results significantly.</p>
<p>Note: the importance weight determines the importance of the sample for denoising. As noted in <cite>Improved Denoising Diffusion Probabilistic Models<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup></cite>, one idea to train diffusion models is to completely ignore this term. This helps the model training.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt" id="hl-9-1"><a class="lnlinks" href="#hl-9-1"> 1</a>
</span><span class="lnt" id="hl-9-2"><a class="lnlinks" href="#hl-9-2"> 2</a>
</span><span class="lnt" id="hl-9-3"><a class="lnlinks" href="#hl-9-3"> 3</a>
</span><span class="lnt" id="hl-9-4"><a class="lnlinks" href="#hl-9-4"> 4</a>
</span><span class="lnt" id="hl-9-5"><a class="lnlinks" href="#hl-9-5"> 5</a>
</span><span class="lnt" id="hl-9-6"><a class="lnlinks" href="#hl-9-6"> 6</a>
</span><span class="lnt" id="hl-9-7"><a class="lnlinks" href="#hl-9-7"> 7</a>
</span><span class="lnt" id="hl-9-8"><a class="lnlinks" href="#hl-9-8"> 8</a>
</span><span class="lnt" id="hl-9-9"><a class="lnlinks" href="#hl-9-9"> 9</a>
</span><span class="lnt" id="hl-9-10"><a class="lnlinks" href="#hl-9-10">10</a>
</span><span class="lnt" id="hl-9-11"><a class="lnlinks" href="#hl-9-11">11</a>
</span><span class="lnt" id="hl-9-12"><a class="lnlinks" href="#hl-9-12">12</a>
</span><span class="lnt" id="hl-9-13"><a class="lnlinks" href="#hl-9-13">13</a>
</span><span class="lnt" id="hl-9-14"><a class="lnlinks" href="#hl-9-14">14</a>
</span><span class="lnt" id="hl-9-15"><a class="lnlinks" href="#hl-9-15">15</a>
</span><span class="lnt" id="hl-9-16"><a class="lnlinks" href="#hl-9-16">16</a>
</span><span class="lnt" id="hl-9-17"><a class="lnlinks" href="#hl-9-17">17</a>
</span><span class="lnt" id="hl-9-18"><a class="lnlinks" href="#hl-9-18">18</a>
</span><span class="lnt" id="hl-9-19"><a class="lnlinks" href="#hl-9-19">19</a>
</span><span class="lnt" id="hl-9-20"><a class="lnlinks" href="#hl-9-20">20</a>
</span><span class="lnt" id="hl-9-21"><a class="lnlinks" href="#hl-9-21">21</a>
</span><span class="lnt" id="hl-9-22"><a class="lnlinks" href="#hl-9-22">22</a>
</span><span class="lnt" id="hl-9-23"><a class="lnlinks" href="#hl-9-23">23</a>
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># using jax.jit to speed up computation of the loss function</span>
</span></span><span class="line"><span class="cl"><span class="n">partial</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">jit</span><span class="p">,</span>  <span class="n">static_argnums</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,))</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">compute_loss</span><span class="p">(</span><span class="n">params</span><span class="p">:</span> <span class="n">hk</span><span class="o">.</span><span class="n">Params</span><span class="p">,</span> <span class="n">state</span><span class="p">:</span> <span class="n">hk</span><span class="o">.</span><span class="n">State</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">Batch</span><span class="p">,</span> <span class="n">is_energy_method</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">is_training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">hk</span><span class="o">.</span><span class="n">State</span><span class="p">]]:</span>
</span></span><span class="line"><span class="cl">  <span class="s2">&#34;&#34;&#34;Compute the loss of the network, including L2.&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">  <span class="n">x</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">timestep</span><span class="p">,</span> <span class="n">noise</span> <span class="o">=</span> <span class="n">batch</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># not capturing state as it is not needed; it should be internally updated and maintaing by haiku and doesn&#39;t need gradient updates </span>
</span></span><span class="line"><span class="cl">  <span class="n">pred_data</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">timestep</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">is_training</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl">  <span class="k">def</span> <span class="nf">error_func</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="n">imp_weight</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="c1"># 1/2 * (1/sigma_squared_q_t_corrected[timestep]) * ((betas[timestep])**2 / (variance[timestep] * alphas[timestep]))</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># loss on prediction</span>
</span></span><span class="line"><span class="cl">    <span class="n">loss_</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">imp_weight</span><span class="p">,</span> <span class="n">huber_loss</span><span class="p">(</span><span class="n">noise</span><span class="p">,</span> <span class="n">pred_data</span><span class="p">)))</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">loss_</span>
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl">  <span class="k">def</span> <span class="nf">energy_func</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="c1">## Energy function interpretation</span>
</span></span><span class="line"><span class="cl">    <span class="n">imp_weight</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="c1"># 1/2 * (1/sigma_squared_q_t_corrected[timestep]) * ((betas[timestep])**2 / (alphas[timestep]))</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># loss on prediction</span>
</span></span><span class="line"><span class="cl">    <span class="n">loss_</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">imp_weight</span><span class="p">,</span> <span class="n">huber_loss</span><span class="p">(</span><span class="n">pred_data</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">noise</span><span class="p">,</span> <span class="o">-</span><span class="n">sd</span><span class="p">[</span><span class="n">timestep</span><span class="p">]))))</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">loss_</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">  <span class="n">loss_</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">lax</span><span class="o">.</span><span class="n">cond</span><span class="p">(</span><span class="n">is_energy_method</span><span class="p">,</span> <span class="n">energy_func</span><span class="p">,</span> <span class="n">error_func</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="k">return</span> <span class="n">loss_</span><span class="p">,</span> <span class="p">(</span><span class="n">loss_</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><strong>Updating Model Weights:</strong></p>
<p>This is a typical code for any Neural Network training in Haiku/Optax and JAX. We are finding the gradient of the loss with respect to the parameters of the Neural Network using JAX and updating the weights using Optax.</p>
<p>Additionally, we are doing exponential updates to the parameters.<cite> Paper on Polyak averaging.<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup></cite></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt" id="hl-10-1"><a class="lnlinks" href="#hl-10-1"> 1</a>
</span><span class="lnt" id="hl-10-2"><a class="lnlinks" href="#hl-10-2"> 2</a>
</span><span class="lnt" id="hl-10-3"><a class="lnlinks" href="#hl-10-3"> 3</a>
</span><span class="lnt" id="hl-10-4"><a class="lnlinks" href="#hl-10-4"> 4</a>
</span><span class="lnt" id="hl-10-5"><a class="lnlinks" href="#hl-10-5"> 5</a>
</span><span class="lnt" id="hl-10-6"><a class="lnlinks" href="#hl-10-6"> 6</a>
</span><span class="lnt" id="hl-10-7"><a class="lnlinks" href="#hl-10-7"> 7</a>
</span><span class="lnt" id="hl-10-8"><a class="lnlinks" href="#hl-10-8"> 8</a>
</span><span class="lnt" id="hl-10-9"><a class="lnlinks" href="#hl-10-9"> 9</a>
</span><span class="lnt" id="hl-10-10"><a class="lnlinks" href="#hl-10-10">10</a>
</span><span class="lnt" id="hl-10-11"><a class="lnlinks" href="#hl-10-11">11</a>
</span><span class="lnt" id="hl-10-12"><a class="lnlinks" href="#hl-10-12">12</a>
</span><span class="lnt" id="hl-10-13"><a class="lnlinks" href="#hl-10-13">13</a>
</span><span class="lnt" id="hl-10-14"><a class="lnlinks" href="#hl-10-14">14</a>
</span><span class="lnt" id="hl-10-15"><a class="lnlinks" href="#hl-10-15">15</a>
</span><span class="lnt" id="hl-10-16"><a class="lnlinks" href="#hl-10-16">16</a>
</span><span class="lnt" id="hl-10-17"><a class="lnlinks" href="#hl-10-17">17</a>
</span><span class="lnt" id="hl-10-18"><a class="lnlinks" href="#hl-10-18">18</a>
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nd">@jax.jit</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">update</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">params</span><span class="p">:</span> <span class="n">hk</span><span class="o">.</span><span class="n">Params</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">state</span><span class="p">:</span> <span class="n">hk</span><span class="o">.</span><span class="n">State</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">opt_state</span><span class="p">:</span> <span class="n">optax</span><span class="o">.</span><span class="n">OptState</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">batch</span><span class="p">:</span> <span class="n">Batch</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">is_energy_method</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">jnp</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">hk</span><span class="o">.</span><span class="n">Params</span><span class="p">,</span> <span class="n">optax</span><span class="o">.</span><span class="n">OptState</span><span class="p">,</span> <span class="n">hk</span><span class="o">.</span><span class="n">State</span><span class="p">]:</span>
</span></span><span class="line"><span class="cl">  <span class="s2">&#34;&#34;&#34;Compute gradients and update the weights&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">  <span class="n">grads</span><span class="p">,</span> <span class="p">(</span><span class="n">loss_value</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span><span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">compute_loss</span><span class="p">,</span> <span class="n">has_aux</span><span class="o">=</span><span class="kc">True</span><span class="p">)(</span><span class="n">params</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">is_energy_method</span><span class="p">,</span> <span class="n">is_training</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">updates</span><span class="p">,</span> <span class="n">opt_state</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="n">opt_state</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">new_params</span> <span class="o">=</span> <span class="n">optax</span><span class="o">.</span><span class="n">apply_updates</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">updates</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="k">return</span> <span class="n">loss_value</span><span class="p">,</span> <span class="n">new_params</span><span class="p">,</span> <span class="n">opt_state</span><span class="p">,</span> <span class="n">state</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@jax.jit</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">ema_update</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">avg_params</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="s2">&#34;&#34;&#34;Incrementally update parameters via polyak averaging.&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># Polyak averaging tracks an (exponential moving) average of the past parameters of a model, for use at test/evaluation time.</span>
</span></span><span class="line"><span class="cl">  <span class="k">return</span> <span class="n">optax</span><span class="o">.</span><span class="n">incremental_update</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">avg_params</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mf">0.95</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="training-code-1">Training Code</h3>
<p>The training code is pretty straight-forward. Below, I have removed the code to checkpoint the different models.</p>
<p><strong>Pseudocode we are going for:</strong></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt" id="hl-11-1"><a class="lnlinks" href="#hl-11-1"> 1</a>
</span><span class="lnt" id="hl-11-2"><a class="lnlinks" href="#hl-11-2"> 2</a>
</span><span class="lnt" id="hl-11-3"><a class="lnlinks" href="#hl-11-3"> 3</a>
</span><span class="lnt" id="hl-11-4"><a class="lnlinks" href="#hl-11-4"> 4</a>
</span><span class="lnt" id="hl-11-5"><a class="lnlinks" href="#hl-11-5"> 5</a>
</span><span class="lnt" id="hl-11-6"><a class="lnlinks" href="#hl-11-6"> 6</a>
</span><span class="lnt" id="hl-11-7"><a class="lnlinks" href="#hl-11-7"> 7</a>
</span><span class="lnt" id="hl-11-8"><a class="lnlinks" href="#hl-11-8"> 8</a>
</span><span class="lnt" id="hl-11-9"><a class="lnlinks" href="#hl-11-9"> 9</a>
</span><span class="lnt" id="hl-11-10"><a class="lnlinks" href="#hl-11-10">10</a>
</span><span class="lnt" id="hl-11-11"><a class="lnlinks" href="#hl-11-11">11</a>
</span><span class="lnt" id="hl-11-12"><a class="lnlinks" href="#hl-11-12">12</a>
</span><span class="lnt" id="hl-11-13"><a class="lnlinks" href="#hl-11-13">13</a>
</span><span class="lnt" id="hl-11-14"><a class="lnlinks" href="#hl-11-14">14</a>
</span><span class="lnt" id="hl-11-15"><a class="lnlinks" href="#hl-11-15">15</a>
</span><span class="lnt" id="hl-11-16"><a class="lnlinks" href="#hl-11-16">16</a>
</span><span class="lnt" id="hl-11-17"><a class="lnlinks" href="#hl-11-17">17</a>
</span><span class="lnt" id="hl-11-18"><a class="lnlinks" href="#hl-11-18">18</a>
</span><span class="lnt" id="hl-11-19"><a class="lnlinks" href="#hl-11-19">19</a>
</span><span class="lnt" id="hl-11-20"><a class="lnlinks" href="#hl-11-20">20</a>
</span><span class="lnt" id="hl-11-21"><a class="lnlinks" href="#hl-11-21">21</a>
</span><span class="lnt" id="hl-11-22"><a class="lnlinks" href="#hl-11-22">22</a>
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">diffusion</span><span class="p">(</span><span class="n">x_0</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">	<span class="n">code</span> <span class="n">to</span> <span class="n">add</span> <span class="n">noise</span> <span class="n">to</span> <span class="n">x_0</span>
</span></span><span class="line"><span class="cl">	<span class="k">return</span> <span class="n">x_i</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">training</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">	<span class="k">for</span> <span class="n">loop</span> <span class="n">until</span> <span class="n">convergence</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">		<span class="n">pick</span> <span class="n">an</span> <span class="n">image</span> <span class="n">x_0</span> <span class="kn">from</span> <span class="nn">X</span> <span class="p">(</span><span class="n">batch</span> <span class="n">of</span> <span class="n">images</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">		<span class="n">sample</span> <span class="n">t</span> <span class="kn">from</span> <span class="mi">1</span> <span class="n">to</span> <span class="n">T</span>
</span></span><span class="line"><span class="cl">		<span class="n">x_t</span> <span class="o">=</span> <span class="n">diffusion_step</span><span class="p">(</span><span class="n">x_0</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">		<span class="n">x_hat_t</span> <span class="o">=</span> <span class="n">NN</span><span class="p">(</span><span class="n">x_t</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>  <span class="c1"># y is the label</span>
</span></span><span class="line"><span class="cl">		<span class="n">loss_</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">x_0</span><span class="p">,</span> <span class="n">x_hat_t</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">		<span class="n">update</span><span class="p">(</span><span class="n">NN</span><span class="p">,</span> <span class="n">grad</span><span class="p">(</span><span class="n">loss_</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># generating new data points through denoising steps</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">generate_new_data</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">	<span class="n">sample</span> <span class="n">x_T</span> <span class="kn">from</span> <span class="nn">N</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">I</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">		<span class="c1"># denoising step</span>
</span></span><span class="line"><span class="cl">		<span class="n">x_hat_t</span> <span class="o">=</span> <span class="n">NN</span><span class="p">(</span><span class="n">x_t</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>  <span class="c1"># y is the desired label </span>
</span></span><span class="line"><span class="cl">		<span class="c1"># get x_{t-1}</span>
</span></span><span class="line"><span class="cl">		<span class="n">x_</span><span class="p">{</span><span class="n">t</span><span class="o">-</span><span class="mi">1</span><span class="p">}</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">x_hat_t</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span> <span class="c1"># refer EQ - 12</span>
</span></span><span class="line"><span class="cl">	<span class="n">x_hat_0</span> <span class="o">=</span> <span class="n">x_0</span>  
</span></span></code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt" id="hl-12-1"><a class="lnlinks" href="#hl-12-1"> 1</a>
</span><span class="lnt" id="hl-12-2"><a class="lnlinks" href="#hl-12-2"> 2</a>
</span><span class="lnt" id="hl-12-3"><a class="lnlinks" href="#hl-12-3"> 3</a>
</span><span class="lnt" id="hl-12-4"><a class="lnlinks" href="#hl-12-4"> 4</a>
</span><span class="lnt" id="hl-12-5"><a class="lnlinks" href="#hl-12-5"> 5</a>
</span><span class="lnt" id="hl-12-6"><a class="lnlinks" href="#hl-12-6"> 6</a>
</span><span class="lnt" id="hl-12-7"><a class="lnlinks" href="#hl-12-7"> 7</a>
</span><span class="lnt" id="hl-12-8"><a class="lnlinks" href="#hl-12-8"> 8</a>
</span><span class="lnt" id="hl-12-9"><a class="lnlinks" href="#hl-12-9"> 9</a>
</span><span class="lnt" id="hl-12-10"><a class="lnlinks" href="#hl-12-10">10</a>
</span><span class="lnt" id="hl-12-11"><a class="lnlinks" href="#hl-12-11">11</a>
</span><span class="lnt" id="hl-12-12"><a class="lnlinks" href="#hl-12-12">12</a>
</span><span class="lnt" id="hl-12-13"><a class="lnlinks" href="#hl-12-13">13</a>
</span><span class="lnt" id="hl-12-14"><a class="lnlinks" href="#hl-12-14">14</a>
</span><span class="lnt" id="hl-12-15"><a class="lnlinks" href="#hl-12-15">15</a>
</span><span class="lnt" id="hl-12-16"><a class="lnlinks" href="#hl-12-16">16</a>
</span><span class="lnt" id="hl-12-17"><a class="lnlinks" href="#hl-12-17">17</a>
</span><span class="lnt" id="hl-12-18"><a class="lnlinks" href="#hl-12-18">18</a>
</span><span class="lnt" id="hl-12-19"><a class="lnlinks" href="#hl-12-19">19</a>
</span><span class="lnt" id="hl-12-20"><a class="lnlinks" href="#hl-12-20">20</a>
</span><span class="lnt" id="hl-12-21"><a class="lnlinks" href="#hl-12-21">21</a>
</span><span class="lnt" id="hl-12-22"><a class="lnlinks" href="#hl-12-22">22</a>
</span><span class="lnt" id="hl-12-23"><a class="lnlinks" href="#hl-12-23">23</a>
</span><span class="lnt" id="hl-12-24"><a class="lnlinks" href="#hl-12-24">24</a>
</span><span class="lnt" id="hl-12-25"><a class="lnlinks" href="#hl-12-25">25</a>
</span><span class="lnt" id="hl-12-26"><a class="lnlinks" href="#hl-12-26">26</a>
</span><span class="lnt" id="hl-12-27"><a class="lnlinks" href="#hl-12-27">27</a>
</span><span class="lnt" id="hl-12-28"><a class="lnlinks" href="#hl-12-28">28</a>
</span><span class="lnt" id="hl-12-29"><a class="lnlinks" href="#hl-12-29">29</a>
</span><span class="lnt" id="hl-12-30"><a class="lnlinks" href="#hl-12-30">30</a>
</span><span class="lnt" id="hl-12-31"><a class="lnlinks" href="#hl-12-31">31</a>
</span><span class="lnt" id="hl-12-32"><a class="lnlinks" href="#hl-12-32">32</a>
</span><span class="lnt" id="hl-12-33"><a class="lnlinks" href="#hl-12-33">33</a>
</span><span class="lnt" id="hl-12-34"><a class="lnlinks" href="#hl-12-34">34</a>
</span><span class="lnt" id="hl-12-35"><a class="lnlinks" href="#hl-12-35">35</a>
</span><span class="lnt" id="hl-12-36"><a class="lnlinks" href="#hl-12-36">36</a>
</span><span class="lnt" id="hl-12-37"><a class="lnlinks" href="#hl-12-37">37</a>
</span><span class="lnt" id="hl-12-38"><a class="lnlinks" href="#hl-12-38">38</a>
</span><span class="lnt" id="hl-12-39"><a class="lnlinks" href="#hl-12-39">39</a>
</span><span class="lnt" id="hl-12-40"><a class="lnlinks" href="#hl-12-40">40</a>
</span><span class="lnt" id="hl-12-41"><a class="lnlinks" href="#hl-12-41">41</a>
</span><span class="lnt" id="hl-12-42"><a class="lnlinks" href="#hl-12-42">42</a>
</span><span class="lnt" id="hl-12-43"><a class="lnlinks" href="#hl-12-43">43</a>
</span><span class="lnt" id="hl-12-44"><a class="lnlinks" href="#hl-12-44">44</a>
</span><span class="lnt" id="hl-12-45"><a class="lnlinks" href="#hl-12-45">45</a>
</span><span class="lnt" id="hl-12-46"><a class="lnlinks" href="#hl-12-46">46</a>
</span><span class="lnt" id="hl-12-47"><a class="lnlinks" href="#hl-12-47">47</a>
</span><span class="lnt" id="hl-12-48"><a class="lnlinks" href="#hl-12-48">48</a>
</span><span class="lnt" id="hl-12-49"><a class="lnlinks" href="#hl-12-49">49</a>
</span><span class="lnt" id="hl-12-50"><a class="lnlinks" href="#hl-12-50">50</a>
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># initialization</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">is_training</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="n">unet</span> <span class="o">=</span> <span class="n">UNet</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">  <span class="k">return</span> <span class="n">unet</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">is_training</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">f_t</span> <span class="o">=</span> <span class="n">hk</span><span class="o">.</span><span class="n">transform_with_state</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">net</span> <span class="o">=</span> <span class="n">hk</span><span class="o">.</span><span class="n">without_apply_rng</span><span class="p">(</span><span class="n">f_t</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">params</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">rng</span><span class="p">,</span> <span class="n">image</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">:</span><span class="n">batch_size</span><span class="p">],</span> <span class="n">timesteps_</span><span class="p">,</span> <span class="n">label</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">:</span><span class="n">batch_size</span><span class="p">],</span> <span class="n">is_training</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">opt</span> <span class="o">=</span> <span class="n">optax</span><span class="o">.</span><span class="n">adam</span><span class="p">(</span><span class="mf">1e-3</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">avg_params</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">opt_state</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">batches_iter</span> <span class="o">=</span> <span class="mi">10000</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># maintaining a batch on which we will measure loss; we will save the model based on performance on this batch</span>
</span></span><span class="line"><span class="cl"><span class="n">one_timestep</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">mod</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">timesteps</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">train</span> <span class="o">=</span> <span class="n">create_input_iter</span><span class="p">(</span><span class="n">train_ds</span><span class="p">)</span> 
</span></span><span class="line"><span class="cl"><span class="n">data_in_batch_</span><span class="p">,</span> <span class="n">label_</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">data_in_batch_</span> <span class="o">=</span> <span class="n">data_in_batch_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">label_</span> <span class="o">=</span> <span class="n">label_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">data_noisy_temp_</span><span class="p">,</span> <span class="n">noise_temp_</span> <span class="o">=</span> <span class="n">get_noisy</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">data_in_batch_</span><span class="p">,</span> <span class="n">one_timestep</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># main method for training</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">opt_state</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">avg_params</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">energy_method</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">best_loss</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">float_info</span><span class="o">.</span><span class="n">max</span> <span class="c1"># initialization   </span>
</span></span><span class="line"><span class="cl">	<span class="n">unique_key</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">fold_in</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	
</span></span><span class="line"><span class="cl">	<span class="c1"># same subkey being used for noise sampling, as it doesn&#39;t matter :)</span>
</span></span><span class="line"><span class="cl">	<span class="n">_</span><span class="p">,</span> <span class="o">*</span><span class="n">timestep_subkeys</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">unique_key</span><span class="p">,</span> <span class="n">batches_iter</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	
</span></span><span class="line"><span class="cl">	<span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">	<span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">batches_iter</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">		<span class="n">data_in_batch</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">		<span class="n">data_in_batch</span> <span class="o">=</span> <span class="n">data_in_batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">		<span class="n">label</span> <span class="o">=</span> <span class="n">label</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">		<span class="n">idx</span> <span class="o">=</span> <span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="n">timestep_subkeys</span><span class="p">[</span><span class="n">iteration</span><span class="p">],</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="o">*</span> <span class="p">(</span><span class="n">timesteps</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">		<span class="n">idx</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">rearrange</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="s1">&#39;a b -&gt; (a b)&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">		<span class="n">timestep</span> <span class="o">=</span> <span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">		<span class="n">data_noisy</span><span class="p">,</span> <span class="n">noise</span> <span class="o">=</span> <span class="n">get_noisy</span><span class="p">(</span><span class="n">timestep_subkeys</span><span class="p">[</span><span class="n">iteration</span><span class="p">],</span> <span class="n">data_in_batch</span><span class="p">,</span> <span class="n">timestep</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">		<span class="c1"># todo: call gradient update function here</span>
</span></span><span class="line"><span class="cl">		<span class="n">loss_value</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">opt_state</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">update</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">opt_state</span><span class="p">,</span> <span class="p">[</span><span class="n">data_noisy</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">timestep</span><span class="p">,</span> <span class="n">noise</span><span class="p">],</span> <span class="n">energy_method</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">		<span class="n">avg_params</span> <span class="o">=</span> <span class="n">ema_update</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">avg_params</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">		                
</span></span><span class="line"><span class="cl">		<span class="c1">## evaluating noise on a fixed timestep to calculate best model</span>
</span></span><span class="line"><span class="cl">		<span class="n">loss_temp</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">device_get</span><span class="p">(</span><span class="n">compute_loss</span><span class="p">(</span><span class="n">avg_params</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="p">[</span><span class="n">data_noisy_temp_</span><span class="p">,</span> <span class="n">label_</span><span class="p">,</span> <span class="n">one_timestep</span><span class="p">,</span> <span class="n">noise_temp_</span><span class="p">],</span> <span class="n">energy_method</span><span class="p">,</span> <span class="n">is_training</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">		<span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss_temp</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">	
</span></span><span class="line"><span class="cl">		<span class="k">if</span> <span class="n">loss_temp</span> <span class="o">&lt;</span> <span class="n">best_loss</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">			<span class="n">best_loss</span> <span class="o">=</span> <span class="n">loss_temp</span>
</span></span><span class="line"><span class="cl">			<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;saving iteration: </span><span class="si">{</span><span class="n">iteration</span><span class="si">}</span><span class="s2"> loss: </span><span class="si">{</span><span class="n">best_loss</span><span class="si">:</span><span class="s2">&gt;7f</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">return</span> <span class="n">data_noisy</span><span class="p">,</span> <span class="n">data_in_batch</span><span class="p">,</span> <span class="n">timestep</span><span class="p">,</span> <span class="n">losses</span><span class="p">,</span> <span class="n">avg_params</span><span class="p">,</span> <span class="n">state</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="generating-conditional-samples">Generating Conditional Samples</h2>
<h3 id="using-all-time-steps-for-generation">Using all time steps for generation</h3>
<p>Code for generating samples is below. We start off with random samples from a Standard Gaussian Distribution and follow steps as described <a href="/posts/diffusion-models/denoising-diffusion-models-1/#2-denoising-step" >here</a>.
We will be using the naïve version of classifier guidance described <a href="/posts/diffusion-models/denoising-diffusion-models-2/#guidance--classifier-free-guidance" >here</a>.</p>
<ul>
<li>Start by sampling a random image from a Sandard Gaussian distribution at time step $T$.</li>
<li>Get an estimate of the error added to the input image from the U-net.</li>
<li>Use the equation 5, in the link above, to calculate the image at the previous time step $T-1$.</li>
<li>Repeat until time step 1.</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt" id="hl-13-1"><a class="lnlinks" href="#hl-13-1">1</a>
</span><span class="lnt" id="hl-13-2"><a class="lnlinks" href="#hl-13-2">2</a>
</span><span class="lnt" id="hl-13-3"><a class="lnlinks" href="#hl-13-3">3</a>
</span><span class="lnt" id="hl-13-4"><a class="lnlinks" href="#hl-13-4">4</a>
</span><span class="lnt" id="hl-13-5"><a class="lnlinks" href="#hl-13-5">5</a>
</span><span class="lnt" id="hl-13-6"><a class="lnlinks" href="#hl-13-6">6</a>
</span><span class="lnt" id="hl-13-7"><a class="lnlinks" href="#hl-13-7">7</a>
</span><span class="lnt" id="hl-13-8"><a class="lnlinks" href="#hl-13-8">8</a>
</span><span class="lnt" id="hl-13-9"><a class="lnlinks" href="#hl-13-9">9</a>
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># defining useful variables</span>
</span></span><span class="line"><span class="cl"><span class="n">alphas_prev_</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">alphas_</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="s2">&#34;constant&#34;</span><span class="p">,</span> <span class="n">constant_values</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">sigma_squared_q_t</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alphas</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alphas_</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alphas_prev_</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">log_sigma_squared_q_t</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">alphas</span><span class="p">)</span> <span class="o">+</span> <span class="n">jnp</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">alphas_</span><span class="p">)</span> <span class="o">-</span> <span class="n">jnp</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">alphas_prev_</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">sigma_squared_q_t_corrected</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_sigma_squared_q_t</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">key</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">mean_coeff_1</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">alphas</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alphas_prev_</span><span class="p">)</span> <span class="o">/</span> <span class="n">variance</span>
</span></span><span class="line"><span class="cl"><span class="n">mean_coeff_2</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">alphas_prev_</span><span class="p">)</span> <span class="o">*</span> <span class="n">betas</span> <span class="o">/</span> <span class="n">variance</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><strong>Generate Samples:</strong></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt" id="hl-14-1"><a class="lnlinks" href="#hl-14-1"> 1</a>
</span><span class="lnt" id="hl-14-2"><a class="lnlinks" href="#hl-14-2"> 2</a>
</span><span class="lnt" id="hl-14-3"><a class="lnlinks" href="#hl-14-3"> 3</a>
</span><span class="lnt" id="hl-14-4"><a class="lnlinks" href="#hl-14-4"> 4</a>
</span><span class="lnt" id="hl-14-5"><a class="lnlinks" href="#hl-14-5"> 5</a>
</span><span class="lnt" id="hl-14-6"><a class="lnlinks" href="#hl-14-6"> 6</a>
</span><span class="lnt" id="hl-14-7"><a class="lnlinks" href="#hl-14-7"> 7</a>
</span><span class="lnt" id="hl-14-8"><a class="lnlinks" href="#hl-14-8"> 8</a>
</span><span class="lnt" id="hl-14-9"><a class="lnlinks" href="#hl-14-9"> 9</a>
</span><span class="lnt" id="hl-14-10"><a class="lnlinks" href="#hl-14-10">10</a>
</span><span class="lnt" id="hl-14-11"><a class="lnlinks" href="#hl-14-11">11</a>
</span><span class="lnt" id="hl-14-12"><a class="lnlinks" href="#hl-14-12">12</a>
</span><span class="lnt" id="hl-14-13"><a class="lnlinks" href="#hl-14-13">13</a>
</span><span class="lnt" id="hl-14-14"><a class="lnlinks" href="#hl-14-14">14</a>
</span><span class="lnt" id="hl-14-15"><a class="lnlinks" href="#hl-14-15">15</a>
</span><span class="lnt" id="hl-14-16"><a class="lnlinks" href="#hl-14-16">16</a>
</span><span class="lnt" id="hl-14-17"><a class="lnlinks" href="#hl-14-17">17</a>
</span><span class="lnt" id="hl-14-18"><a class="lnlinks" href="#hl-14-18">18</a>
</span><span class="lnt" id="hl-14-19"><a class="lnlinks" href="#hl-14-19">19</a>
</span><span class="lnt" id="hl-14-20"><a class="lnlinks" href="#hl-14-20">20</a>
</span><span class="lnt" id="hl-14-21"><a class="lnlinks" href="#hl-14-21">21</a>
</span><span class="lnt" id="hl-14-22"><a class="lnlinks" href="#hl-14-22">22</a>
</span><span class="lnt" id="hl-14-23"><a class="lnlinks" href="#hl-14-23">23</a>
</span><span class="lnt" id="hl-14-24"><a class="lnlinks" href="#hl-14-24">24</a>
</span><span class="lnt" id="hl-14-25"><a class="lnlinks" href="#hl-14-25">25</a>
</span><span class="lnt" id="hl-14-26"><a class="lnlinks" href="#hl-14-26">26</a>
</span><span class="lnt" id="hl-14-27"><a class="lnlinks" href="#hl-14-27">27</a>
</span><span class="lnt" id="hl-14-28"><a class="lnlinks" href="#hl-14-28">28</a>
</span><span class="lnt" id="hl-14-29"><a class="lnlinks" href="#hl-14-29">29</a>
</span><span class="lnt" id="hl-14-30"><a class="lnlinks" href="#hl-14-30">30</a>
</span><span class="lnt" id="hl-14-31"><a class="lnlinks" href="#hl-14-31">31</a>
</span><span class="lnt" id="hl-14-32"><a class="lnlinks" href="#hl-14-32">32</a>
</span><span class="lnt" id="hl-14-33"><a class="lnlinks" href="#hl-14-33">33</a>
</span><span class="lnt" id="hl-14-34"><a class="lnlinks" href="#hl-14-34">34</a>
</span><span class="lnt" id="hl-14-35"><a class="lnlinks" href="#hl-14-35">35</a>
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">random</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">generate_data</span><span class="p">(</span><span class="n">avg_params</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">energy_method</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">clipped_version</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">batch_size_generation</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">unique_key</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">fold_in</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="n">_</span><span class="p">,</span> <span class="n">subkey</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">unique_key</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">_</span><span class="p">,</span> <span class="o">*</span><span class="n">subkeys</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">unique_key</span><span class="p">,</span> <span class="n">timesteps</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># need to generate new keys everytime</span>
</span></span><span class="line"><span class="cl">    <span class="n">data_noisy</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">subkey</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size_generation</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">      
</span></span><span class="line"><span class="cl">    <span class="n">data_in_batch</span> <span class="o">=</span> <span class="n">data_noisy</span>
</span></span><span class="line"><span class="cl">    <span class="n">datas</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">    <span class="n">datas</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">device_get</span><span class="p">(</span><span class="n">data_noisy</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">timesteps</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">timestep</span> <span class="o">=</span> <span class="n">timesteps</span><span class="o">-</span><span class="n">t</span>
</span></span><span class="line"><span class="cl">        <span class="n">t_repeated</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">timestep</span><span class="p">]),</span> <span class="n">batch_size_generation</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># data_stacked = torch.vstack([data_in_batch, labelled_values])</span>
</span></span><span class="line"><span class="cl">        <span class="n">pred_data</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">avg_params</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">data_in_batch</span><span class="p">,</span> <span class="n">t_repeated</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">is_training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">		<span class="c1"># clipping an improvement as recommended in https://github.com/hojonathanho/diffusion/blob/1e0dceb3b3495bbe19116a5e1b3596cd0706c543/diffusion_tf/diffusion_utils.py#L171</span>
</span></span><span class="line"><span class="cl">		<span class="c1"># this helps in improving the samples generated as it keeps the random variables in the range of 0 to +1</span>
</span></span><span class="line"><span class="cl">		<span class="n">x_reconstructed</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">data_in_batch</span><span class="p">,</span> <span class="n">pred_data</span> <span class="o">*</span> <span class="n">sd</span><span class="p">[</span><span class="n">timestep</span><span class="p">])</span><span class="o">/</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">alphas_</span><span class="p">[</span><span class="n">timestep</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">		<span class="k">if</span> <span class="n">timestep</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">			<span class="n">x_reconstructed</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">x_reconstructed</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">		<span class="n">mean_data_1</span> <span class="o">=</span> <span class="n">data_in_batch</span> <span class="o">*</span> <span class="n">mean_coeff_1</span><span class="p">[</span><span class="n">timestep</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">		<span class="n">mean_data_2</span> <span class="o">=</span> <span class="n">x_reconstructed</span> <span class="o">*</span> <span class="n">mean_coeff_2</span><span class="p">[</span><span class="n">timestep</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">		<span class="n">mean_data</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">mean_data_1</span><span class="p">,</span> <span class="n">mean_data_2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">posterior_data</span> <span class="o">=</span> <span class="n">posterior_variance_corrected</span><span class="p">[</span><span class="n">timestep</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">data_noisy</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">subkeys</span><span class="p">[</span><span class="n">t</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size_generation</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="n">data_in_batch</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">mean_data</span><span class="p">,</span>  <span class="n">jnp</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">posterior_data</span><span class="p">)</span> <span class="o">*</span> <span class="n">data_noisy</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">datas</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">device_get</span><span class="p">(</span><span class="n">data_in_batch</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">datas</span><span class="p">,</span> <span class="n">data_in_batch</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="striding-reducing-steps-needed-for-generation">Striding: Reducing steps needed for Generation</h3>
<p>We could reduce the number of steps needed for generation. One of the popular approaches to do this is by using <em>Time Step Striding</em>.</p>
<p>Instead of moving stepsone at a time from $T$ to 1, <code>range(T, 1, -1)</code>, we will move $s$ steps at a time, <code>range(T, 1, -s)</code>. Doing this will speed up generation of new samples from the model by s times. I have been able to produce good quality samples with $s$ set to 5.</p>
<p>We just need to make minor adjustments to the variables we created so that the maths still works.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt" id="hl-15-1"><a class="lnlinks" href="#hl-15-1"> 1</a>
</span><span class="lnt" id="hl-15-2"><a class="lnlinks" href="#hl-15-2"> 2</a>
</span><span class="lnt" id="hl-15-3"><a class="lnlinks" href="#hl-15-3"> 3</a>
</span><span class="lnt" id="hl-15-4"><a class="lnlinks" href="#hl-15-4"> 4</a>
</span><span class="lnt" id="hl-15-5"><a class="lnlinks" href="#hl-15-5"> 5</a>
</span><span class="lnt" id="hl-15-6"><a class="lnlinks" href="#hl-15-6"> 6</a>
</span><span class="lnt" id="hl-15-7"><a class="lnlinks" href="#hl-15-7"> 7</a>
</span><span class="lnt" id="hl-15-8"><a class="lnlinks" href="#hl-15-8"> 8</a>
</span><span class="lnt" id="hl-15-9"><a class="lnlinks" href="#hl-15-9"> 9</a>
</span><span class="lnt" id="hl-15-10"><a class="lnlinks" href="#hl-15-10">10</a>
</span><span class="lnt" id="hl-15-11"><a class="lnlinks" href="#hl-15-11">11</a>
</span><span class="lnt" id="hl-15-12"><a class="lnlinks" href="#hl-15-12">12</a>
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">strided_schedule</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span> <span class="o">+</span> <span class="p">[</span><span class="n">timesteps</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">alphas_strided_</span> <span class="o">=</span> <span class="n">alphas_</span><span class="p">[</span><span class="n">strided_schedule</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">alphas_prev_strided_</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">alphas_strided_</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="s2">&#34;constant&#34;</span><span class="p">,</span> <span class="n">constant_values</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">betas_strided</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">alphas_strided_</span><span class="o">/</span><span class="n">alphas_prev_strided_</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">posterior_variance_new_schedule</span> <span class="o">=</span> <span class="n">betas_strided</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alphas_prev_strided_</span><span class="p">)</span><span class="o">/</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">alphas_strided_</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">log_posterior_variance</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">posterior_variance_new_schedule</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">posterior_variance_new_schedule</span><span class="p">[</span><span class="mi">1</span><span class="p">:]]))</span>
</span></span><span class="line"><span class="cl"><span class="n">posterior_variance_new_schedule_corrected</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_posterior_variance</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">mean_coeff_1_strided</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">betas_strided</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alphas_prev_strided_</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alphas_strided_</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">mean_coeff_2_strided</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">alphas_prev_strided_</span><span class="p">)</span> <span class="o">*</span> <span class="n">betas_strided</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alphas_strided_</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><strong>Generate Samples:</strong></p>
<p>The code to generate samples is pretty similar, now we need to use the strided variables defined above.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt" id="hl-16-1"><a class="lnlinks" href="#hl-16-1"> 1</a>
</span><span class="lnt" id="hl-16-2"><a class="lnlinks" href="#hl-16-2"> 2</a>
</span><span class="lnt" id="hl-16-3"><a class="lnlinks" href="#hl-16-3"> 3</a>
</span><span class="lnt" id="hl-16-4"><a class="lnlinks" href="#hl-16-4"> 4</a>
</span><span class="lnt" id="hl-16-5"><a class="lnlinks" href="#hl-16-5"> 5</a>
</span><span class="lnt" id="hl-16-6"><a class="lnlinks" href="#hl-16-6"> 6</a>
</span><span class="lnt" id="hl-16-7"><a class="lnlinks" href="#hl-16-7"> 7</a>
</span><span class="lnt" id="hl-16-8"><a class="lnlinks" href="#hl-16-8"> 8</a>
</span><span class="lnt" id="hl-16-9"><a class="lnlinks" href="#hl-16-9"> 9</a>
</span><span class="lnt" id="hl-16-10"><a class="lnlinks" href="#hl-16-10">10</a>
</span><span class="lnt" id="hl-16-11"><a class="lnlinks" href="#hl-16-11">11</a>
</span><span class="lnt" id="hl-16-12"><a class="lnlinks" href="#hl-16-12">12</a>
</span><span class="lnt" id="hl-16-13"><a class="lnlinks" href="#hl-16-13">13</a>
</span><span class="lnt" id="hl-16-14"><a class="lnlinks" href="#hl-16-14">14</a>
</span><span class="lnt" id="hl-16-15"><a class="lnlinks" href="#hl-16-15">15</a>
</span><span class="lnt" id="hl-16-16"><a class="lnlinks" href="#hl-16-16">16</a>
</span><span class="lnt" id="hl-16-17"><a class="lnlinks" href="#hl-16-17">17</a>
</span><span class="lnt" id="hl-16-18"><a class="lnlinks" href="#hl-16-18">18</a>
</span><span class="lnt" id="hl-16-19"><a class="lnlinks" href="#hl-16-19">19</a>
</span><span class="lnt" id="hl-16-20"><a class="lnlinks" href="#hl-16-20">20</a>
</span><span class="lnt" id="hl-16-21"><a class="lnlinks" href="#hl-16-21">21</a>
</span><span class="lnt" id="hl-16-22"><a class="lnlinks" href="#hl-16-22">22</a>
</span><span class="lnt" id="hl-16-23"><a class="lnlinks" href="#hl-16-23">23</a>
</span><span class="lnt" id="hl-16-24"><a class="lnlinks" href="#hl-16-24">24</a>
</span><span class="lnt" id="hl-16-25"><a class="lnlinks" href="#hl-16-25">25</a>
</span><span class="lnt" id="hl-16-26"><a class="lnlinks" href="#hl-16-26">26</a>
</span><span class="lnt" id="hl-16-27"><a class="lnlinks" href="#hl-16-27">27</a>
</span><span class="lnt" id="hl-16-28"><a class="lnlinks" href="#hl-16-28">28</a>
</span><span class="lnt" id="hl-16-29"><a class="lnlinks" href="#hl-16-29">29</a>
</span><span class="lnt" id="hl-16-30"><a class="lnlinks" href="#hl-16-30">30</a>
</span><span class="lnt" id="hl-16-31"><a class="lnlinks" href="#hl-16-31">31</a>
</span><span class="lnt" id="hl-16-32"><a class="lnlinks" href="#hl-16-32">32</a>
</span><span class="lnt" id="hl-16-33"><a class="lnlinks" href="#hl-16-33">33</a>
</span><span class="lnt" id="hl-16-34"><a class="lnlinks" href="#hl-16-34">34</a>
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">random</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">generate_data_strided</span><span class="p">(</span><span class="n">avg_params</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">energy_method</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">clipped_version</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">batch_size_generation</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">unique_key</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">fold_in</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="n">_</span><span class="p">,</span> <span class="n">subkey</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">unique_key</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">_</span><span class="p">,</span> <span class="o">*</span><span class="n">subkeys</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">unique_key</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">strided_schedule</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="n">data_noisy</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">subkey</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size_generation</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">          
</span></span><span class="line"><span class="cl">    <span class="n">data_in_batch</span> <span class="o">=</span> <span class="n">data_noisy</span>
</span></span><span class="line"><span class="cl">	<span class="n">datas</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">    <span class="n">datas</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">device_get</span><span class="p">(</span><span class="n">data_noisy</span><span class="p">))</span>                   
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">strided_schedule</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">stride_timestep</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">strided_schedule</span><span class="p">)</span><span class="o">-</span><span class="n">t</span>
</span></span><span class="line"><span class="cl">        <span class="n">timestep</span> <span class="o">=</span> <span class="n">strided_schedule</span><span class="p">[</span><span class="n">stride_timestep</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">t_repeated</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">timestep</span><span class="p">]),</span> <span class="n">batch_size_generation</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># data_stacked = torch.vstack([data_in_batch, labelled_values])</span>
</span></span><span class="line"><span class="cl">        <span class="n">pred_data</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">avg_params</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">data_in_batch</span><span class="p">,</span> <span class="n">t_repeated</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">is_training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">		<span class="c1"># Clipping helps in improving the samples generated as it keeps the random variables in the range of 0 to +1</span>
</span></span><span class="line"><span class="cl">		<span class="n">x_reconstructed</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">data_in_batch</span><span class="p">,</span> <span class="n">pred_data</span> <span class="o">*</span> <span class="n">sd</span><span class="p">[</span><span class="n">timestep</span><span class="p">])</span><span class="o">/</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">alphas_</span><span class="p">[</span><span class="n">timestep</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">		
</span></span><span class="line"><span class="cl">		<span class="k">if</span> <span class="n">timestep</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">			<span class="n">x_reconstructed</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">x_reconstructed</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">		<span class="n">mean_data_1</span> <span class="o">=</span> <span class="n">data_in_batch</span> <span class="o">*</span> <span class="n">mean_coeff_1_strided</span><span class="p">[</span><span class="n">stride_timestep</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">		<span class="n">mean_data_2</span> <span class="o">=</span> <span class="n">x_reconstructed</span> <span class="o">*</span> <span class="n">mean_coeff_2_strided</span><span class="p">[</span><span class="n">stride_timestep</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">		<span class="n">mean_data</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">mean_data_1</span><span class="p">,</span> <span class="n">mean_data_2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">posterior_data</span> <span class="o">=</span> <span class="n">posterior_variance_new_schedule_corrected</span><span class="p">[</span><span class="n">stride_timestep</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">data_noisy</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">subkeys</span><span class="p">[</span><span class="n">t</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size_generation</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="n">data_in_batch</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">mean_data</span><span class="p">,</span>  <span class="n">jnp</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">posterior_data</span><span class="p">)</span> <span class="o">*</span> <span class="n">data_noisy</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="err">        </span><span class="n">datas</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">device_get</span><span class="p">(</span><span class="n">data_in_batch</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="err">    </span><span class="k">return</span><span class="err"> </span><span class="n">datas</span><span class="p">,</span><span class="err"> </span><span class="n">data_in_batch</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="generating-samples--outputs">Generating Samples &amp; Outputs</h2>
<p>Let&rsquo;s first create a map between the label values and the characters.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt" id="hl-17-1"><a class="lnlinks" href="#hl-17-1"> 1</a>
</span><span class="lnt" id="hl-17-2"><a class="lnlinks" href="#hl-17-2"> 2</a>
</span><span class="lnt" id="hl-17-3"><a class="lnlinks" href="#hl-17-3"> 3</a>
</span><span class="lnt" id="hl-17-4"><a class="lnlinks" href="#hl-17-4"> 4</a>
</span><span class="lnt" id="hl-17-5"><a class="lnlinks" href="#hl-17-5"> 5</a>
</span><span class="lnt" id="hl-17-6"><a class="lnlinks" href="#hl-17-6"> 6</a>
</span><span class="lnt" id="hl-17-7"><a class="lnlinks" href="#hl-17-7"> 7</a>
</span><span class="lnt" id="hl-17-8"><a class="lnlinks" href="#hl-17-8"> 8</a>
</span><span class="lnt" id="hl-17-9"><a class="lnlinks" href="#hl-17-9"> 9</a>
</span><span class="lnt" id="hl-17-10"><a class="lnlinks" href="#hl-17-10">10</a>
</span><span class="lnt" id="hl-17-11"><a class="lnlinks" href="#hl-17-11">11</a>
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">string</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">x</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">63</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">)))]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">string</span><span class="o">.</span><span class="n">ascii_uppercase</span> <span class="o">+</span> <span class="n">string</span><span class="o">.</span><span class="n">ascii_lowercase</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">dict_</span> <span class="o">=</span> <span class="p">{}</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">x</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">  <span class="n">dict_</span><span class="p">[</span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="n">i</span>
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">get_label</span><span class="p">(</span><span class="n">ans</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">dict_</span><span class="p">[</span><span class="nb">str</span><span class="o">.</span><span class="n">upper</span><span class="p">(</span><span class="n">char</span><span class="p">)]</span> <span class="k">for</span> <span class="n">char</span> <span class="ow">in</span> <span class="n">ans</span><span class="p">])</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><strong>Generating Samples:</strong></p>
<p>Generating &lsquo;<em><strong>varun</strong></em>&rsquo; using the trained diffusion model.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt" id="hl-18-1"><a class="lnlinks" href="#hl-18-1">1</a>
</span><span class="lnt" id="hl-18-2"><a class="lnlinks" href="#hl-18-2">2</a>
</span><span class="lnt" id="hl-18-3"><a class="lnlinks" href="#hl-18-3">3</a>
</span><span class="lnt" id="hl-18-4"><a class="lnlinks" href="#hl-18-4">4</a>
</span><span class="lnt" id="hl-18-5"><a class="lnlinks" href="#hl-18-5">5</a>
</span><span class="lnt" id="hl-18-6"><a class="lnlinks" href="#hl-18-6">6</a>
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">datas</span><span class="p">,</span> <span class="n">d</span> <span class="o">=</span> <span class="n">generate_data_strided</span><span class="p">(</span><span class="n">avg_params</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span> <span class="s2">&#34;varun&#34;</span><span class="p">,</span> <span class="n">energy_method</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">clipped_version</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">datas_</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">datas</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span> <span class="p">:</span><span class="mi">2</span><span class="p">]),</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">d_</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">rearrange</span><span class="p">(</span><span class="n">datas_</span><span class="p">,</span> <span class="s1">&#39;a b c d e -&gt; (b a) c d e&#39;</span><span class="p">)</span> 
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">rawarrview</span><span class="p">(</span><span class="n">reshape_image_batch</span><span class="p">(</span><span class="n">datas</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">rows</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;bone_r&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">rawarrview</span><span class="p">(</span><span class="n">reshape_image_batch</span><span class="p">(</span><span class="n">d_</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span><span class="err"> </span><span class="n">rows</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span><span class="err"> </span><span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;bone_r&#39;</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><figure class="align-center ">
    <img loading="lazy" src="/images/varun.png#center"
         alt="Figure 4: &amp;lsquo;varun&amp;rsquo; generated using strided sampling technique." width="100%"/> <figcaption>
            <p>Figure 4: &lsquo;varun&rsquo; generated using strided sampling technique.</p>
        </figcaption>
</figure>

<figure class="align-center ">
    <img loading="lazy" src="/images/denoising_varun.png#center"
         alt="Figure 5: Visualizing the steps in the diffusion process. If you notice carefully, not much is happening at the early stages." width="100%"/> <figcaption>
            <p>Figure 5: Visualizing the steps in the diffusion process. If you notice carefully, not much is happening at the early stages.</p>
        </figcaption>
</figure>
</p>
<p>Generating &lsquo;<em><strong>tulsian</strong></em>&rsquo; using the trained diffusion model.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt" id="hl-19-1"><a class="lnlinks" href="#hl-19-1">1</a>
</span><span class="lnt" id="hl-19-2"><a class="lnlinks" href="#hl-19-2">2</a>
</span><span class="lnt" id="hl-19-3"><a class="lnlinks" href="#hl-19-3">3</a>
</span><span class="lnt" id="hl-19-4"><a class="lnlinks" href="#hl-19-4">4</a>
</span><span class="lnt" id="hl-19-5"><a class="lnlinks" href="#hl-19-5">5</a>
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">datas</span><span class="p">,</span> <span class="n">d</span> <span class="o">=</span> <span class="n">generate_data_strided</span><span class="p">(</span><span class="n">avg_params</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span> <span class="s2">&#34;tulsian&#34;</span><span class="p">,</span> <span class="n">energy_method</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">clipped_version</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">datas_</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">datas</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span> <span class="p">:</span><span class="mi">2</span><span class="p">]),</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">d_</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">rearrange</span><span class="p">(</span><span class="n">datas_</span><span class="p">,</span> <span class="s1">&#39;a b c d e -&gt; (b a) c d e&#39;</span><span class="p">)</span> 
</span></span><span class="line"><span class="cl"><span class="n">rawarrview</span><span class="p">(</span><span class="n">reshape_image_batch</span><span class="p">(</span><span class="n">datas</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">rows</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;bone_r&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">rawarrview</span><span class="p">(</span><span class="n">reshape_image_batch</span><span class="p">(</span><span class="n">d_</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span><span class="err"> </span><span class="n">rows</span><span class="o">=</span><span class="mi">7</span><span class="p">),</span><span class="err"> </span><span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;bone_r&#39;</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><figure class="align-center ">
    <img loading="lazy" src="/images/tulsian.png#center"
         alt="Figure 6: &amp;rsquo;tulsian&amp;rsquo; generated using strided sampling technique." width="100%"/> <figcaption>
            <p>Figure 6: &rsquo;tulsian&rsquo; generated using strided sampling technique.</p>
        </figcaption>
</figure>

<figure class="align-center ">
    <img loading="lazy" src="/images/denoising_tulsian.png#center"
         alt="Figure 7: Visualizing the steps in the diffusion process. Similar to earlier, not much is happening at the early stages." width="100%"/> <figcaption>
            <p>Figure 7: Visualizing the steps in the diffusion process. Similar to earlier, not much is happening at the early stages.</p>
        </figcaption>
</figure>
</p>
<h2 id="conclusion">Conclusion</h2>
<p>Denoising Diffusion models are a powerful algorithmic tool for Generative AI. Although much of the work done so far focusses on images, we could generate any distribution using these techniques.</p>
<p>I sincerely hope this introduction was useful to you. Please explore additional resources <a href="/posts/diffusion-models/bonus-denoising-diffusion-models-resources/" >here.</a></p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Ioffe et al. 2015 <a href="https://arxiv.org/abs/1502.03167" target="_blank" >Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</a>&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>Nichol et al. 2021 <a href="https://arxiv.org/abs/2102.09672" target="_blank" >Improved Denoising Diffusion Probabilistic Models</a>&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>Polyak et al. 1991<a href="https://epubs.siam.org/doi/10.1137/0330046" target="_blank" >Acceleration of Stochastic Approximation by Averaging</a>&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content:encoded>
    </item>
    
    <item>
      <title>Cohere Research Scholar Notebook</title>
      <link>https://varun-ml.github.io/posts/cohere/cohere-research-scholar/</link>
      <pubDate>Mon, 07 Nov 2022 01:17:43 +0530</pubDate>
      
      <guid>https://varun-ml.github.io/posts/cohere/cohere-research-scholar/</guid>
      <description> Notebook Github Link Colab Co;here Research Scholar Assignment Github </description>
      <content:encoded><![CDATA[<table>
<thead>
<tr>
<th style="text-align:left">Notebook</th>
<th style="text-align:left">Github Link</th>
<th style="text-align:left">Colab</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Co;here Research Scholar Assignment</td>
<td style="text-align:left"><a href="https://github.com/varun-ml/cohere-scholars-application/blob/main/C4AIScholarsChallenge-2022.ipynb" target="_blank" >Github</a></td>
<td style="text-align:left"><a href="https://colab.research.google.com/github/varun-ml/cohere-scholars-application/blob/main/C4AIScholarsChallenge-2022.ipynb" target="_blank" >
  <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colab">
</a></td>
</tr>
</tbody>
</table>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
