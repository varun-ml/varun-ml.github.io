<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Denoising Diffusion Models Part 1: Estimating True Distribution | wity'ai</title><meta name=keywords content="diffusion model,de-noising,generative ai,pytorch,DDPM,jupyter,tutorial,diffusion model series"><meta name=description content="What are Denoising Diffusion Models? Denoising Diffusion Models, commonly referred to as &ldquo;Diffusion models&rdquo;, are a class of generative models based on the Variational Auto Encoder (VAE) architecture. These models are called likelihood-based models because they assign a high likelihood to the observed data samples. In contrast to other generative models, such as GANs, which learn the sampling process of a complex distribution and are trained adversarially.
VAE&rsquo;s Let&rsquo;s take a detour and understand VAEs, as it will help with some intuition."><meta name=author content="Varun Tulsian"><link rel=canonical href=https://varun-ml.github.io/posts/diffusion-models/denoising-diffusion-models-1><meta name=google-site-verification content="G-1VE9P31T88"><link crossorigin=anonymous href=/assets/css/stylesheet.5b8287ef08b591d10eaf101babd7987c2c16890af54b921a596538e838629b23.css integrity="sha256-W4KH7wi1kdEOrxAbq9eYfCwWiQr1S5IaWWU46DhimyM=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://varun-ml.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://varun-ml.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://varun-ml.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://varun-ml.github.io/apple-touch-icon.png><link rel=mask-icon href=https://varun-ml.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css integrity=sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0 crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js integrity=sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe+j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4 crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous onload=renderMathInElement(document.body)></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-1VE9P31T88"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-1VE9P31T88",{anonymize_ip:!1})}</script><meta property="og:title" content="Denoising Diffusion Models Part 1: Estimating True Distribution"><meta property="og:description" content="What are Denoising Diffusion Models? Denoising Diffusion Models, commonly referred to as &ldquo;Diffusion models&rdquo;, are a class of generative models based on the Variational Auto Encoder (VAE) architecture. These models are called likelihood-based models because they assign a high likelihood to the observed data samples. In contrast to other generative models, such as GANs, which learn the sampling process of a complex distribution and are trained adversarially.
VAE&rsquo;s Let&rsquo;s take a detour and understand VAEs, as it will help with some intuition."><meta property="og:type" content="article"><meta property="og:url" content="https://varun-ml.github.io/posts/diffusion-models/denoising-diffusion-models-1/"><meta property="og:image" content="https://varun-ml.github.io/images/denoising_varun.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-12-09T11:28:30+05:30"><meta property="article:modified_time" content="2022-12-09T11:28:30+05:30"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://varun-ml.github.io/images/denoising_varun.png"><meta name=twitter:title content="Denoising Diffusion Models Part 1: Estimating True Distribution"><meta name=twitter:description content="What are Denoising Diffusion Models? Denoising Diffusion Models, commonly referred to as &ldquo;Diffusion models&rdquo;, are a class of generative models based on the Variational Auto Encoder (VAE) architecture. These models are called likelihood-based models because they assign a high likelihood to the observed data samples. In contrast to other generative models, such as GANs, which learn the sampling process of a complex distribution and are trained adversarially.
VAE&rsquo;s Let&rsquo;s take a detour and understand VAEs, as it will help with some intuition."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://varun-ml.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Denoising Diffusion Models Part 1: Estimating True Distribution","item":"https://varun-ml.github.io/posts/diffusion-models/denoising-diffusion-models-1/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Denoising Diffusion Models Part 1: Estimating True Distribution","name":"Denoising Diffusion Models Part 1: Estimating True Distribution","description":"What are Denoising Diffusion Models? Denoising Diffusion Models, commonly referred to as \u0026ldquo;Diffusion models\u0026rdquo;, are a class of generative models based on the Variational Auto Encoder (VAE) architecture. These models are called likelihood-based models because they assign a high likelihood to the observed data samples. In contrast to other generative models, such as GANs, which learn the sampling process of a complex distribution and are trained adversarially.\nVAE\u0026rsquo;s Let\u0026rsquo;s take a detour and understand VAEs, as it will help with some intuition.","keywords":["diffusion model","de-noising","generative ai","pytorch","DDPM","jupyter","tutorial","diffusion model series"],"articleBody":"What are Denoising Diffusion Models? Denoising Diffusion Models, commonly referred to as ‚ÄúDiffusion models‚Äù, are a class of generative models based on the Variational Auto Encoder (VAE) architecture. These models are called likelihood-based models because they assign a high likelihood to the observed data samples. In contrast to other generative models, such as GANs, which learn the sampling process of a complex distribution and are trained adversarially.\nVAE‚Äôs Let‚Äôs take a detour and understand VAEs, as it will help with some intuition. VAEs are composed of two processes: an encoder ($q$) (also referred to as the inference model), which generates a latent representation ($z$) of the input data ($x_0$), and a decoder ($p$) (also referred to as the generator), which generates the input data ($\\hat x_0$) using the latent representation ($z$) as input. The encoder and decoder are trained together using a variational objective, often referred to as the ELBO.\nFigure 1: An architecture for a Variational Auto Encoder. (Image source: VAE tutorial, Kingma et.al; 2019)\nFigure 2: Graphical representation of a Variational Auto Encoder. The $p$ function is the decoder and the $q$ function is the encoder. (Image source: Calvin Luo; 2022)\nFigures 1 \u0026 2 give a simplistic representation of a VAE model.\nDenoising Diffusion Models Analogous to VAEs, Denoising Diffusion models also consist of two processes: Diffusion, which is analogous to the VAE encoder, and Denoising, which is analogous to the VAE decoder.\nDiffusion - The diffusion process repeatedly samples random noise and corrupts our input data by adding the noise. In contrast to the VAE encoder, we typically do not learn this process. At step $T$, the data would be so corrupted that its just noise. Figure 3: Illustration of the Diffusion Process. Image of ‚ÄòZ‚Äô char is corrupted step by step.\nDenoising - The denoising is done by a learned model that takes completely noisy data and tries to generate the input data by repeatedly (over $t$ steps: $1$ to $T$) removing noise from the noisy data. Figure 4: Illustration of the Denoising Process. Image of ‚ÄòZ‚Äô character is generated step by step.\nDiffusion models are able to generate images from pure noise.\nHumans paint, they are able to generate images in a stepwise manner by painting on a blank canvas. Diffusion models are similar, they generate images in a stepwise manner by denoising a noisy canvas.\nIntroduction to this series I have spent too much time understanding diffusion models, which started with some wild posts I saw on Twitter.\nIntroducing Imagen, a new text-to-image synthesis model that can generate high-fidelity, photorealistic images from a deep level of language understanding. Learn more and and check out some examples of #imagen at https://t.co/RhD6siY6BY pic.twitter.com/C8javVu3iW\n‚Äî Google AI (@GoogleAI) May 24, 2022 Imagen Google AI Diffusion model. (Image source: Imagen Web Link)\nMy curiosity led to experiments, which enriched my ML skill-set. In this series, I will try to demystify some of the magic behind diffusion models. Finally read a tutorial on Diffusion models. Now, I understand how they work just not why they work. To me it's crazy that they do. pic.twitter.com/LXm5OrD993\n‚Äî Varun Tulsian (@varuntul22) October 5, 2022 Diffusion Models Series In this series, I will attempt to simplify the concepts and provide you with some code that you can easily run on Google Colab or your local Jupyter server. To be able to run things with minimal setup, we will be working on a 2D dataset (generated using scikit-learn) and the EMNIST dataset (28x28x1 images).\nThis is the first of 3 posts on diffusion models. You can check all the posts in the Full Diffusion Model Series. All the code for the diffusion model series is available here.\nThe first 2 parts of the series will focus on setting up the basic concepts and code. You won‚Äôt need a GPU to run the notebooks. The code is written in PyTorch. We will be working on simple 2D distributions and trying to generate them using denoising:\nPart 1: I will introduce the basics of the denoising approach for the diffusion model. We will predict the original distribution directly, following the first part of Luo, 20221\nPart 2: I will introduce some optimizations that have been shown to work better. The 2^nd^ part will include classifier-free guidance and steps to generate distributions faster using striding. This will correspond to the second part (Three Equivalent Interpretations) of Luo, 20221 In the last part of the series, we will be using the concepts learned to implement diffusion models for character generation. This will be done by training a U-Net model over the Extended-MNIST dataset. The code is written in JAX, Haiku.\nThere are a few high-quality blogs that can help you understand diffusion models in greater depth. A comprehensive list of resources can be found here.\nWhat are Diffusion Models? Let‚Äôs go over this again, this time in a little more detail. We will start seeing some mathematical equations and PyTorch code below.\nFigure 5: Graphical representation of a Denoising Diffusion Model. The decoder is the $p$ function, the encoder is the $q$ function. (Image source: Calvin Luo; 2022)\nDenoising Diffusion models are a Markovian Hierarchical Variational Auto Encoder , unlike a standard VAE model the encoder process (diffusion) and the decoder process (denoising) occur in multiple steps. Figure 5 depicts the diffusion process, which begins with a random variable $x$ and generates random variables $x_t$ at the $t^{th}$ step. The denoising process starts at $x_T$ and attempts to generate $\\hat x_t$ and ultimately $\\hat x_0$.\nWe will be going over the Diffusion Process and the Denoising Process followed by the Training procedure. But first, let‚Äôs build an understanding of what needs to be done to implement such a model.\nTraining a Denoising Diffusion model\nThis is the main source of confusion when it comes to understanding diffusion models. From the description above and the analogy with the VAEs it would seem that training a diffusion model would consist of the following steps.\nUsing some data as an input ($x_0$). Perform a Forward Pass (Diffusion), generating $x_t$‚Äôs in order. Run the noisy image ($x_T$) to the Backward pass (Denoising) to get $\\hat x_0$. This would be done using a $NN(\\hat x_t, t)$ and the output should be $\\hat x_{t-1}$. Performing a weight update of the model $NN$ after computing a loss-based $L(x_t, \\hat x_t)$. However, this isn‚Äôt the case üôà. Let‚Äôs investigate the issues with this approach. For every input in our dataset, we will have to go through all the timesteps, apply diffusion, and then go through the whole denoising steps, with weight updates only happening at the end of the pass. Training in such a way would be slow, and we would not be able to meaningfully learn anything useful.\nInstead, we can show that we can effectively learn the distribution $p(X)$ while just doing the following steps.\nusing some data as an input ($x_0$). 1a. Take uniform and random samples of a time variable $t$ ranging from $1,to,T$. Compute the latent variable $x_t$ in a single step. Refer to the diffusion process section. Apply the $NN$ model to the noisy image ($x_t$) to obtain $\\hat x_t0$. The result of $NN(\\hat x_t, t)$ is $\\hat x_t0$. We will not go over each step during training. Note about notation: $\\hat x_t0$ is the predicted reconstruction of the input $x_0$ at timestep $t$.\nPerforming a weight update of the model $NN$ after computing a loss-based $L(x, \\hat x_t0, t)$. Pseudo code:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 def diffusion(x_0, t): code to add noise to x_0 return x_i def training(): for loop until convergence: pick an image x_0 from X (batch of images) sample t from 1 to T x_t = diffusion(x_0, t) x_hat_t = NN(x_t, t) loss_ = loss(x_0, x_hat_t) update(NN, grad(loss_) # denoising def generate_new_data(): sample x_T from N(0, I) for t in range(T, 1): x_hat_t = NN(x_t, t) # get x_{t-1} x_{t-1} = func(x_hat_t, t) x_hat_0 = x_0 The proof requires us to reduce the ELBO loss making use of the Markovian assumption in the diffusion process, and using Monte-Carlo estimates to obtain an equivalent loss. I won‚Äôt go into details on this proof, please refer Section: Variational Diffusion Models, equation 100 gives the reduced loss 1.\nDiffusion Process As described earlier, we are going to be adding noise to the input vector. Let‚Äôs see how exactly one can do that ‚Äì\nAt each timestep $t$ in the diffusion process, we sample from the latent variable, $q_t(x_t|x_{t-1})$. $$ q_t(x_t|x_{t-1}) = N(\\sqrt\\alpha_tx_{t-1}, (1 - \\alpha_t )I) $$ $\\alpha_t$, $t\\in[1, T]$, where $\\alpha_t \u003c 1$, describes the diffusion schedule. $\\alpha_{t-1} \u003c \\alpha_t$, as we go along in the diffusion process we are adding more and more noise.\nThe form of the coefficients is chosen such that the variance of the latent variables stay at a similar scale. At this point, let me introduce the reparameterization trick.\n$$ N(\\sqrt\\alpha_tx_{t-1}, (1 - \\alpha_t )I) = \\sqrt\\alpha_tx_{t-1} + (1 - \\alpha_t)*\\epsilon \\quad with \\,\\, \\epsilon \\sim N(0, I) $$ The reparemetarization trick is cool, it simplifies working with a complex Gaussian distribution. If you want to sample from the diffusion step at $t$, you can simply sample from a standard Gaussian distribution $N(0, I)$ and factor and plug in the mean and variance. Consider another interesting result: suppose we want to sample from the latent $x_t$ directly given $x_0$. In other words, we want to take a sample from $q(x_t|x_0)$.\n$$ \\begin{align} q(x_t|x) \u0026= N(\\sqrt\\alpha_tx_{t-1}, (1 - \\alpha_t )I) \\cr \u0026= \\sqrt\\alpha_t x_{t-1} + \\sqrt{(1-\\alpha_t)}\\ast\\epsilon_t \\cr \u0026= \\sqrt\\alpha_t(\\sqrt\\alpha_t x_{t-2} + \\sqrt{(1-\\alpha_{t-1})}\\ast\\epsilon_{t-1}) + \\sqrt(1-\\alpha_t)\\ast\\epsilon_t \\cr \u0026= \\sqrt\\alpha_t\\sqrt\\alpha_t x_{t-2} + \\sqrt\\alpha_t\\sqrt{(1-\\alpha_{t-1})}\\ast\\epsilon_{t-1} + \\sqrt(1-\\alpha_t)\\ast\\epsilon_t \\cr \u0026= \\sqrt\\alpha_t\\sqrt\\alpha_tx_{t-2} + \\sqrt{(1-\\alpha_t\\alpha_{t-1})}\\ast\\epsilon_{t-1}^\\ast \\quad where \\thinspace \\epsilon_{t-1}^\\ast\\in N(0, I) \\cr \u0026= ... \\cr \u0026= \\sqrt{\\bar\\alpha_t}x_0 + \\sqrt{(1 - \\bar\\alpha_t )}\\ast\\epsilon^\\ast ; where \\space \\bar\\alpha_t=\\Pi_{i=1}^T{\\sqrt\\alpha_i}, \\space \\epsilon^\\ast \\in N(0, I) \\cr \u0026= N(\\sqrt{\\bar\\alpha_t}x_0, (1 - \\bar\\alpha_t )I)\\cr \\end{align} $$ In equation 5, we have utilized sum of two independent Gaussian random variables.\nWith this in place, let‚Äôs put some code together.\nThe diffusion schedule: $\\alpha$\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 timestepts = 200 ## linear schedule def linear_beta_schedule(timesteps): beta_start = 0.0001 beta_end = 0.02 return jnp.linspace(beta_start, beta_end, timesteps) ## cosine schedule as proposed in https://arxiv.org/abs/2102.09672 ## The cosine schedule is recommened if timesteps \u003e\u003e 200. As it results in a gradual noisification of the input data def cosine_beta_schedule(timesteps, s=0.008): steps = timesteps + 1 x = jnp.linspace(0, timesteps, steps) alphas_cumprod = jnp.cos(((x / timesteps) + s) / (1 + s) * jnp.pi * 0.5) ** 2 alphas_cumprod = alphas_cumprod / alphas_cumprod[0] betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1]) return jnp.clip(betas, 0.0001, 0.1) ## some handy variables betas = linear_beta_schedule(timesteps) alphas = 1 - betas alphas_ = torch.cumprod(alphas, axis=0) variance = 1 - alphas_ sd = torch.sqrt(variance) import torch.nn.functional as F alphas_prev_ = F.pad(alphas_[:-1], [1, 0], \"constant\", 1.0) Diffusion: Given input data $x_0$, a timestep $t$ and a schedule, the diffusion method should return the latent variable $x_t$.\n1 2 3 4 5 6 # how to add noise to the data def get_noisy(batch, timestep): # we will use the reparameterization trick noise_at_t = torch.normal(0, std=1, size=batch.size()) added_noise_at_t = batch.mul(torch.sqrt(alphas_[timestep])) + noise_at_t.mul(sd[timestep]) return added_noise_at_t, noise_at_t In Variational Diffusion Models, Kingma et.al, 20222 propose a way to learn the parameters of the schedule and provide additional insights helpful in understanding diffusion models.\nTraining Procedure We have just defined the diffusion method in the pseudo code. Let‚Äôs define the loss function and the Neural Network.\nNeural Network:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 from torch import nn class DenoisingModelSequential(nn.Module): def __init__(self, hidden_units=32): super(DenoisingModelSequential, self).__init__() # hidden_units = 32 self.mlp = nn.Sequential( nn.Linear(3, int(hidden_units), bias=True), nn.GELU(), nn.Linear(int(hidden_units), int(hidden_units/2), bias=True), nn.GELU(), nn.Linear(int(hidden_units/2), int(hidden_units/4), bias=True), nn.GELU(), nn.Linear(int(hidden_units/4), int(hidden_units/8), bias=True), nn.GELU(), nn.Linear(int(hidden_units/8), int(hidden_units/16), bias=True), nn.GELU(), nn.Linear(int(hidden_units/16), int(hidden_units/8), bias=True), nn.GELU(), nn.Linear(int(hidden_units/8), int(hidden_units/4), bias=True), nn.GELU(), nn.Linear(int(hidden_units/4), int(hidden_units/2), bias=True), nn.GELU(), nn.Linear(int(hidden_units/2), int(hidden_units), bias=True), nn.GELU(), nn.Linear(int(hidden_units), 2, bias=True) ) def forward(self, x): x = self.mlp(x) return x denoising_model = DenoisingModelSequential(64) The input to the NN is 3 dimensional. We are working with 2d dataset, so $\\hat x_t$‚Äôs is a 2d vector. In this article, we are going to pass $t$ as the 3rd dimension, we will pass it as a scalar. In the subsequent articles, we will see how to generate an embedding for a timestep and concatenate/fuse it with the input. The output of the NN needs to be $\\hat x_t^0$ which is a 2d vector. The NN architecture doesn‚Äôt really matter. In this case, I‚Äôve used a basic Multi Layer Perceptron with GeLU activation units3. We will use a U-net architecture for character generation using the EMNIST dataset. Checkout Part 4.\nLoss Function: At timestep $t$ $$ Loss(x_0, \\hat x_t, t) = 1/2\\ast(\\frac{\\bar\\alpha_{t-1}}{1-\\bar\\alpha_{t-1}} - \\frac{\\bar\\alpha_t}{1-\\bar\\alpha_t})\\ast\\mid\\mid x_0-\\hat x_0^t\\mid\\mid_2^2 $$ $$ \\text{SNR}_t =\\frac{\\bar\\alpha_t}{1-\\bar\\alpha_t} $$ SNR stands for Signal to Noise. In the case of the diffusion, the schedule must to be chosen such that $SNR_t \u003c SNT_{t-1}$.\nLoss:\n1 2 3 4 5 6 # instead of the l2 loss, I use the huber loss # https://pytorch.org/docs/stable/generated/torch.nn.HuberLoss.html loss_func = nn.HuberLoss() imp_weight = torch.sqrt(1/2 * ((alphas_prev_[timestep] / (1 - alphas_prev_[timestep])) - (alphas_[timestep]/(1 - alphas_[timestep])))) loss_ = loss_func(data_in_batch.mul(imp_weight), pred_data.T.mul(imp_weight)) In Variation Diffusion Models2, authors propose using a separate Neural Network to model SNR as a function of t. The Neural Network should be monotonically decreasing.\nDenoising Process Let‚Äôs recap, the denoising process is responsible to generate synthetic data $\\hat x$.\nStart with a completely noisy data, $x_T = N(0, I)$ Uses a Neural Network to predict $\\hat x_T^0$ We will use $\\hat x_T^0$ to generate the latent $\\hat x_{T-1}$ repeat step 2 with input $\\hat x_{T-1}$ to get $\\hat x_{T-2}$ until t=1 Refer, our mathematical setup in Figure 5. Let‚Äôs try to look at a backward transition in the denoising process $p(\\hat x_t|\\hat x_{t+1})$. This is also called the posterior distribution.\nLet‚Äôs investigate what this looks like in the diffusion process: $$ \\begin{align} q(x_t|x_{t+1}) = \\frac{q(x_t|x_{t-1})\\ast q(x_{t-1}|x_0)}{q(x_t|x_0)}\\quad \\text{Baye's theorem \\\u0026} \\, \\text{Note: } x_0 = x \\cr = ... \\cr \\varpropto N(x_{t-1};\\underbrace{\\frac{\\sqrt\\alpha_t(1-\\bar\\alpha_{t-1})x_t + \\sqrt{\\bar\\alpha_{t-1}}(1-\\alpha_t)x_0}{1-\\bar\\alpha_t}}_{\\mu_q(x_t,x_0)}, \\underbrace{\\frac{(1-\\alpha_t)(1-\\bar\\alpha_{t-1})}{1-\\bar\\alpha_t}I}_{\\sum_q(t)}) \\cr \\end{align} $$ For the full derivation please refer Equation #71; Calvin Luo‚Äôs tutorial1\nWe will assume that the reverse process $p(\\hat x_t|\\hat x_{t+1})$ also follows the same form as the forward process $q(x_t|x_{t+1})$. We will hence do the following ‚Äì\nAssume that posterior $p(\\hat x_t|\\hat x_{t+1})$ follows a Gaussian distribution as well. We would keep the posterior mean follow the same form as $\\mu_q(x_t, x_0)$. $\\mu_p(\\hat x_t|\\hat x_{t+1}) = \\mu_q(x_t, x_0)$, here $\\hat x_t$ is the input to the $NN$ and the $NN$ will output a prediction for $\\hat x_t^0$ In Equation 11, we will replace $x_0$ with $\\hat x_t^0$ and $x_t$ with $\\hat x_t$ With fixed variance, $\\sum_{p(x_{t-1}|x_t)} = \\sum_q(t)$. As show in Improved Denoising Diffusion Probabilistic Models.4 We could alternatively learn the posterior variance. In this case, we will make the neural network output the variance as well as the mean. Diffusion: With Fixed Variance\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # fixed posterior variance posterior_variance = (1 - alphas) * (1 - alphas_prev_) / (1 - alphas) def generate_data(denoising_model): # generating multiple samples at the same time batch_size_generation = 2048*5 # x_T -- we will start from a Noisy sample data_noisy = torch.normal(mean=0, std=1, size=(2, batch_size_generation)) for n in range(1, int(len(data_noisy[0])/batch_size_generation) + 1): data_in_batch = data_noisy[:, (n-1)*batch_size_generation:(n*batch_size_generation)] for t in range(1, timesteps): timestep = timesteps-t t_repeated = torch.Tensor([timestep]).repeat(batch_size_generation) data_stacked = torch.vstack([data_in_batch, t_repeated]) # x_hat_0 prediction at time t pred_data = denoising_model(data_stacked.T) # implementing equation above to get x_(t-1) from x_t and x_0 mean_data_1 = data_in_batch.T.mul(torch.sqrt(alphas[timestep])*(1-alphas_prev_[timestep])/(variance[timestep])) mean_data_2 = pred_data.mul(torch.sqrt(alphas_prev_[timestep])*(1-alphas[timestep])/(variance[timestep])) mean_data = mean_data_1.add(mean_data_2) posterior_data = posterior_variance[timestep] data_in_batch = torch.normal(mean_data, torch.sqrt(posterior_data)).T return data_in_batch Let‚Äôs look at some outputs In this article, we will play with some 2d data-points.\nLoading data points:\n1 2 3 samples = 1024*128 x = torch.normal(mean=0, std=4, size=(1, samples)) y = torch.normal(mean=0.25*torch.ones(samples)*x*x, std=torch.ones(samples)*1) 1 2 3 circles, _ = datasets.make_circles(1024*128, noise=0.01, factor=0.1, shuffle=True) make_moons, labels = datasets.make_moons(n_samples=1024*128, noise=0.01) complex_data = numpy.hstack([make_moons + 15, circles ]) Data compared to Diffusion data:\nLet‚Äôs look at some data I was able to generate using this concept.\nFigure 6: 2D Parabola vs Diffusion generated\nFigure 7: 2D Complex vs Diffusion generated\nFigure 8: A gif show-casing the denoising process; We start from complete noise and make small improvements step by step\nSee you in the next part. You can find the Jupyter Notebook here.\nWritten with StackEdit.\nCalvin Luo; 2019 ‚ÄúUnderstanding Diffusion Models: A Unified Perspective‚Äù¬†‚Ü©Ô∏é¬†‚Ü©Ô∏é¬†‚Ü©Ô∏é¬†‚Ü©Ô∏é\nKingma et al; 2022 ‚ÄúVariational Diffusion Models‚Äù¬†‚Ü©Ô∏é¬†‚Ü©Ô∏é\nHendrycks et. al; 2016 Gelu‚Äôs¬†‚Ü©Ô∏é\nNichol et al; 2021 Improved Denoising Diffusion Probabilistic Models¬†‚Ü©Ô∏é\n","wordCount":"2824","inLanguage":"en","image":"https://varun-ml.github.io/images/denoising_varun.png","datePublished":"2022-12-09T11:28:30+05:30","dateModified":"2022-12-09T11:28:30+05:30","author":{"@type":"Person","name":"Varun Tulsian"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://varun-ml.github.io/posts/diffusion-models/denoising-diffusion-models-1/"},"publisher":{"@type":"Organization","name":"wity'ai","logo":{"@type":"ImageObject","url":"https://varun-ml.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://varun-ml.github.io/ accesskey=h title="wity'ai (Alt + H)">wity'ai</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://varun-ml.github.io/posts title=Posts><span>Posts</span></a></li><li><a href=https://varun-ml.github.io/archives title=Archive><span>Archive</span></a></li><li><a href=https://varun-ml.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://varun-ml.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://varun-ml.github.io/faq.html title=FAQ><span>FAQ</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://varun-ml.github.io/>Home</a>&nbsp;¬ª&nbsp;<a href=https://varun-ml.github.io/posts/>Posts</a></div><h1 class=post-title>Denoising Diffusion Models Part 1: Estimating True Distribution</h1><div class=post-meta><span title='2022-12-09 11:28:30 +0530 IST'>December 9, 2022</span>&nbsp;¬∑&nbsp;14 min&nbsp;¬∑&nbsp;2824 words&nbsp;¬∑&nbsp;Varun Tulsian</div></header><figure class=entry-cover><img loading=lazy src=https://varun-ml.github.io/images/denoising_varun.png alt="First part tutorial for density generation using diffusion models"><p>Denoising in action. Characters generated using EMNIST dataset. Left to Right: Noisy image is getting denoised.</p></figure><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#what-are-denoising-diffusion-models>What are Denoising Diffusion Models?</a><ul><li><a href=#vaes>VAE&rsquo;s</a></li><li><a href=#denoising-diffusion-models>Denoising Diffusion Models</a></li></ul></li><li><a href=#introduction-to-this-series>Introduction to this series</a><ul><li><a href=#diffusion-models-series>Diffusion Models Series</a></li></ul></li><li><a href=#what-are-diffusion-models>What are Diffusion Models?</a><ul><li><a href=#diffusion-process>Diffusion Process</a></li><li><a href=#training-procedure>Training Procedure</a></li><li><a href=#denoising-process>Denoising Process</a></li></ul></li><li><a href=#lets-look-at-some-outputs>Let&rsquo;s look at some outputs</a></li></ul></nav></div></details></div><div class=post-content><h2 id=what-are-denoising-diffusion-models>What are Denoising Diffusion Models?<a hidden class=anchor aria-hidden=true href=#what-are-denoising-diffusion-models>#</a></h2><p>Denoising Diffusion Models, commonly referred to as &ldquo;<strong>Diffusion models</strong>&rdquo;, are a class of generative models based on the <strong>Variational Auto Encoder</strong> (VAE) architecture. These models are called <em>likelihood-based models</em> because they assign a high likelihood to the observed data samples. In contrast to other <em>generative models</em>, such as GANs, which learn the sampling process of a complex distribution and are trained adversarially.</p><h3 id=vaes>VAE&rsquo;s<a hidden class=anchor aria-hidden=true href=#vaes>#</a></h3><p>Let&rsquo;s take a detour and understand VAEs, as it will help with some intuition. VAEs are composed of two processes: an <strong>encoder</strong> ($q$) (also referred to as the inference model), which generates a latent representation ($z$) of the input data ($x_0$), and a <strong>decoder</strong> ($p$) (also referred to as the generator), which generates the input data ($\hat x_0$) using the latent representation ($z$) as input. The encoder and decoder are trained together using a <em>variational objective</em>, often referred to as the <em>ELBO</em>.</p><figure><img loading=lazy src=/images/vae-max.png alt="Figure 1: An architecture for a Variational Auto Encoder. (Image source: VAE tutorial, Kingma et.al; 2019)" width=100%><figcaption><p>Figure 1: An architecture for a Variational Auto Encoder. (Image source: <a href=http://arxiv.org/abs/1906.02691>VAE tutorial, Kingma et.al; 2019</a>)</p></figcaption></figure><figure class=align-center><img loading=lazy src=/images/vae-graphical-representation.png#center alt="Figure 2: Graphical representation of a Variational Auto Encoder. The $p$ function is the decoder and the $q$ function is the encoder. (Image source: Calvin Luo; 2022)" width=50%><figcaption><p>Figure 2: Graphical representation of a Variational Auto Encoder. The $p$ function is the decoder and the $q$ function is the encoder. (Image source: <a href=http://arxiv.org/abs/2208.11970>Calvin Luo; 2022</a>)</p></figcaption></figure><p>Figures 1 & 2 give a simplistic representation of a VAE model.</p><h3 id=denoising-diffusion-models>Denoising Diffusion Models<a hidden class=anchor aria-hidden=true href=#denoising-diffusion-models>#</a></h3><p>Analogous to VAEs, Denoising Diffusion models also consist of two processes: <strong>Diffusion</strong>, which is analogous to the VAE encoder, and <strong>Denoising</strong>, which is analogous to the VAE decoder.</p><ul><li><strong>Diffusion</strong> - The diffusion process repeatedly samples random noise and corrupts our input data by adding the noise. In contrast to the VAE encoder, we typically do not learn this process. At step $T$, the data would be so corrupted that its just noise.</li></ul><figure><img loading=lazy src=/images/diffusion-z.png alt="Figure 3: Illustration of the Diffusion Process. Image of &amp;lsquo;Z&amp;rsquo; char is corrupted step by step." width=100%><figcaption><p>Figure 3: Illustration of the Diffusion Process. Image of &lsquo;Z&rsquo; char is corrupted step by step.</p></figcaption></figure><ul><li><strong>Denoising</strong> - The denoising is done by a learned model that takes <em>completely noisy data</em> and tries to generate the input data by repeatedly (over $t$ steps: $1$ to $T$) removing noise from the noisy data.<figure><img loading=lazy src=/images/denoising-z.png alt="Figure 4: Illustration of the Denoising Process. Image of &amp;lsquo;Z&amp;rsquo; character is generated step by step." width=100%><figcaption><p>Figure 4: Illustration of the Denoising Process. Image of &lsquo;Z&rsquo; character is generated step by step.</p></figcaption></figure></li></ul><p>Diffusion models are able to generate images from pure noise.</p><blockquote><p>Humans paint, they are able to generate images in a stepwise manner by painting on a blank canvas. Diffusion models are similar, they generate images in a stepwise manner by <em>denoising</em> a noisy canvas.</p></blockquote><h2 id=introduction-to-this-series>Introduction to this series<a hidden class=anchor aria-hidden=true href=#introduction-to-this-series>#</a></h2><p>I have spent too much time understanding diffusion models, which started with some wild posts I saw on Twitter.</p><blockquote class=twitter-tweet data-dnt=true><p lang=en dir=ltr>Introducing Imagen, a new text-to-image synthesis model that can generate high-fidelity, photorealistic images from a deep level of language understanding. Learn more and and check out some examples of <a href="https://twitter.com/hashtag/imagen?src=hash&ref_src=twsrc%5Etfw">#imagen</a> at <a href=https://t.co/RhD6siY6BY>https://t.co/RhD6siY6BY</a> <a href=https://t.co/C8javVu3iW>pic.twitter.com/C8javVu3iW</a></p>&mdash; Google AI (@GoogleAI) <a href="https://twitter.com/GoogleAI/status/1529165219997528064?ref_src=twsrc%5Etfw">May 24, 2022</a></blockquote><figure class=align-center><img loading=lazy src=/images/diffusion-01.jpg#center alt="Imagen Google AI Diffusion model. (Image source: Imagen Web Link)" width=60%><figcaption><p>Imagen Google AI Diffusion model. (Image source: <a href=https://imagen.research.google/>Imagen Web Link</a>)</p></figcaption></figure><p>My curiosity led to experiments, which enriched my ML skill-set. In this series, I will try to demystify some of the magic behind diffusion models.<blockquote class=twitter-tweet data-dnt=true><p lang=en dir=ltr>Finally read a tutorial on Diffusion models. Now, I understand how they work just not why they work. To me it's crazy that they do. <a href=https://t.co/LXm5OrD993>pic.twitter.com/LXm5OrD993</a></p>&mdash; Varun Tulsian (@varuntul22) <a href="https://twitter.com/varuntul22/status/1577715572271611904?ref_src=twsrc%5Etfw">October 5, 2022</a></blockquote></p><h3 id=diffusion-models-series>Diffusion Models Series<a hidden class=anchor aria-hidden=true href=#diffusion-models-series>#</a></h3><p>In this series, I will attempt to simplify the concepts and provide you with some code that you can easily run on Google Colab or your local Jupyter server. To be able to run things with minimal setup, we will be working on a 2D dataset (generated using scikit-learn) and the <a href=https://www.tensorflow.org/datasets/catalog/emnist>EMNIST dataset (28x28x1 images)</a>.</p><p>This is the first of 3 posts on diffusion models. You can check all the posts in the <a href=/tags/diffusion-model-series/>Full Diffusion Model Series</a>. All the code for the diffusion model series is available <a href=/posts/diffusion-models/diffusion-models-notebooks/>here</a>.</p><p>The first 2 parts of the series will focus on setting up the basic concepts and code. You won&rsquo;t need a GPU to run the notebooks. The code is written in PyTorch. We will be working on simple 2D distributions and trying to generate them using denoising:</p><ul><li><p><strong>Part 1</strong>: I will introduce the basics of the denoising approach for the diffusion model. We will predict the original distribution directly, following the <cite>first part of Luo, 2022<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup></cite></p></li><li><p><strong>Part 2</strong>: I will introduce some optimizations that have been shown to work better. The 2^nd^ part will include <em>classifier-free guidance</em> and steps to generate distributions faster using <em>striding</em>. This will correspond to the <cite>second part (Three Equivalent Interpretations) of Luo, 2022<sup id=fnref1:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup></cite></p></li></ul><p>In the last part of the series, we will be using the concepts learned to implement diffusion models for character generation. This will be done by training a U-Net model over the <a href=https://www.tensorflow.org/datasets/catalog/emnist>Extended-MNIST dataset</a>. The code is written in <a href=https://jax.readthedocs.io/>JAX</a>, <a href=https://dm-haiku.readthedocs.io/>Haiku</a>.</p><p>There are a few high-quality blogs that can help you understand diffusion models in greater depth. A comprehensive list of resources can be found <a href=/posts/diffusion-models/bonus-denoising-diffusion-models-resources/>here</a>.</p><h2 id=what-are-diffusion-models>What are Diffusion Models?<a hidden class=anchor aria-hidden=true href=#what-are-diffusion-models>#</a></h2><p>Let&rsquo;s go over this again, this time in a little more detail. We will start seeing some mathematical equations and PyTorch code below.</p><figure class=align-center><img loading=lazy src=/images/diffusion-graphical-representation.png#center alt="Figure 5: Graphical representation of a Denoising Diffusion Model. The decoder is the $p$ function, the encoder is the $q$ function. (Image source: Calvin Luo; 2022)" width=80%><figcaption><p>Figure 5: Graphical representation of a Denoising Diffusion Model. The decoder is the $p$ function, the encoder is the $q$ function. (Image source: <a href=http://arxiv.org/abs/2208.11970>Calvin Luo; 2022</a>)</p></figcaption></figure><p>Denoising Diffusion models are a Markovian Hierarchical Variational Auto Encoder , unlike a standard VAE model the encoder process (diffusion) and the decoder process (denoising) occur in multiple steps.
Figure 5 depicts the diffusion process, which begins with a random variable $x$ and generates random variables $x_t$ at the $t^{th}$ step. The denoising process starts at $x_T$ and attempts to generate $\hat x_t$ and ultimately $\hat x_0$.</p><p>We will be going over the <em>Diffusion Process</em> and the <em>Denoising Process</em> followed by the <em>Training procedure</em>. But first, let&rsquo;s build an understanding of what needs to be done to implement such a model.</p><p><strong>Training a Denoising Diffusion model</strong></p><p>This is the main source of confusion when it comes to understanding diffusion models. From the description above and the analogy with the VAEs it would seem that training a diffusion model would consist of the following steps.</p><ol><li>Using some data as an input ($x_0$).</li><li>Perform a Forward Pass (Diffusion), generating $x_t$&rsquo;s in order.</li><li>Run the noisy image ($x_T$) to the Backward pass (Denoising) to get $\hat x_0$. This would be done using a $NN(\hat x_t, t)$ and the output should be $\hat x_{t-1}$.</li><li>Performing a weight update of the model $NN$ after computing a loss-based $L(x_t, \hat x_t)$.</li></ol><p>However, this isn&rsquo;t the case <span class=emojify>üôà</span>. Let&rsquo;s investigate the issues with this approach. For every input in our dataset, we will have to go through all the timesteps, apply diffusion, and then go through the whole denoising steps, with weight updates only happening at the end of the pass. Training in such a way would be slow, and we would not be able to meaningfully learn anything useful.</p><p>Instead, we can show that we can effectively learn the distribution $p(X)$ while just doing the following steps.</p><ol><li>using some data as an input ($x_0$).
1a. Take uniform and random samples of a time variable $t$ ranging from $1,to,T$.</li><li>Compute the latent variable $x_t$ in a single step. <a href=/posts/diffusion-models/denoising-diffusion-models-1/#diffusion-process>Refer to the diffusion process section</a>.</li><li>Apply the $NN$ model to the noisy image ($x_t$) to obtain $\hat x_t0$. The result of $NN(\hat x_t, t)$ is $\hat x_t0$. We will not go over each step <strong>during training</strong>.</li></ol><blockquote><p>Note about notation: $\hat x_t0$ is the predicted reconstruction of the input $x_0$ at timestep $t$.</p></blockquote><ol start=4><li>Performing a weight update of the model $NN$ after computing a loss-based $L(x, \hat x_t0, t)$.</li></ol><p><strong>Pseudo code:</strong></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-0-1><a class=lnlinks href=#hl-0-1> 1</a>
</span><span class=lnt id=hl-0-2><a class=lnlinks href=#hl-0-2> 2</a>
</span><span class=lnt id=hl-0-3><a class=lnlinks href=#hl-0-3> 3</a>
</span><span class=lnt id=hl-0-4><a class=lnlinks href=#hl-0-4> 4</a>
</span><span class=lnt id=hl-0-5><a class=lnlinks href=#hl-0-5> 5</a>
</span><span class=lnt id=hl-0-6><a class=lnlinks href=#hl-0-6> 6</a>
</span><span class=lnt id=hl-0-7><a class=lnlinks href=#hl-0-7> 7</a>
</span><span class=lnt id=hl-0-8><a class=lnlinks href=#hl-0-8> 8</a>
</span><span class=lnt id=hl-0-9><a class=lnlinks href=#hl-0-9> 9</a>
</span><span class=lnt id=hl-0-10><a class=lnlinks href=#hl-0-10>10</a>
</span><span class=lnt id=hl-0-11><a class=lnlinks href=#hl-0-11>11</a>
</span><span class=lnt id=hl-0-12><a class=lnlinks href=#hl-0-12>12</a>
</span><span class=lnt id=hl-0-13><a class=lnlinks href=#hl-0-13>13</a>
</span><span class=lnt id=hl-0-14><a class=lnlinks href=#hl-0-14>14</a>
</span><span class=lnt id=hl-0-15><a class=lnlinks href=#hl-0-15>15</a>
</span><span class=lnt id=hl-0-16><a class=lnlinks href=#hl-0-16>16</a>
</span><span class=lnt id=hl-0-17><a class=lnlinks href=#hl-0-17>17</a>
</span><span class=lnt id=hl-0-18><a class=lnlinks href=#hl-0-18>18</a>
</span><span class=lnt id=hl-0-19><a class=lnlinks href=#hl-0-19>19</a>
</span><span class=lnt id=hl-0-20><a class=lnlinks href=#hl-0-20>20</a>
</span><span class=lnt id=hl-0-21><a class=lnlinks href=#hl-0-21>21</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>diffusion</span><span class=p>(</span><span class=n>x_0</span><span class=p>,</span> <span class=n>t</span><span class=p>):</span>
</span></span><span class=line><span class=cl>	<span class=n>code</span> <span class=n>to</span> <span class=n>add</span> <span class=n>noise</span> <span class=n>to</span> <span class=n>x_0</span>
</span></span><span class=line><span class=cl>	<span class=k>return</span> <span class=n>x_i</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>training</span><span class=p>():</span>
</span></span><span class=line><span class=cl>	<span class=k>for</span> <span class=n>loop</span> <span class=n>until</span> <span class=n>convergence</span><span class=p>:</span>
</span></span><span class=line><span class=cl>		<span class=n>pick</span> <span class=n>an</span> <span class=n>image</span> <span class=n>x_0</span> <span class=kn>from</span> <span class=nn>X</span> <span class=p>(</span><span class=n>batch</span> <span class=n>of</span> <span class=n>images</span><span class=p>)</span>
</span></span><span class=line><span class=cl>		<span class=n>sample</span> <span class=n>t</span> <span class=kn>from</span> <span class=mi>1</span> <span class=n>to</span> <span class=n>T</span>
</span></span><span class=line><span class=cl>		<span class=n>x_t</span> <span class=o>=</span> <span class=n>diffusion</span><span class=p>(</span><span class=n>x_0</span><span class=p>,</span> <span class=n>t</span><span class=p>)</span>
</span></span><span class=line><span class=cl>		<span class=n>x_hat_t</span> <span class=o>=</span> <span class=n>NN</span><span class=p>(</span><span class=n>x_t</span><span class=p>,</span> <span class=n>t</span><span class=p>)</span>
</span></span><span class=line><span class=cl>		<span class=n>loss_</span> <span class=o>=</span> <span class=n>loss</span><span class=p>(</span><span class=n>x_0</span><span class=p>,</span> <span class=n>x_hat_t</span><span class=p>)</span>
</span></span><span class=line><span class=cl>		<span class=n>update</span><span class=p>(</span><span class=n>NN</span><span class=p>,</span> <span class=n>grad</span><span class=p>(</span><span class=n>loss_</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># denoising</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>generate_new_data</span><span class=p>():</span>
</span></span><span class=line><span class=cl>	<span class=n>sample</span> <span class=n>x_T</span> <span class=kn>from</span> <span class=nn>N</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>I</span><span class=p>)</span>
</span></span><span class=line><span class=cl>	<span class=k>for</span> <span class=n>t</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>T</span><span class=p>,</span> <span class=mi>1</span><span class=p>):</span>
</span></span><span class=line><span class=cl>		<span class=n>x_hat_t</span> <span class=o>=</span> <span class=n>NN</span><span class=p>(</span><span class=n>x_t</span><span class=p>,</span> <span class=n>t</span><span class=p>)</span>
</span></span><span class=line><span class=cl>		<span class=c1># get x_{t-1}</span>
</span></span><span class=line><span class=cl>		<span class=n>x_</span><span class=p>{</span><span class=n>t</span><span class=o>-</span><span class=mi>1</span><span class=p>}</span> <span class=o>=</span> <span class=n>func</span><span class=p>(</span><span class=n>x_hat_t</span><span class=p>,</span> <span class=n>t</span><span class=p>)</span>
</span></span><span class=line><span class=cl>	<span class=n>x_hat_0</span> <span class=o>=</span> <span class=n>x_0</span>  
</span></span></code></pre></td></tr></table></div></div><p>The proof requires us to reduce the ELBO loss making use of the Markovian assumption in the diffusion process, and using Monte-Carlo estimates to obtain an equivalent loss. I won&rsquo;t go into details on this proof, please refer <cite>Section: Variational Diffusion Models, equation 100 gives the reduced loss <sup id=fnref2:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup></cite>.</p><h3 id=diffusion-process>Diffusion Process<a hidden class=anchor aria-hidden=true href=#diffusion-process>#</a></h3><p>As described earlier, we are going to be adding noise to the input vector. Let&rsquo;s see how exactly one can do that &ndash;<br>At each timestep $t$ in the diffusion process, we sample from the latent variable, $q_t(x_t|x_{t-1})$.
$$
q_t(x_t|x_{t-1}) = N(\sqrt\alpha_tx_{t-1}, (1 - \alpha_t )I)
$$</p><ul><li>$\alpha_t$, $t\in[1, T]$, where $\alpha_t &lt; 1$, describes the diffusion schedule.</li><li>$\alpha_{t-1} &lt; \alpha_t$, as we go along in the diffusion process we are adding more and more noise.<br>The form of the coefficients is chosen such that the variance of the latent variables stay at a similar scale.</li></ul><p>At this point, let me introduce the reparameterization trick.<br>$$
N(\sqrt\alpha_tx_{t-1}, (1 - \alpha_t )I) = \sqrt\alpha_tx_{t-1} + (1 - \alpha_t)*\epsilon \quad with \,\, \epsilon \sim N(0, I)
$$</p><p>The reparemetarization trick is cool, it simplifies working with a complex Gaussian distribution. If you want to sample from the diffusion step at $t$, you can simply sample from a standard Gaussian distribution $N(0, I)$ and factor and plug in the mean and variance.
Consider another interesting result: suppose we want to sample from the latent $x_t$ directly given $x_0$. In other words, we want to take a sample from $q(x_t|x_0)$.</p><p>$$
\begin{align}
q(x_t|x) &= N(\sqrt\alpha_tx_{t-1}, (1 - \alpha_t )I) \cr
&= \sqrt\alpha_t x_{t-1} + \sqrt{(1-\alpha_t)}\ast\epsilon_t \cr
&= \sqrt\alpha_t(\sqrt\alpha_t x_{t-2} + \sqrt{(1-\alpha_{t-1})}\ast\epsilon_{t-1}) + \sqrt(1-\alpha_t)\ast\epsilon_t \cr
&= \sqrt\alpha_t\sqrt\alpha_t x_{t-2} + \sqrt\alpha_t\sqrt{(1-\alpha_{t-1})}\ast\epsilon_{t-1} + \sqrt(1-\alpha_t)\ast\epsilon_t \cr
&= \sqrt\alpha_t\sqrt\alpha_tx_{t-2} + \sqrt{(1-\alpha_t\alpha_{t-1})}\ast\epsilon_{t-1}^\ast \quad where \thinspace \epsilon_{t-1}^\ast\in N(0, I) \cr
&= ... \cr  
&= \sqrt{\bar\alpha_t}x_0 + \sqrt{(1 - \bar\alpha_t )}\ast\epsilon^\ast ; where \space \bar\alpha_t=\Pi_{i=1}^T{\sqrt\alpha_i}, \space \epsilon^\ast \in N(0, I) \cr
&= N(\sqrt{\bar\alpha_t}x_0, (1 - \bar\alpha_t )I)\cr
\end{align}
$$<br>In equation 5, we have utilized <a href=https://en.wikipedia.org/wiki/Sum_of_normally_distributed_random_variables>sum of two independent Gaussian random variables.</a></p><p>With this in place, let&rsquo;s put some code together.</p><p><strong>The diffusion schedule:</strong> $\alpha$</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-1-1><a class=lnlinks href=#hl-1-1> 1</a>
</span><span class=lnt id=hl-1-2><a class=lnlinks href=#hl-1-2> 2</a>
</span><span class=lnt id=hl-1-3><a class=lnlinks href=#hl-1-3> 3</a>
</span><span class=lnt id=hl-1-4><a class=lnlinks href=#hl-1-4> 4</a>
</span><span class=lnt id=hl-1-5><a class=lnlinks href=#hl-1-5> 5</a>
</span><span class=lnt id=hl-1-6><a class=lnlinks href=#hl-1-6> 6</a>
</span><span class=lnt id=hl-1-7><a class=lnlinks href=#hl-1-7> 7</a>
</span><span class=lnt id=hl-1-8><a class=lnlinks href=#hl-1-8> 8</a>
</span><span class=lnt id=hl-1-9><a class=lnlinks href=#hl-1-9> 9</a>
</span><span class=lnt id=hl-1-10><a class=lnlinks href=#hl-1-10>10</a>
</span><span class=lnt id=hl-1-11><a class=lnlinks href=#hl-1-11>11</a>
</span><span class=lnt id=hl-1-12><a class=lnlinks href=#hl-1-12>12</a>
</span><span class=lnt id=hl-1-13><a class=lnlinks href=#hl-1-13>13</a>
</span><span class=lnt id=hl-1-14><a class=lnlinks href=#hl-1-14>14</a>
</span><span class=lnt id=hl-1-15><a class=lnlinks href=#hl-1-15>15</a>
</span><span class=lnt id=hl-1-16><a class=lnlinks href=#hl-1-16>16</a>
</span><span class=lnt id=hl-1-17><a class=lnlinks href=#hl-1-17>17</a>
</span><span class=lnt id=hl-1-18><a class=lnlinks href=#hl-1-18>18</a>
</span><span class=lnt id=hl-1-19><a class=lnlinks href=#hl-1-19>19</a>
</span><span class=lnt id=hl-1-20><a class=lnlinks href=#hl-1-20>20</a>
</span><span class=lnt id=hl-1-21><a class=lnlinks href=#hl-1-21>21</a>
</span><span class=lnt id=hl-1-22><a class=lnlinks href=#hl-1-22>22</a>
</span><span class=lnt id=hl-1-23><a class=lnlinks href=#hl-1-23>23</a>
</span><span class=lnt id=hl-1-24><a class=lnlinks href=#hl-1-24>24</a>
</span><span class=lnt id=hl-1-25><a class=lnlinks href=#hl-1-25>25</a>
</span><span class=lnt id=hl-1-26><a class=lnlinks href=#hl-1-26>26</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>timestepts</span> <span class=o>=</span> <span class=mi>200</span>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>## linear schedule  </span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>linear_beta_schedule</span><span class=p>(</span><span class=n>timesteps</span><span class=p>):</span>  
</span></span><span class=line><span class=cl> <span class=n>beta_start</span> <span class=o>=</span> <span class=mf>0.0001</span> 
</span></span><span class=line><span class=cl> <span class=n>beta_end</span> <span class=o>=</span> <span class=mf>0.02</span> 
</span></span><span class=line><span class=cl> <span class=k>return</span> <span class=n>jnp</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=n>beta_start</span><span class=p>,</span> <span class=n>beta_end</span><span class=p>,</span> <span class=n>timesteps</span><span class=p>)</span>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>## cosine schedule as proposed in https://arxiv.org/abs/2102.09672  </span>
</span></span><span class=line><span class=cl><span class=c1>## The cosine schedule is recommened if timesteps &gt;&gt; 200. As it results in a gradual noisification of the input data  </span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>cosine_beta_schedule</span><span class=p>(</span><span class=n>timesteps</span><span class=p>,</span> <span class=n>s</span><span class=o>=</span><span class=mf>0.008</span><span class=p>):</span>  
</span></span><span class=line><span class=cl> <span class=n>steps</span> <span class=o>=</span> <span class=n>timesteps</span> <span class=o>+</span> <span class=mi>1</span> 
</span></span><span class=line><span class=cl> <span class=n>x</span> <span class=o>=</span> <span class=n>jnp</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>timesteps</span><span class=p>,</span> <span class=n>steps</span><span class=p>)</span> 
</span></span><span class=line><span class=cl> <span class=n>alphas_cumprod</span> <span class=o>=</span> <span class=n>jnp</span><span class=o>.</span><span class=n>cos</span><span class=p>(((</span><span class=n>x</span> <span class=o>/</span> <span class=n>timesteps</span><span class=p>)</span> <span class=o>+</span> <span class=n>s</span><span class=p>)</span> <span class=o>/</span> <span class=p>(</span><span class=mi>1</span> <span class=o>+</span> <span class=n>s</span><span class=p>)</span> <span class=o>*</span> <span class=n>jnp</span><span class=o>.</span><span class=n>pi</span> <span class=o>*</span> <span class=mf>0.5</span><span class=p>)</span> <span class=o>**</span> <span class=mi>2</span> 
</span></span><span class=line><span class=cl> <span class=n>alphas_cumprod</span> <span class=o>=</span> <span class=n>alphas_cumprod</span> <span class=o>/</span> <span class=n>alphas_cumprod</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> 
</span></span><span class=line><span class=cl> <span class=n>betas</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>-</span> <span class=p>(</span><span class=n>alphas_cumprod</span><span class=p>[</span><span class=mi>1</span><span class=p>:]</span> <span class=o>/</span> <span class=n>alphas_cumprod</span><span class=p>[:</span><span class=o>-</span><span class=mi>1</span><span class=p>])</span> 
</span></span><span class=line><span class=cl> <span class=k>return</span> <span class=n>jnp</span><span class=o>.</span><span class=n>clip</span><span class=p>(</span><span class=n>betas</span><span class=p>,</span> <span class=mf>0.0001</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>)</span>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>## some handy variables  </span>
</span></span><span class=line><span class=cl><span class=n>betas</span> <span class=o>=</span> <span class=n>linear_beta_schedule</span><span class=p>(</span><span class=n>timesteps</span><span class=p>)</span>  
</span></span><span class=line><span class=cl><span class=n>alphas</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>-</span> <span class=n>betas</span>  
</span></span><span class=line><span class=cl><span class=n>alphas_</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cumprod</span><span class=p>(</span><span class=n>alphas</span><span class=p>,</span> <span class=n>axis</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>  
</span></span><span class=line><span class=cl><span class=n>variance</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>-</span> <span class=n>alphas_</span>  
</span></span><span class=line><span class=cl><span class=n>sd</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>variance</span><span class=p>)</span>  
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.nn.functional</span> <span class=k>as</span> <span class=nn>F</span>
</span></span><span class=line><span class=cl><span class=n>alphas_prev_</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>pad</span><span class=p>(</span><span class=n>alphas_</span><span class=p>[:</span><span class=o>-</span><span class=mi>1</span><span class=p>],</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span> <span class=s2>&#34;constant&#34;</span><span class=p>,</span> <span class=mf>1.0</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p><strong>Diffusion:</strong> Given input data $x_0$, a timestep $t$ and a schedule, the diffusion method should return the latent variable $x_t$.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-2-1><a class=lnlinks href=#hl-2-1>1</a>
</span><span class=lnt id=hl-2-2><a class=lnlinks href=#hl-2-2>2</a>
</span><span class=lnt id=hl-2-3><a class=lnlinks href=#hl-2-3>3</a>
</span><span class=lnt id=hl-2-4><a class=lnlinks href=#hl-2-4>4</a>
</span><span class=lnt id=hl-2-5><a class=lnlinks href=#hl-2-5>5</a>
</span><span class=lnt id=hl-2-6><a class=lnlinks href=#hl-2-6>6</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># how to add noise to the data  </span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>get_noisy</span><span class=p>(</span><span class=n>batch</span><span class=p>,</span> <span class=n>timestep</span><span class=p>):</span>  
</span></span><span class=line><span class=cl> <span class=c1># we will use the reparameterization trick </span>
</span></span><span class=line><span class=cl> <span class=n>noise_at_t</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>normal</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>std</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=n>batch</span><span class=o>.</span><span class=n>size</span><span class=p>())</span> 
</span></span><span class=line><span class=cl> <span class=n>added_noise_at_t</span> <span class=o>=</span> <span class=n>batch</span><span class=o>.</span><span class=n>mul</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>alphas_</span><span class=p>[</span><span class=n>timestep</span><span class=p>]))</span> <span class=o>+</span> <span class=n>noise_at_t</span><span class=o>.</span><span class=n>mul</span><span class=p>(</span><span class=n>sd</span><span class=p>[</span><span class=n>timestep</span><span class=p>])</span> 
</span></span><span class=line><span class=cl> <span class=k>return</span> <span class=n>added_noise_at_t</span><span class=p>,</span> <span class=n>noise_at_t</span>  
</span></span></code></pre></td></tr></table></div></div><p>In Variational Diffusion Models, <cite>Kingma et.al, 2022<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup></cite> propose a way to learn the parameters of the schedule and provide additional insights helpful in understanding diffusion models.</p><h3 id=training-procedure>Training Procedure<a hidden class=anchor aria-hidden=true href=#training-procedure>#</a></h3><p>We have just defined the diffusion method in the <a href=/posts/diffusion-models/denoising-diffusion-models-1/#hl-0-1>pseudo code</a>. Let&rsquo;s define the loss function and the Neural Network.</p><p><strong>Neural Network:</strong></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-3-1><a class=lnlinks href=#hl-3-1> 1</a>
</span><span class=lnt id=hl-3-2><a class=lnlinks href=#hl-3-2> 2</a>
</span><span class=lnt id=hl-3-3><a class=lnlinks href=#hl-3-3> 3</a>
</span><span class=lnt id=hl-3-4><a class=lnlinks href=#hl-3-4> 4</a>
</span><span class=lnt id=hl-3-5><a class=lnlinks href=#hl-3-5> 5</a>
</span><span class=lnt id=hl-3-6><a class=lnlinks href=#hl-3-6> 6</a>
</span><span class=lnt id=hl-3-7><a class=lnlinks href=#hl-3-7> 7</a>
</span><span class=lnt id=hl-3-8><a class=lnlinks href=#hl-3-8> 8</a>
</span><span class=lnt id=hl-3-9><a class=lnlinks href=#hl-3-9> 9</a>
</span><span class=lnt id=hl-3-10><a class=lnlinks href=#hl-3-10>10</a>
</span><span class=lnt id=hl-3-11><a class=lnlinks href=#hl-3-11>11</a>
</span><span class=lnt id=hl-3-12><a class=lnlinks href=#hl-3-12>12</a>
</span><span class=lnt id=hl-3-13><a class=lnlinks href=#hl-3-13>13</a>
</span><span class=lnt id=hl-3-14><a class=lnlinks href=#hl-3-14>14</a>
</span><span class=lnt id=hl-3-15><a class=lnlinks href=#hl-3-15>15</a>
</span><span class=lnt id=hl-3-16><a class=lnlinks href=#hl-3-16>16</a>
</span><span class=lnt id=hl-3-17><a class=lnlinks href=#hl-3-17>17</a>
</span><span class=lnt id=hl-3-18><a class=lnlinks href=#hl-3-18>18</a>
</span><span class=lnt id=hl-3-19><a class=lnlinks href=#hl-3-19>19</a>
</span><span class=lnt id=hl-3-20><a class=lnlinks href=#hl-3-20>20</a>
</span><span class=lnt id=hl-3-21><a class=lnlinks href=#hl-3-21>21</a>
</span><span class=lnt id=hl-3-22><a class=lnlinks href=#hl-3-22>22</a>
</span><span class=lnt id=hl-3-23><a class=lnlinks href=#hl-3-23>23</a>
</span><span class=lnt id=hl-3-24><a class=lnlinks href=#hl-3-24>24</a>
</span><span class=lnt id=hl-3-25><a class=lnlinks href=#hl-3-25>25</a>
</span><span class=lnt id=hl-3-26><a class=lnlinks href=#hl-3-26>26</a>
</span><span class=lnt id=hl-3-27><a class=lnlinks href=#hl-3-27>27</a>
</span><span class=lnt id=hl-3-28><a class=lnlinks href=#hl-3-28>28</a>
</span><span class=lnt id=hl-3-29><a class=lnlinks href=#hl-3-29>29</a>
</span><span class=lnt id=hl-3-30><a class=lnlinks href=#hl-3-30>30</a>
</span><span class=lnt id=hl-3-31><a class=lnlinks href=#hl-3-31>31</a>
</span><span class=lnt id=hl-3-32><a class=lnlinks href=#hl-3-32>32</a>
</span><span class=lnt id=hl-3-33><a class=lnlinks href=#hl-3-33>33</a>
</span><span class=lnt id=hl-3-34><a class=lnlinks href=#hl-3-34>34</a>
</span><span class=lnt id=hl-3-35><a class=lnlinks href=#hl-3-35>35</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torch</span> <span class=kn>import</span> <span class=n>nn</span>
</span></span><span class=line><span class=cl>  
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>DenoisingModelSequential</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>hidden_units</span><span class=o>=</span><span class=mi>32</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>(</span><span class=n>DenoisingModelSequential</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=c1># hidden_units = 32</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>mlp</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=nb>int</span><span class=p>(</span><span class=n>hidden_units</span><span class=p>),</span> <span class=n>bias</span><span class=o>=</span><span class=kc>True</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>GELU</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=nb>int</span><span class=p>(</span><span class=n>hidden_units</span><span class=p>),</span> <span class=nb>int</span><span class=p>(</span><span class=n>hidden_units</span><span class=o>/</span><span class=mi>2</span><span class=p>),</span> <span class=n>bias</span><span class=o>=</span><span class=kc>True</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>GELU</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=nb>int</span><span class=p>(</span><span class=n>hidden_units</span><span class=o>/</span><span class=mi>2</span><span class=p>),</span> <span class=nb>int</span><span class=p>(</span><span class=n>hidden_units</span><span class=o>/</span><span class=mi>4</span><span class=p>),</span> <span class=n>bias</span><span class=o>=</span><span class=kc>True</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>GELU</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=nb>int</span><span class=p>(</span><span class=n>hidden_units</span><span class=o>/</span><span class=mi>4</span><span class=p>),</span> <span class=nb>int</span><span class=p>(</span><span class=n>hidden_units</span><span class=o>/</span><span class=mi>8</span><span class=p>),</span> <span class=n>bias</span><span class=o>=</span><span class=kc>True</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>GELU</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=nb>int</span><span class=p>(</span><span class=n>hidden_units</span><span class=o>/</span><span class=mi>8</span><span class=p>),</span> <span class=nb>int</span><span class=p>(</span><span class=n>hidden_units</span><span class=o>/</span><span class=mi>16</span><span class=p>),</span> <span class=n>bias</span><span class=o>=</span><span class=kc>True</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>GELU</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=nb>int</span><span class=p>(</span><span class=n>hidden_units</span><span class=o>/</span><span class=mi>16</span><span class=p>),</span> <span class=nb>int</span><span class=p>(</span><span class=n>hidden_units</span><span class=o>/</span><span class=mi>8</span><span class=p>),</span> <span class=n>bias</span><span class=o>=</span><span class=kc>True</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>GELU</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=nb>int</span><span class=p>(</span><span class=n>hidden_units</span><span class=o>/</span><span class=mi>8</span><span class=p>),</span> <span class=nb>int</span><span class=p>(</span><span class=n>hidden_units</span><span class=o>/</span><span class=mi>4</span><span class=p>),</span> <span class=n>bias</span><span class=o>=</span><span class=kc>True</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>GELU</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=nb>int</span><span class=p>(</span><span class=n>hidden_units</span><span class=o>/</span><span class=mi>4</span><span class=p>),</span> <span class=nb>int</span><span class=p>(</span><span class=n>hidden_units</span><span class=o>/</span><span class=mi>2</span><span class=p>),</span> <span class=n>bias</span><span class=o>=</span><span class=kc>True</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>GELU</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=nb>int</span><span class=p>(</span><span class=n>hidden_units</span><span class=o>/</span><span class=mi>2</span><span class=p>),</span> <span class=nb>int</span><span class=p>(</span><span class=n>hidden_units</span><span class=p>),</span> <span class=n>bias</span><span class=o>=</span><span class=kc>True</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>GELU</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=nb>int</span><span class=p>(</span><span class=n>hidden_units</span><span class=p>),</span> <span class=mi>2</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>   
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>mlp</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>x</span>
</span></span><span class=line><span class=cl>      
</span></span><span class=line><span class=cl><span class=n>denoising_model</span> <span class=o>=</span> <span class=n>DenoisingModelSequential</span><span class=p>(</span><span class=mi>64</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>The input to the NN is 3 dimensional. We are working with 2d dataset, so $\hat x_t$&rsquo;s is a 2d vector. In this article, we are going to pass $t$ as the 3rd dimension, we will pass it as a scalar. In the subsequent articles, we will see how to generate an embedding for a timestep and concatenate/fuse it with the input.
The output of the NN needs to be $\hat x_t^0$ which is a 2d vector.
The NN architecture doesn&rsquo;t really matter. In this case, I&rsquo;ve used a basic Multi Layer Perceptron with <cite>GeLU activation units<sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup></cite>.
We will use a U-net architecture for character generation using the EMNIST dataset. <a href=/posts/diffusion-models/denoising-diffusion-models-4/>Checkout Part 4.</a></p><p><strong>Loss Function</strong>: At timestep $t$
$$
Loss(x_0, \hat x_t, t) = 1/2\ast(\frac{\bar\alpha_{t-1}}{1-\bar\alpha_{t-1}} - \frac{\bar\alpha_t}{1-\bar\alpha_t})\ast\mid\mid x_0-\hat x_0^t\mid\mid_2^2
$$
$$
\text{SNR}_t =\frac{\bar\alpha_t}{1-\bar\alpha_t}
$$
SNR stands for Signal to Noise. In the case of the diffusion, the schedule must to be chosen such that $SNR_t &lt; SNT_{t-1}$.</p><p><strong>Loss:</strong></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-4-1><a class=lnlinks href=#hl-4-1>1</a>
</span><span class=lnt id=hl-4-2><a class=lnlinks href=#hl-4-2>2</a>
</span><span class=lnt id=hl-4-3><a class=lnlinks href=#hl-4-3>3</a>
</span><span class=lnt id=hl-4-4><a class=lnlinks href=#hl-4-4>4</a>
</span><span class=lnt id=hl-4-5><a class=lnlinks href=#hl-4-5>5</a>
</span><span class=lnt id=hl-4-6><a class=lnlinks href=#hl-4-6>6</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># instead of the l2 loss, I use the huber loss </span>
</span></span><span class=line><span class=cl><span class=c1># https://pytorch.org/docs/stable/generated/torch.nn.HuberLoss.html</span>
</span></span><span class=line><span class=cl><span class=n>loss_func</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>HuberLoss</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>imp_weight</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=mi>1</span><span class=o>/</span><span class=mi>2</span> <span class=o>*</span> <span class=p>((</span><span class=n>alphas_prev_</span><span class=p>[</span><span class=n>timestep</span><span class=p>]</span> <span class=o>/</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>alphas_prev_</span><span class=p>[</span><span class=n>timestep</span><span class=p>]))</span> <span class=o>-</span> <span class=p>(</span><span class=n>alphas_</span><span class=p>[</span><span class=n>timestep</span><span class=p>]</span><span class=o>/</span><span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>alphas_</span><span class=p>[</span><span class=n>timestep</span><span class=p>]))))</span>
</span></span><span class=line><span class=cl><span class=n>loss_</span> <span class=o>=</span> <span class=n>loss_func</span><span class=p>(</span><span class=n>data_in_batch</span><span class=o>.</span><span class=n>mul</span><span class=p>(</span><span class=n>imp_weight</span><span class=p>),</span> <span class=n>pred_data</span><span class=o>.</span><span class=n>T</span><span class=o>.</span><span class=n>mul</span><span class=p>(</span><span class=n>imp_weight</span><span class=p>))</span>
</span></span></code></pre></td></tr></table></div></div><p>In <cite>Variation Diffusion Models<sup id=fnref1:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup></cite>, authors propose using a separate Neural Network to model SNR as a function of t. The Neural Network should be monotonically decreasing.</p><h3 id=denoising-process>Denoising Process<a hidden class=anchor aria-hidden=true href=#denoising-process>#</a></h3><p>Let&rsquo;s recap, the denoising process is responsible to generate synthetic data $\hat x$.</p><ol><li>Start with a completely noisy data, $x_T = N(0, I)$</li><li>Uses a Neural Network to predict $\hat x_T^0$</li><li>We will use $\hat x_T^0$ to generate the latent $\hat x_{T-1}$</li><li>repeat step 2 with input $\hat x_{T-1}$ to get $\hat x_{T-2}$ until t=1</li></ol><p>Refer, our mathematical setup in Figure 5. Let&rsquo;s try to look at a backward transition in the denoising process $p(\hat x_t|\hat x_{t+1})$. This is also called the <strong>posterior distribution</strong>.</p><p>Let&rsquo;s investigate what this looks like in the diffusion process:
$$
\begin{align}
q(x_t|x_{t+1}) = \frac{q(x_t|x_{t-1})\ast q(x_{t-1}|x_0)}{q(x_t|x_0)}\quad \text{Baye's theorem \&} \, \text{Note: } x_0 = x \cr 
= ... \cr
\varpropto N(x_{t-1};\underbrace{\frac{\sqrt\alpha_t(1-\bar\alpha_{t-1})x_t + \sqrt{\bar\alpha_{t-1}}(1-\alpha_t)x_0}{1-\bar\alpha_t}}_{\mu_q(x_t,x_0)}, \underbrace{\frac{(1-\alpha_t)(1-\bar\alpha_{t-1})}{1-\bar\alpha_t}I}_{\sum_q(t)}) \cr
\end{align}
$$
For the full derivation please refer <cite>Equation #71; Calvin Luo&rsquo;s tutorial<sup id=fnref3:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup></cite></p><p>We will assume that the reverse process $p(\hat x_t|\hat x_{t+1})$ also follows the same form as the forward process $q(x_t|x_{t+1})$. We will hence do the following &ndash;</p><ol><li>Assume that posterior $p(\hat x_t|\hat x_{t+1})$ follows a Gaussian distribution as well.</li><li>We would keep the posterior mean follow the same form as $\mu_q(x_t, x_0)$.<ul><li>$\mu_p(\hat x_t|\hat x_{t+1}) = \mu_q(x_t, x_0)$, here $\hat x_t$ is the input to the $NN$ and the $NN$ will output a prediction for $\hat x_t^0$</li><li>In Equation 11, we will replace $x_0$ with $\hat x_t^0$ and $x_t$ with $\hat x_t$</li></ul></li><li>With fixed variance, $\sum_{p(x_{t-1}|x_t)} = \sum_q(t)$.<ul><li>As show in <cite>Improved Denoising Diffusion Probabilistic Models.<sup id=fnref:4><a href=#fn:4 class=footnote-ref role=doc-noteref>4</a></sup></cite> We could alternatively learn the posterior variance. In this case, we will make the neural network output the variance as well as the mean.</li></ul></li></ol><p><strong>Diffusion: With Fixed Variance</strong></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-5-1><a class=lnlinks href=#hl-5-1> 1</a>
</span><span class=lnt id=hl-5-2><a class=lnlinks href=#hl-5-2> 2</a>
</span><span class=lnt id=hl-5-3><a class=lnlinks href=#hl-5-3> 3</a>
</span><span class=lnt id=hl-5-4><a class=lnlinks href=#hl-5-4> 4</a>
</span><span class=lnt id=hl-5-5><a class=lnlinks href=#hl-5-5> 5</a>
</span><span class=lnt id=hl-5-6><a class=lnlinks href=#hl-5-6> 6</a>
</span><span class=lnt id=hl-5-7><a class=lnlinks href=#hl-5-7> 7</a>
</span><span class=lnt id=hl-5-8><a class=lnlinks href=#hl-5-8> 8</a>
</span><span class=lnt id=hl-5-9><a class=lnlinks href=#hl-5-9> 9</a>
</span><span class=lnt id=hl-5-10><a class=lnlinks href=#hl-5-10>10</a>
</span><span class=lnt id=hl-5-11><a class=lnlinks href=#hl-5-11>11</a>
</span><span class=lnt id=hl-5-12><a class=lnlinks href=#hl-5-12>12</a>
</span><span class=lnt id=hl-5-13><a class=lnlinks href=#hl-5-13>13</a>
</span><span class=lnt id=hl-5-14><a class=lnlinks href=#hl-5-14>14</a>
</span><span class=lnt id=hl-5-15><a class=lnlinks href=#hl-5-15>15</a>
</span><span class=lnt id=hl-5-16><a class=lnlinks href=#hl-5-16>16</a>
</span><span class=lnt id=hl-5-17><a class=lnlinks href=#hl-5-17>17</a>
</span><span class=lnt id=hl-5-18><a class=lnlinks href=#hl-5-18>18</a>
</span><span class=lnt id=hl-5-19><a class=lnlinks href=#hl-5-19>19</a>
</span><span class=lnt id=hl-5-20><a class=lnlinks href=#hl-5-20>20</a>
</span><span class=lnt id=hl-5-21><a class=lnlinks href=#hl-5-21>21</a>
</span><span class=lnt id=hl-5-22><a class=lnlinks href=#hl-5-22>22</a>
</span><span class=lnt id=hl-5-23><a class=lnlinks href=#hl-5-23>23</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># fixed posterior variance</span>
</span></span><span class=line><span class=cl><span class=n>posterior_variance</span> <span class=o>=</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>alphas</span><span class=p>)</span> <span class=o>*</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>alphas_prev_</span><span class=p>)</span> <span class=o>/</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>alphas</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>generate_data</span><span class=p>(</span><span class=n>denoising_model</span><span class=p>):</span>
</span></span><span class=line><span class=cl>		<span class=c1># generating multiple samples at the same time</span>
</span></span><span class=line><span class=cl>    <span class=n>batch_size_generation</span> <span class=o>=</span> <span class=mi>2048</span><span class=o>*</span><span class=mi>5</span>
</span></span><span class=line><span class=cl>    <span class=c1># x_T -- we will start from a Noisy sample</span>
</span></span><span class=line><span class=cl>    <span class=n>data_noisy</span> <span class=o>=</span>  <span class=n>torch</span><span class=o>.</span><span class=n>normal</span><span class=p>(</span><span class=n>mean</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>std</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=n>batch_size_generation</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>n</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=nb>int</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>data_noisy</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span><span class=o>/</span><span class=n>batch_size_generation</span><span class=p>)</span> <span class=o>+</span> <span class=mi>1</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>data_in_batch</span> <span class=o>=</span> <span class=n>data_noisy</span><span class=p>[:,</span> <span class=p>(</span><span class=n>n</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span><span class=o>*</span><span class=n>batch_size_generation</span><span class=p>:(</span><span class=n>n</span><span class=o>*</span><span class=n>batch_size_generation</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>t</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>timesteps</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>timestep</span> <span class=o>=</span> <span class=n>timesteps</span><span class=o>-</span><span class=n>t</span>
</span></span><span class=line><span class=cl>            <span class=n>t_repeated</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>([</span><span class=n>timestep</span><span class=p>])</span><span class=o>.</span><span class=n>repeat</span><span class=p>(</span><span class=n>batch_size_generation</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>data_stacked</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>vstack</span><span class=p>([</span><span class=n>data_in_batch</span><span class=p>,</span> <span class=n>t_repeated</span><span class=p>])</span>
</span></span><span class=line><span class=cl>            <span class=c1># x_hat_0 prediction at time t</span>
</span></span><span class=line><span class=cl>            <span class=n>pred_data</span> <span class=o>=</span> <span class=n>denoising_model</span><span class=p>(</span><span class=n>data_stacked</span><span class=o>.</span><span class=n>T</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=c1># implementing equation above to get x_(t-1) from x_t and x_0</span>
</span></span><span class=line><span class=cl>            <span class=n>mean_data_1</span> <span class=o>=</span> <span class=n>data_in_batch</span><span class=o>.</span><span class=n>T</span><span class=o>.</span><span class=n>mul</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>alphas</span><span class=p>[</span><span class=n>timestep</span><span class=p>])</span><span class=o>*</span><span class=p>(</span><span class=mi>1</span><span class=o>-</span><span class=n>alphas_prev_</span><span class=p>[</span><span class=n>timestep</span><span class=p>])</span><span class=o>/</span><span class=p>(</span><span class=n>variance</span><span class=p>[</span><span class=n>timestep</span><span class=p>]))</span>
</span></span><span class=line><span class=cl>            <span class=n>mean_data_2</span> <span class=o>=</span> <span class=n>pred_data</span><span class=o>.</span><span class=n>mul</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>alphas_prev_</span><span class=p>[</span><span class=n>timestep</span><span class=p>])</span><span class=o>*</span><span class=p>(</span><span class=mi>1</span><span class=o>-</span><span class=n>alphas</span><span class=p>[</span><span class=n>timestep</span><span class=p>])</span><span class=o>/</span><span class=p>(</span><span class=n>variance</span><span class=p>[</span><span class=n>timestep</span><span class=p>]))</span>
</span></span><span class=line><span class=cl>            <span class=n>mean_data</span> <span class=o>=</span> <span class=n>mean_data_1</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>mean_data_2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>posterior_data</span> <span class=o>=</span> <span class=n>posterior_variance</span><span class=p>[</span><span class=n>timestep</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=n>data_in_batch</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>normal</span><span class=p>(</span><span class=n>mean_data</span><span class=p>,</span> <span class=n>torch</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>posterior_data</span><span class=p>))</span><span class=o>.</span><span class=n>T</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>data_in_batch</span>
</span></span></code></pre></td></tr></table></div></div><h2 id=lets-look-at-some-outputs>Let&rsquo;s look at some outputs<a hidden class=anchor aria-hidden=true href=#lets-look-at-some-outputs>#</a></h2><p>In this article, we will play with some 2d data-points.</p><p><strong>Loading data points:</strong></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-6-1><a class=lnlinks href=#hl-6-1>1</a>
</span><span class=lnt id=hl-6-2><a class=lnlinks href=#hl-6-2>2</a>
</span><span class=lnt id=hl-6-3><a class=lnlinks href=#hl-6-3>3</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>samples</span> <span class=o>=</span> <span class=mi>1024</span><span class=o>*</span><span class=mi>128</span>
</span></span><span class=line><span class=cl><span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>normal</span><span class=p>(</span><span class=n>mean</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>std</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>samples</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>y</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>normal</span><span class=p>(</span><span class=n>mean</span><span class=o>=</span><span class=mf>0.25</span><span class=o>*</span><span class=n>torch</span><span class=o>.</span><span class=n>ones</span><span class=p>(</span><span class=n>samples</span><span class=p>)</span><span class=o>*</span><span class=n>x</span><span class=o>*</span><span class=n>x</span><span class=p>,</span> <span class=n>std</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>ones</span><span class=p>(</span><span class=n>samples</span><span class=p>)</span><span class=o>*</span><span class=mi>1</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt id=hl-7-1><a class=lnlinks href=#hl-7-1>1</a>
</span><span class=lnt id=hl-7-2><a class=lnlinks href=#hl-7-2>2</a>
</span><span class=lnt id=hl-7-3><a class=lnlinks href=#hl-7-3>3</a>
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>circles</span><span class=p>,</span> <span class=n>_</span> <span class=o>=</span> <span class=n>datasets</span><span class=o>.</span><span class=n>make_circles</span><span class=p>(</span><span class=mi>1024</span><span class=o>*</span><span class=mi>128</span><span class=p>,</span> <span class=n>noise</span><span class=o>=</span><span class=mf>0.01</span><span class=p>,</span> <span class=n>factor</span><span class=o>=</span><span class=mf>0.1</span><span class=p>,</span> <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>make_moons</span><span class=p>,</span> <span class=n>labels</span> <span class=o>=</span> <span class=n>datasets</span><span class=o>.</span><span class=n>make_moons</span><span class=p>(</span><span class=n>n_samples</span><span class=o>=</span><span class=mi>1024</span><span class=o>*</span><span class=mi>128</span><span class=p>,</span> <span class=n>noise</span><span class=o>=</span><span class=mf>0.01</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>complex_data</span> <span class=o>=</span> <span class=n>numpy</span><span class=o>.</span><span class=n>hstack</span><span class=p>([</span><span class=n>make_moons</span> <span class=o>+</span> <span class=mi>15</span><span class=p>,</span> <span class=n>circles</span> <span class=p>])</span> 
</span></span></code></pre></td></tr></table></div></div><p><strong>Data compared to Diffusion data:</strong></p><p>Let&rsquo;s look at some data I was able to generate using this concept.</p><figure class=align-center><img loading=lazy src=/images/parabola.png#center alt="Figure 6: 2D Parabola vs Diffusion generated" width=80%><figcaption><p>Figure 6: 2D Parabola vs Diffusion generated</p></figcaption></figure><figure class=align-center><img loading=lazy src=/images/complex.png#center alt="Figure 7: 2D Complex vs Diffusion generated" width=80%><figcaption><p>Figure 7: 2D Complex vs Diffusion generated</p></figcaption></figure><figure class=align-center><img loading=lazy src=/images/complex-data.gif#center alt="Figure 8: A gif show-casing the denoising process; We start from complete noise and make small improvements step by step" width=80%><figcaption><p>Figure 8: A gif show-casing the denoising process; We start from complete noise and make small improvements step by step</p></figcaption></figure><p>See you in the <a href=/posts/diffusion-models/denoising-diffusion-models-2>next part</a>.
You can find the <a href=/posts/diffusion-models/diffusion-models-notebooks>Jupyter Notebook here</a>.</p><blockquote><p>Written with <a href=https://stackedit.io/>StackEdit</a>.</p></blockquote><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>Calvin Luo; 2019 <a href=http://arxiv.org/abs/2208.11970>&ldquo;Understanding Diffusion Models: A Unified Perspective&rdquo;</a>&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a>&#160;<a href=#fnref1:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a>&#160;<a href=#fnref2:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a>&#160;<a href=#fnref3:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p>Kingma et al; 2022 <a href=http://arxiv.org/abs/2107.00630>&ldquo;Variational Diffusion Models&rdquo;</a>&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a>&#160;<a href=#fnref1:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3><p>Hendrycks et. al; 2016 <a href=https://arxiv.org/abs/1606.08415>Gelu&rsquo;s</a>&#160;<a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:4><p>Nichol et al; 2021 <a href=http://arxiv.org/abs/2102.09672>Improved Denoising Diffusion Probabilistic Models</a>&#160;<a href=#fnref:4 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><footer class=post-footer><ul class=post-tags><li><a href=https://varun-ml.github.io/tags/diffusion-model/>diffusion model</a></li><li><a href=https://varun-ml.github.io/tags/de-noising/>de-noising</a></li><li><a href=https://varun-ml.github.io/tags/generative-ai/>generative ai</a></li><li><a href=https://varun-ml.github.io/tags/pytorch/>pytorch</a></li><li><a href=https://varun-ml.github.io/tags/ddpm/>DDPM</a></li><li><a href=https://varun-ml.github.io/tags/jupyter/>jupyter</a></li><li><a href=https://varun-ml.github.io/tags/tutorial/>tutorial</a></li><li><a href=https://varun-ml.github.io/tags/diffusion-model-series/>diffusion model series</a></li></ul><nav class=paginav><a class=next href=https://varun-ml.github.io/posts/diffusion-models/diffusion-models-notebooks/><span class=title>Next ¬ª</span><br><span>Code: Diffusion Model Notebooks</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share Denoising Diffusion Models Part 1: Estimating True Distribution on twitter" href="https://twitter.com/intent/tweet/?text=Denoising%20Diffusion%20Models%20Part%201%3a%20Estimating%20True%20Distribution&url=https%3a%2f%2fvarun-ml.github.io%2fposts%2fdiffusion-models%2fdenoising-diffusion-models-1%2f&hashtags=diffusionmodel%2cde-noising%2cgenerativeai%2cpytorch%2cDDPM%2cjupyter%2ctutorial%2cdiffusionmodelseries"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Denoising Diffusion Models Part 1: Estimating True Distribution on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fvarun-ml.github.io%2fposts%2fdiffusion-models%2fdenoising-diffusion-models-1%2f&title=Denoising%20Diffusion%20Models%20Part%201%3a%20Estimating%20True%20Distribution&summary=Denoising%20Diffusion%20Models%20Part%201%3a%20Estimating%20True%20Distribution&source=https%3a%2f%2fvarun-ml.github.io%2fposts%2fdiffusion-models%2fdenoising-diffusion-models-1%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Denoising Diffusion Models Part 1: Estimating True Distribution on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fvarun-ml.github.io%2fposts%2fdiffusion-models%2fdenoising-diffusion-models-1%2f&title=Denoising%20Diffusion%20Models%20Part%201%3a%20Estimating%20True%20Distribution"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Denoising Diffusion Models Part 1: Estimating True Distribution on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fvarun-ml.github.io%2fposts%2fdiffusion-models%2fdenoising-diffusion-models-1%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Denoising Diffusion Models Part 1: Estimating True Distribution on whatsapp" href="https://api.whatsapp.com/send?text=Denoising%20Diffusion%20Models%20Part%201%3a%20Estimating%20True%20Distribution%20-%20https%3a%2f%2fvarun-ml.github.io%2fposts%2fdiffusion-models%2fdenoising-diffusion-models-1%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Denoising Diffusion Models Part 1: Estimating True Distribution on telegram" href="https://telegram.me/share/url?text=Denoising%20Diffusion%20Models%20Part%201%3a%20Estimating%20True%20Distribution&url=https%3a%2f%2fvarun-ml.github.io%2fposts%2fdiffusion-models%2fdenoising-diffusion-models-1%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2022 <a href=https://varun-ml.github.io/>wity'ai</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>